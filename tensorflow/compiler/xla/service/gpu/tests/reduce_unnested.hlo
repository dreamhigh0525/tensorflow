// RUN: hlo_to_llvm_ir %s | FileCheck %s

// NOTE: Assertions have been autogenerated by utils/generate-test-checks.py

// CHECK-LABEL: entry:
// CHECK:         %[[VAL_0:.*]] = getelementptr inbounds i8, i8* %[[VAL_1:.*]], i64 0
// CHECK:         %[[VAL_2:.*]] = bitcast i8* %[[VAL_0]] to [2 x [32 x [32 x float]]]*
// CHECK:         %[[VAL_3:.*]] = getelementptr inbounds i8, i8* %[[VAL_4:.*]], i64 0
// CHECK:         %[[VAL_5:.*]] = bitcast i8* %[[VAL_3]] to float*
// CHECK:         %[[VAL_6:.*]] = getelementptr inbounds i8, i8* %[[VAL_7:.*]], i64 0
// CHECK:         %[[VAL_8:.*]] = bitcast i8* %[[VAL_6]] to float*
// CHECK:         %[[VAL_9:.*]] = getelementptr inbounds i8, i8* %[[VAL_10:.*]], i64 0
// CHECK:         %[[VAL_11:.*]] = bitcast i8* %[[VAL_9]] to [2 x [32 x float]]*
// CHECK:         %[[VAL_12:.*]] = getelementptr inbounds i8, i8* %[[VAL_13:.*]], i64 0
// CHECK:         %[[VAL_14:.*]] = bitcast i8* %[[VAL_12]] to [2 x [32 x float]]*
// CHECK:         %[[VAL_15:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !6
// CHECK:         %[[VAL_16:.*]] = zext i32 %[[VAL_15]] to i64
// CHECK:         %[[VAL_17:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !7
// CHECK:         %[[VAL_18:.*]] = zext i32 %[[VAL_17]] to i64
// CHECK:         %[[VAL_19:.*]] = mul nuw nsw i64 %[[VAL_16]], 64
// CHECK:         %[[VAL_20:.*]] = add nuw nsw i64 %[[VAL_19]], %[[VAL_18]]
// CHECK:         %[[VAL_21:.*]] = icmp ult i64 %[[VAL_20]], 64
// CHECK:         call void @llvm.assume(i1 %[[VAL_21]])
// CHECK:         %[[VAL_22:.*]] = udiv i64 %[[VAL_20]], 1
// CHECK:         %[[VAL_23:.*]] = urem i64 %[[VAL_22]], 32
// CHECK:         %[[VAL_24:.*]] = udiv i64 %[[VAL_20]], 32
// CHECK:         %[[VAL_25:.*]] = icmp ult i64 %[[VAL_20]], 64
// CHECK:         br i1 %[[VAL_25]], label %[[VAL_26:.*]], label %[[VAL_27:.*]]
// CHECK:       fusion.in_bounds-after:                           ; preds = %[[VAL_26]], %[[VAL_28:.*]]
// CHECK:         ret void
// CHECK:       fusion.in_bounds-true:                            ; preds = %[[VAL_28]]
// CHECK:         %[[VAL_29:.*]] = load float, float* %[[VAL_5]], align 4, !invariant.load !8
// CHECK:         %[[VAL_30:.*]] = bitcast [2 x [32 x float]]* %[[VAL_11]] to float*
// CHECK:         %[[VAL_31:.*]] = getelementptr inbounds float, float* %[[VAL_30]], i64 %[[VAL_20]]
// CHECK:         store float %[[VAL_29]], float* %[[VAL_31]], align 4
// CHECK:         br label %[[VAL_27]]
// CHECK:       entry:
// CHECK:         %[[VAL_32:.*]] = getelementptr inbounds i8, i8* %[[VAL_33:.*]], i64 0
// CHECK:         %[[VAL_34:.*]] = bitcast i8* %[[VAL_32]] to [2 x [32 x [32 x float]]]*
// CHECK:         %[[VAL_35:.*]] = getelementptr inbounds i8, i8* %[[VAL_36:.*]], i64 0
// CHECK:         %[[VAL_37:.*]] = bitcast i8* %[[VAL_35]] to float*
// CHECK:         %[[VAL_38:.*]] = getelementptr inbounds i8, i8* %[[VAL_39:.*]], i64 0
// CHECK:         %[[VAL_40:.*]] = bitcast i8* %[[VAL_38]] to float*
// CHECK:         %[[VAL_41:.*]] = getelementptr inbounds i8, i8* %[[VAL_42:.*]], i64 0
// CHECK:         %[[VAL_43:.*]] = bitcast i8* %[[VAL_41]] to [2 x [32 x float]]*
// CHECK:         %[[VAL_44:.*]] = getelementptr inbounds i8, i8* %[[VAL_45:.*]], i64 0
// CHECK:         %[[VAL_46:.*]] = bitcast i8* %[[VAL_44]] to [2 x [32 x float]]*
// CHECK:         %[[VAL_47:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !6
// CHECK:         %[[VAL_48:.*]] = zext i32 %[[VAL_47]] to i64
// CHECK:         %[[VAL_49:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !7
// CHECK:         %[[VAL_50:.*]] = zext i32 %[[VAL_49]] to i64
// CHECK:         %[[VAL_51:.*]] = mul nuw nsw i64 %[[VAL_48]], 64
// CHECK:         %[[VAL_52:.*]] = add nuw nsw i64 %[[VAL_51]], %[[VAL_50]]
// CHECK:         %[[VAL_53:.*]] = icmp ult i64 %[[VAL_52]], 64
// CHECK:         call void @llvm.assume(i1 %[[VAL_53]])
// CHECK:         %[[VAL_54:.*]] = udiv i64 %[[VAL_52]], 1
// CHECK:         %[[VAL_55:.*]] = urem i64 %[[VAL_54]], 32
// CHECK:         %[[VAL_56:.*]] = udiv i64 %[[VAL_52]], 32
// CHECK:         %[[VAL_57:.*]] = icmp ult i64 %[[VAL_52]], 64
// CHECK:         br i1 %[[VAL_57]], label %[[VAL_58:.*]], label %[[VAL_59:.*]]
// CHECK:       fusion.in_bounds-after:                           ; preds = %[[VAL_58]], %[[VAL_60:.*]]
// CHECK:         ret void
// CHECK:       fusion.in_bounds-true:                            ; preds = %[[VAL_60]]
// CHECK:         %[[VAL_61:.*]] = load float, float* %[[VAL_40]], align 4, !invariant.load !8
// CHECK:         %[[VAL_62:.*]] = bitcast [2 x [32 x float]]* %[[VAL_46]] to float*
// CHECK:         %[[VAL_63:.*]] = getelementptr inbounds float, float* %[[VAL_62]], i64 %[[VAL_52]]
// CHECK:         store float %[[VAL_61]], float* %[[VAL_63]], align 4
// CHECK:         br label %[[VAL_59]]
// CHECK:       entry:
// CHECK:         %[[VAL_64:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_65:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_66:.*]] = alloca float, align 4
// CHECK:         %[[VAL_67:.*]] = alloca float, align 4
// CHECK:         %[[VAL_68:.*]] = alloca float, align 4
// CHECK:         %[[VAL_69:.*]] = alloca float, align 4
// CHECK:         %[[VAL_70:.*]] = alloca float, align 4
// CHECK:         %[[VAL_71:.*]] = alloca float, align 4
// CHECK:         %[[VAL_72:.*]] = alloca float, align 4
// CHECK:         %[[VAL_73:.*]] = alloca float, align 4
// CHECK:         %[[VAL_74:.*]] = alloca float, align 4
// CHECK:         %[[VAL_75:.*]] = alloca float, align 4
// CHECK:         %[[VAL_76:.*]] = alloca float, align 4
// CHECK:         %[[VAL_77:.*]] = alloca float, align 4
// CHECK:         %[[VAL_78:.*]] = alloca float, align 4
// CHECK:         %[[VAL_79:.*]] = alloca float, align 4
// CHECK:         %[[VAL_80:.*]] = alloca float, align 4
// CHECK:         %[[VAL_81:.*]] = alloca float, align 4
// CHECK:         %[[VAL_82:.*]] = alloca float, align 4
// CHECK:         %[[VAL_83:.*]] = alloca float, align 4
// CHECK:         %[[VAL_84:.*]] = alloca float, align 4
// CHECK:         %[[VAL_85:.*]] = alloca float, align 4
// CHECK:         %[[VAL_86:.*]] = alloca float, align 4
// CHECK:         %[[VAL_87:.*]] = alloca float, align 4
// CHECK:         %[[VAL_88:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_89:.*]] = alloca float, align 4
// CHECK:         %[[VAL_90:.*]] = alloca float, align 4
// CHECK:         %[[VAL_91:.*]] = alloca float, align 4
// CHECK:         %[[VAL_92:.*]] = alloca float, align 4
// CHECK:         %[[VAL_93:.*]] = getelementptr inbounds i8, i8* %[[VAL_94:.*]], i64 0
// CHECK:         %[[VAL_95:.*]] = bitcast i8* %[[VAL_93]] to [2 x [32 x [32 x float]]]*
// CHECK:         %[[VAL_96:.*]] = getelementptr inbounds i8, i8* %[[VAL_97:.*]], i64 0
// CHECK:         %[[VAL_98:.*]] = bitcast i8* %[[VAL_96]] to float*
// CHECK:         %[[VAL_99:.*]] = getelementptr inbounds i8, i8* %[[VAL_100:.*]], i64 0
// CHECK:         %[[VAL_101:.*]] = bitcast i8* %[[VAL_99]] to float*
// CHECK:         %[[VAL_102:.*]] = getelementptr inbounds i8, i8* %[[VAL_103:.*]], i64 0
// CHECK:         %[[VAL_104:.*]] = bitcast i8* %[[VAL_102]] to [2 x [32 x float]]*
// CHECK:         %[[VAL_105:.*]] = getelementptr inbounds i8, i8* %[[VAL_106:.*]], i64 0
// CHECK:         %[[VAL_107:.*]] = bitcast i8* %[[VAL_105]] to [2 x [32 x float]]*
// CHECK:         %[[VAL_108:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y(), !range !6
// CHECK:         %[[VAL_109:.*]] = icmp eq i32 %[[VAL_108]], 0
// CHECK:         br i1 %[[VAL_109]], label %[[VAL_110:.*]], label %[[VAL_111:.*]]
// CHECK:       reduce-group-0-after:                             ; preds = %[[VAL_112:.*]], %[[VAL_113:.*]]
// CHECK:         ret void
// CHECK:       reduce-group-0-true:                              ; preds = %[[VAL_113]]
// CHECK:         %[[VAL_114:.*]] = load float, float* %[[VAL_98]], align 4, !invariant.load !8
// CHECK:         %[[VAL_115:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         store float %[[VAL_114]], float* %[[VAL_115]], align 4
// CHECK:         %[[VAL_116:.*]] = load float, float* %[[VAL_101]], align 4, !invariant.load !8
// CHECK:         %[[VAL_117:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         store float %[[VAL_116]], float* %[[VAL_117]], align 4
// CHECK:         %[[VAL_118:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !9
// CHECK:         %[[VAL_119:.*]] = urem i32 %[[VAL_118]], 32
// CHECK:         %[[VAL_120:.*]] = udiv i32 %[[VAL_118]], 32
// CHECK:         %[[VAL_121:.*]] = urem i32 %[[VAL_118]], 32
// CHECK:         %[[VAL_122:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !7
// CHECK:         %[[VAL_123:.*]] = udiv i32 %[[VAL_122]], 1
// CHECK:         %[[VAL_124:.*]] = urem i32 %[[VAL_123]], 1
// CHECK:         %[[VAL_125:.*]] = udiv i32 %[[VAL_122]], 1
// CHECK:         %[[VAL_126:.*]] = urem i32 %[[VAL_125]], 64
// CHECK:         %[[VAL_127:.*]] = udiv i32 %[[VAL_122]], 64
// CHECK:         %[[VAL_128:.*]] = mul i32 %[[VAL_127]], 1
// CHECK:         %[[VAL_129:.*]] = icmp eq i32 %[[VAL_126]], 63
// CHECK:         %[[VAL_130:.*]] = select i1 %[[VAL_129]], i32 1, i32 1
// CHECK:         %[[VAL_131:.*]] = icmp eq i32 %[[VAL_124]], 0
// CHECK:         %[[VAL_132:.*]] = select i1 %[[VAL_131]], i32 32, i32 512
// CHECK:         %[[VAL_133:.*]] = mul i32 %[[VAL_126]], 1
// CHECK:         %[[VAL_134:.*]] = mul i32 %[[VAL_124]], 512
// CHECK:         %[[VAL_135:.*]] = mul i32 %[[VAL_119]], 2
// CHECK:         %[[VAL_136:.*]] = add i32 %[[VAL_134]], %[[VAL_135]]
// CHECK:         store i32 %[[VAL_120]], i32* %[[VAL_88]], align 4
// CHECK:         br label %[[VAL_137:.*]]
// CHECK:       output_y_in_tile.loop_header:                     ; preds = %[[VAL_138:.*]], %[[VAL_110]]
// CHECK:         %[[VAL_139:.*]] = load i32, i32* %[[VAL_88]], align 4
// CHECK:         %[[VAL_140:.*]] = icmp uge i32 %[[VAL_139]], %[[VAL_130]]
// CHECK:         br i1 %[[VAL_140]], label %[[VAL_141:.*]], label %[[VAL_142:.*]]
// CHECK:       output_y_in_tile.loop_body:                       ; preds = %[[VAL_137]]
// CHECK:         %[[VAL_143:.*]] = add nuw nsw i32 %[[VAL_139]], 1
// CHECK:         store i32 %[[VAL_143]], i32* %[[VAL_88]], align 4
// CHECK:         %[[VAL_144:.*]] = icmp eq i32 %[[VAL_139]], %[[VAL_120]]
// CHECK:         %[[VAL_145:.*]] = icmp eq i32 512, %[[VAL_132]]
// CHECK:         br i1 %[[VAL_145]], label %[[VAL_146:.*]], label %[[VAL_147:.*]]
// CHECK:       output_is_full_tile-after:                        ; preds = %[[VAL_148:.*]], %[[VAL_146]]
// CHECK:         br label %[[VAL_137]], !llvm.loop !10
// CHECK:       output_y_in_tile.loop_exit:                       ; preds = %[[VAL_137]]
// CHECK:         %[[VAL_149:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !9
// CHECK:         %[[VAL_150:.*]] = urem i32 %[[VAL_149]], 32
// CHECK:         %[[VAL_151:.*]] = udiv i32 %[[VAL_149]], 32
// CHECK:         %[[VAL_152:.*]] = urem i32 %[[VAL_149]], 32
// CHECK:         %[[VAL_153:.*]] = mul i32 %[[VAL_150]], 2
// CHECK:         %[[VAL_154:.*]] = add i32 %[[VAL_133]], %[[VAL_151]]
// CHECK:         %[[VAL_155:.*]] = add i32 %[[VAL_134]], %[[VAL_153]]
// CHECK:         %[[VAL_156:.*]] = add i32 %[[VAL_155]], 0
// CHECK:         %[[VAL_157:.*]] = udiv i32 %[[VAL_154]], 1
// CHECK:         %[[VAL_158:.*]] = urem i32 %[[VAL_157]], 32
// CHECK:         %[[VAL_159:.*]] = udiv i32 %[[VAL_154]], 32
// CHECK:         %[[VAL_160:.*]] = getelementptr inbounds [2 x [32 x float]], [2 x [32 x float]]* %[[VAL_104]], i32 0, i32 %[[VAL_159]], i32 %[[VAL_158]]
// CHECK:         %[[VAL_161:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         %[[VAL_162:.*]] = load float, float* %[[VAL_161]], align 4
// CHECK:         %[[VAL_163:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_162]], i32 16, i32 31)
// CHECK:         store float %[[VAL_163]], float* %[[VAL_87]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_161]], float* %[[VAL_87]], float* %[[VAL_161]])
// CHECK:         %[[VAL_164:.*]] = load float, float* %[[VAL_161]], align 4
// CHECK:         %[[VAL_165:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_164]], i32 8, i32 31)
// CHECK:         store float %[[VAL_165]], float* %[[VAL_86]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_161]], float* %[[VAL_86]], float* %[[VAL_161]])
// CHECK:         %[[VAL_166:.*]] = load float, float* %[[VAL_161]], align 4
// CHECK:         %[[VAL_167:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_166]], i32 4, i32 31)
// CHECK:         store float %[[VAL_167]], float* %[[VAL_85]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_161]], float* %[[VAL_85]], float* %[[VAL_161]])
// CHECK:         %[[VAL_168:.*]] = load float, float* %[[VAL_161]], align 4
// CHECK:         %[[VAL_169:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_168]], i32 2, i32 31)
// CHECK:         store float %[[VAL_169]], float* %[[VAL_84]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_161]], float* %[[VAL_84]], float* %[[VAL_161]])
// CHECK:         %[[VAL_170:.*]] = load float, float* %[[VAL_161]], align 4
// CHECK:         %[[VAL_171:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_170]], i32 1, i32 31)
// CHECK:         store float %[[VAL_171]], float* %[[VAL_83]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_161]], float* %[[VAL_83]], float* %[[VAL_161]])
// CHECK:         %[[VAL_172:.*]] = udiv i32 %[[VAL_150]], 32
// CHECK:         %[[VAL_173:.*]] = icmp eq i32 %[[VAL_152]], 0
// CHECK:         br i1 %[[VAL_173]], label %[[VAL_174:.*]], label %[[VAL_175:.*]]
// CHECK:       intra_warp_reduce_write-after:                    ; preds = %[[VAL_174]], %[[VAL_141]]
// CHECK:         call void @llvm.nvvm.barrier0()
// CHECK:         %[[VAL_176:.*]] = icmp eq i32 %[[VAL_172]], 0
// CHECK:         br i1 %[[VAL_176]], label %[[VAL_177:.*]], label %[[VAL_178:.*]]
// CHECK:       inter_warp_reduce-after:                          ; preds = %[[VAL_179:.*]], %[[VAL_175]]
// CHECK:         %[[VAL_180:.*]] = add i32 %[[VAL_155]], 0
// CHECK:         %[[VAL_181:.*]] = udiv i32 %[[VAL_154]], 1
// CHECK:         %[[VAL_182:.*]] = urem i32 %[[VAL_181]], 32
// CHECK:         %[[VAL_183:.*]] = udiv i32 %[[VAL_154]], 32
// CHECK:         %[[VAL_184:.*]] = getelementptr inbounds [2 x [32 x float]], [2 x [32 x float]]* %[[VAL_107]], i32 0, i32 %[[VAL_183]], i32 %[[VAL_182]]
// CHECK:         %[[VAL_185:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         %[[VAL_186:.*]] = load float, float* %[[VAL_185]], align 4
// CHECK:         %[[VAL_187:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_186]], i32 16, i32 31)
// CHECK:         store float %[[VAL_187]], float* %[[VAL_76]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_185]], float* %[[VAL_76]], float* %[[VAL_185]])
// CHECK:         %[[VAL_188:.*]] = load float, float* %[[VAL_185]], align 4
// CHECK:         %[[VAL_189:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_188]], i32 8, i32 31)
// CHECK:         store float %[[VAL_189]], float* %[[VAL_75]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_185]], float* %[[VAL_75]], float* %[[VAL_185]])
// CHECK:         %[[VAL_190:.*]] = load float, float* %[[VAL_185]], align 4
// CHECK:         %[[VAL_191:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_190]], i32 4, i32 31)
// CHECK:         store float %[[VAL_191]], float* %[[VAL_74]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_185]], float* %[[VAL_74]], float* %[[VAL_185]])
// CHECK:         %[[VAL_192:.*]] = load float, float* %[[VAL_185]], align 4
// CHECK:         %[[VAL_193:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_192]], i32 2, i32 31)
// CHECK:         store float %[[VAL_193]], float* %[[VAL_73]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_185]], float* %[[VAL_73]], float* %[[VAL_185]])
// CHECK:         %[[VAL_194:.*]] = load float, float* %[[VAL_185]], align 4
// CHECK:         %[[VAL_195:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_194]], i32 1, i32 31)
// CHECK:         store float %[[VAL_195]], float* %[[VAL_72]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_185]], float* %[[VAL_72]], float* %[[VAL_185]])
// CHECK:         %[[VAL_196:.*]] = udiv i32 %[[VAL_150]], 32
// CHECK:         %[[VAL_197:.*]] = icmp eq i32 %[[VAL_152]], 0
// CHECK:         br i1 %[[VAL_197]], label %[[VAL_198:.*]], label %[[VAL_199:.*]]
// CHECK:       intra_warp_reduce_write-after225:                 ; preds = %[[VAL_198]], %[[VAL_178]]
// CHECK:         call void @llvm.nvvm.barrier0()
// CHECK:         %[[VAL_200:.*]] = icmp eq i32 %[[VAL_196]], 0
// CHECK:         br i1 %[[VAL_200]], label %[[VAL_201:.*]], label %[[VAL_112]]
// CHECK:       inter_warp_reduce-after227:                       ; preds = %[[VAL_202:.*]], %[[VAL_199]]
// CHECK:         br label %[[VAL_111]]
// CHECK:       output_is_full_tile-true:                         ; preds = %[[VAL_142]]
// CHECK:         %[[VAL_203:.*]] = add i32 %[[VAL_133]], %[[VAL_139]]
// CHECK:         %[[VAL_204:.*]] = add i32 0, %[[VAL_135]]
// CHECK:         %[[VAL_205:.*]] = add i32 %[[VAL_136]], 0
// CHECK:         %[[VAL_206:.*]] = mul nuw nsw i32 %[[VAL_205]], 1
// CHECK:         %[[VAL_207:.*]] = add nuw nsw i32 0, %[[VAL_206]]
// CHECK:         %[[VAL_208:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_209:.*]] = add nuw nsw i32 %[[VAL_207]], %[[VAL_208]]
// CHECK:         %[[VAL_210:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_211:.*]] = add nuw nsw i32 %[[VAL_209]], %[[VAL_210]]
// CHECK:         %[[VAL_212:.*]] = udiv i32 %[[VAL_211]], 1
// CHECK:         %[[VAL_213:.*]] = urem i32 %[[VAL_212]], 32
// CHECK:         %[[VAL_214:.*]] = udiv i32 %[[VAL_211]], 32
// CHECK:         %[[VAL_215:.*]] = urem i32 %[[VAL_214]], 32
// CHECK:         %[[VAL_216:.*]] = udiv i32 %[[VAL_211]], 1024
// CHECK:         %[[VAL_217:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_218:.*]] = getelementptr inbounds float, float* %[[VAL_217]], i32 %[[VAL_211]]
// CHECK:         %[[VAL_219:.*]] = load float, float* %[[VAL_218]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_219]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_220:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_220]], float* %[[VAL_92]], float* %[[VAL_220]])
// CHECK:         %[[VAL_221:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_222:.*]] = getelementptr inbounds float, float* %[[VAL_221]], i32 %[[VAL_211]]
// CHECK:         %[[VAL_223:.*]] = load float, float* %[[VAL_222]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_223]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_224:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_224]], float* %[[VAL_90]], float* %[[VAL_224]])
// CHECK:         %[[VAL_225:.*]] = add i32 1, %[[VAL_135]]
// CHECK:         %[[VAL_226:.*]] = add i32 %[[VAL_136]], 1
// CHECK:         %[[VAL_227:.*]] = mul nuw nsw i32 %[[VAL_226]], 1
// CHECK:         %[[VAL_228:.*]] = add nuw nsw i32 0, %[[VAL_227]]
// CHECK:         %[[VAL_229:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_230:.*]] = add nuw nsw i32 %[[VAL_228]], %[[VAL_229]]
// CHECK:         %[[VAL_231:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_232:.*]] = add nuw nsw i32 %[[VAL_230]], %[[VAL_231]]
// CHECK:         %[[VAL_233:.*]] = udiv i32 %[[VAL_232]], 1
// CHECK:         %[[VAL_234:.*]] = urem i32 %[[VAL_233]], 32
// CHECK:         %[[VAL_235:.*]] = udiv i32 %[[VAL_232]], 32
// CHECK:         %[[VAL_236:.*]] = urem i32 %[[VAL_235]], 32
// CHECK:         %[[VAL_237:.*]] = udiv i32 %[[VAL_232]], 1024
// CHECK:         %[[VAL_238:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_239:.*]] = getelementptr inbounds float, float* %[[VAL_238]], i32 %[[VAL_232]]
// CHECK:         %[[VAL_240:.*]] = load float, float* %[[VAL_239]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_240]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_241:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_241]], float* %[[VAL_92]], float* %[[VAL_241]])
// CHECK:         %[[VAL_242:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_243:.*]] = getelementptr inbounds float, float* %[[VAL_242]], i32 %[[VAL_232]]
// CHECK:         %[[VAL_244:.*]] = load float, float* %[[VAL_243]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_244]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_245:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_245]], float* %[[VAL_90]], float* %[[VAL_245]])
// CHECK:         %[[VAL_246:.*]] = add i32 64, %[[VAL_135]]
// CHECK:         %[[VAL_247:.*]] = add i32 %[[VAL_136]], 64
// CHECK:         %[[VAL_248:.*]] = mul nuw nsw i32 %[[VAL_247]], 1
// CHECK:         %[[VAL_249:.*]] = add nuw nsw i32 0, %[[VAL_248]]
// CHECK:         %[[VAL_250:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_251:.*]] = add nuw nsw i32 %[[VAL_249]], %[[VAL_250]]
// CHECK:         %[[VAL_252:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_253:.*]] = add nuw nsw i32 %[[VAL_251]], %[[VAL_252]]
// CHECK:         %[[VAL_254:.*]] = udiv i32 %[[VAL_253]], 1
// CHECK:         %[[VAL_255:.*]] = urem i32 %[[VAL_254]], 32
// CHECK:         %[[VAL_256:.*]] = udiv i32 %[[VAL_253]], 32
// CHECK:         %[[VAL_257:.*]] = urem i32 %[[VAL_256]], 32
// CHECK:         %[[VAL_258:.*]] = udiv i32 %[[VAL_253]], 1024
// CHECK:         %[[VAL_259:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_260:.*]] = getelementptr inbounds float, float* %[[VAL_259]], i32 %[[VAL_253]]
// CHECK:         %[[VAL_261:.*]] = load float, float* %[[VAL_260]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_261]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_262:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_262]], float* %[[VAL_92]], float* %[[VAL_262]])
// CHECK:         %[[VAL_263:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_264:.*]] = getelementptr inbounds float, float* %[[VAL_263]], i32 %[[VAL_253]]
// CHECK:         %[[VAL_265:.*]] = load float, float* %[[VAL_264]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_265]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_266:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_266]], float* %[[VAL_90]], float* %[[VAL_266]])
// CHECK:         %[[VAL_267:.*]] = add i32 65, %[[VAL_135]]
// CHECK:         %[[VAL_268:.*]] = add i32 %[[VAL_136]], 65
// CHECK:         %[[VAL_269:.*]] = mul nuw nsw i32 %[[VAL_268]], 1
// CHECK:         %[[VAL_270:.*]] = add nuw nsw i32 0, %[[VAL_269]]
// CHECK:         %[[VAL_271:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_272:.*]] = add nuw nsw i32 %[[VAL_270]], %[[VAL_271]]
// CHECK:         %[[VAL_273:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_274:.*]] = add nuw nsw i32 %[[VAL_272]], %[[VAL_273]]
// CHECK:         %[[VAL_275:.*]] = udiv i32 %[[VAL_274]], 1
// CHECK:         %[[VAL_276:.*]] = urem i32 %[[VAL_275]], 32
// CHECK:         %[[VAL_277:.*]] = udiv i32 %[[VAL_274]], 32
// CHECK:         %[[VAL_278:.*]] = urem i32 %[[VAL_277]], 32
// CHECK:         %[[VAL_279:.*]] = udiv i32 %[[VAL_274]], 1024
// CHECK:         %[[VAL_280:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_281:.*]] = getelementptr inbounds float, float* %[[VAL_280]], i32 %[[VAL_274]]
// CHECK:         %[[VAL_282:.*]] = load float, float* %[[VAL_281]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_282]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_283:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_283]], float* %[[VAL_92]], float* %[[VAL_283]])
// CHECK:         %[[VAL_284:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_285:.*]] = getelementptr inbounds float, float* %[[VAL_284]], i32 %[[VAL_274]]
// CHECK:         %[[VAL_286:.*]] = load float, float* %[[VAL_285]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_286]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_287:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_287]], float* %[[VAL_90]], float* %[[VAL_287]])
// CHECK:         %[[VAL_288:.*]] = add i32 128, %[[VAL_135]]
// CHECK:         %[[VAL_289:.*]] = add i32 %[[VAL_136]], 128
// CHECK:         %[[VAL_290:.*]] = mul nuw nsw i32 %[[VAL_289]], 1
// CHECK:         %[[VAL_291:.*]] = add nuw nsw i32 0, %[[VAL_290]]
// CHECK:         %[[VAL_292:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_293:.*]] = add nuw nsw i32 %[[VAL_291]], %[[VAL_292]]
// CHECK:         %[[VAL_294:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_295:.*]] = add nuw nsw i32 %[[VAL_293]], %[[VAL_294]]
// CHECK:         %[[VAL_296:.*]] = udiv i32 %[[VAL_295]], 1
// CHECK:         %[[VAL_297:.*]] = urem i32 %[[VAL_296]], 32
// CHECK:         %[[VAL_298:.*]] = udiv i32 %[[VAL_295]], 32
// CHECK:         %[[VAL_299:.*]] = urem i32 %[[VAL_298]], 32
// CHECK:         %[[VAL_300:.*]] = udiv i32 %[[VAL_295]], 1024
// CHECK:         %[[VAL_301:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_302:.*]] = getelementptr inbounds float, float* %[[VAL_301]], i32 %[[VAL_295]]
// CHECK:         %[[VAL_303:.*]] = load float, float* %[[VAL_302]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_303]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_304:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_304]], float* %[[VAL_92]], float* %[[VAL_304]])
// CHECK:         %[[VAL_305:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_306:.*]] = getelementptr inbounds float, float* %[[VAL_305]], i32 %[[VAL_295]]
// CHECK:         %[[VAL_307:.*]] = load float, float* %[[VAL_306]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_307]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_308:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_308]], float* %[[VAL_90]], float* %[[VAL_308]])
// CHECK:         %[[VAL_309:.*]] = add i32 129, %[[VAL_135]]
// CHECK:         %[[VAL_310:.*]] = add i32 %[[VAL_136]], 129
// CHECK:         %[[VAL_311:.*]] = mul nuw nsw i32 %[[VAL_310]], 1
// CHECK:         %[[VAL_312:.*]] = add nuw nsw i32 0, %[[VAL_311]]
// CHECK:         %[[VAL_313:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_314:.*]] = add nuw nsw i32 %[[VAL_312]], %[[VAL_313]]
// CHECK:         %[[VAL_315:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_316:.*]] = add nuw nsw i32 %[[VAL_314]], %[[VAL_315]]
// CHECK:         %[[VAL_317:.*]] = udiv i32 %[[VAL_316]], 1
// CHECK:         %[[VAL_318:.*]] = urem i32 %[[VAL_317]], 32
// CHECK:         %[[VAL_319:.*]] = udiv i32 %[[VAL_316]], 32
// CHECK:         %[[VAL_320:.*]] = urem i32 %[[VAL_319]], 32
// CHECK:         %[[VAL_321:.*]] = udiv i32 %[[VAL_316]], 1024
// CHECK:         %[[VAL_322:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_323:.*]] = getelementptr inbounds float, float* %[[VAL_322]], i32 %[[VAL_316]]
// CHECK:         %[[VAL_324:.*]] = load float, float* %[[VAL_323]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_324]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_325:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_325]], float* %[[VAL_92]], float* %[[VAL_325]])
// CHECK:         %[[VAL_326:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_327:.*]] = getelementptr inbounds float, float* %[[VAL_326]], i32 %[[VAL_316]]
// CHECK:         %[[VAL_328:.*]] = load float, float* %[[VAL_327]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_328]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_329:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_329]], float* %[[VAL_90]], float* %[[VAL_329]])
// CHECK:         %[[VAL_330:.*]] = add i32 192, %[[VAL_135]]
// CHECK:         %[[VAL_331:.*]] = add i32 %[[VAL_136]], 192
// CHECK:         %[[VAL_332:.*]] = mul nuw nsw i32 %[[VAL_331]], 1
// CHECK:         %[[VAL_333:.*]] = add nuw nsw i32 0, %[[VAL_332]]
// CHECK:         %[[VAL_334:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_335:.*]] = add nuw nsw i32 %[[VAL_333]], %[[VAL_334]]
// CHECK:         %[[VAL_336:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_337:.*]] = add nuw nsw i32 %[[VAL_335]], %[[VAL_336]]
// CHECK:         %[[VAL_338:.*]] = udiv i32 %[[VAL_337]], 1
// CHECK:         %[[VAL_339:.*]] = urem i32 %[[VAL_338]], 32
// CHECK:         %[[VAL_340:.*]] = udiv i32 %[[VAL_337]], 32
// CHECK:         %[[VAL_341:.*]] = urem i32 %[[VAL_340]], 32
// CHECK:         %[[VAL_342:.*]] = udiv i32 %[[VAL_337]], 1024
// CHECK:         %[[VAL_343:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_344:.*]] = getelementptr inbounds float, float* %[[VAL_343]], i32 %[[VAL_337]]
// CHECK:         %[[VAL_345:.*]] = load float, float* %[[VAL_344]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_345]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_346:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_346]], float* %[[VAL_92]], float* %[[VAL_346]])
// CHECK:         %[[VAL_347:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_348:.*]] = getelementptr inbounds float, float* %[[VAL_347]], i32 %[[VAL_337]]
// CHECK:         %[[VAL_349:.*]] = load float, float* %[[VAL_348]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_349]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_350:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_350]], float* %[[VAL_90]], float* %[[VAL_350]])
// CHECK:         %[[VAL_351:.*]] = add i32 193, %[[VAL_135]]
// CHECK:         %[[VAL_352:.*]] = add i32 %[[VAL_136]], 193
// CHECK:         %[[VAL_353:.*]] = mul nuw nsw i32 %[[VAL_352]], 1
// CHECK:         %[[VAL_354:.*]] = add nuw nsw i32 0, %[[VAL_353]]
// CHECK:         %[[VAL_355:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_356:.*]] = add nuw nsw i32 %[[VAL_354]], %[[VAL_355]]
// CHECK:         %[[VAL_357:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_358:.*]] = add nuw nsw i32 %[[VAL_356]], %[[VAL_357]]
// CHECK:         %[[VAL_359:.*]] = udiv i32 %[[VAL_358]], 1
// CHECK:         %[[VAL_360:.*]] = urem i32 %[[VAL_359]], 32
// CHECK:         %[[VAL_361:.*]] = udiv i32 %[[VAL_358]], 32
// CHECK:         %[[VAL_362:.*]] = urem i32 %[[VAL_361]], 32
// CHECK:         %[[VAL_363:.*]] = udiv i32 %[[VAL_358]], 1024
// CHECK:         %[[VAL_364:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_365:.*]] = getelementptr inbounds float, float* %[[VAL_364]], i32 %[[VAL_358]]
// CHECK:         %[[VAL_366:.*]] = load float, float* %[[VAL_365]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_366]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_367:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_367]], float* %[[VAL_92]], float* %[[VAL_367]])
// CHECK:         %[[VAL_368:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_369:.*]] = getelementptr inbounds float, float* %[[VAL_368]], i32 %[[VAL_358]]
// CHECK:         %[[VAL_370:.*]] = load float, float* %[[VAL_369]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_370]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_371:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_371]], float* %[[VAL_90]], float* %[[VAL_371]])
// CHECK:         %[[VAL_372:.*]] = add i32 256, %[[VAL_135]]
// CHECK:         %[[VAL_373:.*]] = add i32 %[[VAL_136]], 256
// CHECK:         %[[VAL_374:.*]] = mul nuw nsw i32 %[[VAL_373]], 1
// CHECK:         %[[VAL_375:.*]] = add nuw nsw i32 0, %[[VAL_374]]
// CHECK:         %[[VAL_376:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_377:.*]] = add nuw nsw i32 %[[VAL_375]], %[[VAL_376]]
// CHECK:         %[[VAL_378:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_379:.*]] = add nuw nsw i32 %[[VAL_377]], %[[VAL_378]]
// CHECK:         %[[VAL_380:.*]] = udiv i32 %[[VAL_379]], 1
// CHECK:         %[[VAL_381:.*]] = urem i32 %[[VAL_380]], 32
// CHECK:         %[[VAL_382:.*]] = udiv i32 %[[VAL_379]], 32
// CHECK:         %[[VAL_383:.*]] = urem i32 %[[VAL_382]], 32
// CHECK:         %[[VAL_384:.*]] = udiv i32 %[[VAL_379]], 1024
// CHECK:         %[[VAL_385:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_386:.*]] = getelementptr inbounds float, float* %[[VAL_385]], i32 %[[VAL_379]]
// CHECK:         %[[VAL_387:.*]] = load float, float* %[[VAL_386]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_387]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_388:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_388]], float* %[[VAL_92]], float* %[[VAL_388]])
// CHECK:         %[[VAL_389:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_390:.*]] = getelementptr inbounds float, float* %[[VAL_389]], i32 %[[VAL_379]]
// CHECK:         %[[VAL_391:.*]] = load float, float* %[[VAL_390]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_391]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_392:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_392]], float* %[[VAL_90]], float* %[[VAL_392]])
// CHECK:         %[[VAL_393:.*]] = add i32 257, %[[VAL_135]]
// CHECK:         %[[VAL_394:.*]] = add i32 %[[VAL_136]], 257
// CHECK:         %[[VAL_395:.*]] = mul nuw nsw i32 %[[VAL_394]], 1
// CHECK:         %[[VAL_396:.*]] = add nuw nsw i32 0, %[[VAL_395]]
// CHECK:         %[[VAL_397:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_398:.*]] = add nuw nsw i32 %[[VAL_396]], %[[VAL_397]]
// CHECK:         %[[VAL_399:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_400:.*]] = add nuw nsw i32 %[[VAL_398]], %[[VAL_399]]
// CHECK:         %[[VAL_401:.*]] = udiv i32 %[[VAL_400]], 1
// CHECK:         %[[VAL_402:.*]] = urem i32 %[[VAL_401]], 32
// CHECK:         %[[VAL_403:.*]] = udiv i32 %[[VAL_400]], 32
// CHECK:         %[[VAL_404:.*]] = urem i32 %[[VAL_403]], 32
// CHECK:         %[[VAL_405:.*]] = udiv i32 %[[VAL_400]], 1024
// CHECK:         %[[VAL_406:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_407:.*]] = getelementptr inbounds float, float* %[[VAL_406]], i32 %[[VAL_400]]
// CHECK:         %[[VAL_408:.*]] = load float, float* %[[VAL_407]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_408]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_409:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_409]], float* %[[VAL_92]], float* %[[VAL_409]])
// CHECK:         %[[VAL_410:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_411:.*]] = getelementptr inbounds float, float* %[[VAL_410]], i32 %[[VAL_400]]
// CHECK:         %[[VAL_412:.*]] = load float, float* %[[VAL_411]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_412]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_413:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_413]], float* %[[VAL_90]], float* %[[VAL_413]])
// CHECK:         %[[VAL_414:.*]] = add i32 320, %[[VAL_135]]
// CHECK:         %[[VAL_415:.*]] = add i32 %[[VAL_136]], 320
// CHECK:         %[[VAL_416:.*]] = mul nuw nsw i32 %[[VAL_415]], 1
// CHECK:         %[[VAL_417:.*]] = add nuw nsw i32 0, %[[VAL_416]]
// CHECK:         %[[VAL_418:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_419:.*]] = add nuw nsw i32 %[[VAL_417]], %[[VAL_418]]
// CHECK:         %[[VAL_420:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_421:.*]] = add nuw nsw i32 %[[VAL_419]], %[[VAL_420]]
// CHECK:         %[[VAL_422:.*]] = udiv i32 %[[VAL_421]], 1
// CHECK:         %[[VAL_423:.*]] = urem i32 %[[VAL_422]], 32
// CHECK:         %[[VAL_424:.*]] = udiv i32 %[[VAL_421]], 32
// CHECK:         %[[VAL_425:.*]] = urem i32 %[[VAL_424]], 32
// CHECK:         %[[VAL_426:.*]] = udiv i32 %[[VAL_421]], 1024
// CHECK:         %[[VAL_427:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_428:.*]] = getelementptr inbounds float, float* %[[VAL_427]], i32 %[[VAL_421]]
// CHECK:         %[[VAL_429:.*]] = load float, float* %[[VAL_428]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_429]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_430:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_430]], float* %[[VAL_92]], float* %[[VAL_430]])
// CHECK:         %[[VAL_431:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_432:.*]] = getelementptr inbounds float, float* %[[VAL_431]], i32 %[[VAL_421]]
// CHECK:         %[[VAL_433:.*]] = load float, float* %[[VAL_432]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_433]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_434:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_434]], float* %[[VAL_90]], float* %[[VAL_434]])
// CHECK:         %[[VAL_435:.*]] = add i32 321, %[[VAL_135]]
// CHECK:         %[[VAL_436:.*]] = add i32 %[[VAL_136]], 321
// CHECK:         %[[VAL_437:.*]] = mul nuw nsw i32 %[[VAL_436]], 1
// CHECK:         %[[VAL_438:.*]] = add nuw nsw i32 0, %[[VAL_437]]
// CHECK:         %[[VAL_439:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_440:.*]] = add nuw nsw i32 %[[VAL_438]], %[[VAL_439]]
// CHECK:         %[[VAL_441:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_442:.*]] = add nuw nsw i32 %[[VAL_440]], %[[VAL_441]]
// CHECK:         %[[VAL_443:.*]] = udiv i32 %[[VAL_442]], 1
// CHECK:         %[[VAL_444:.*]] = urem i32 %[[VAL_443]], 32
// CHECK:         %[[VAL_445:.*]] = udiv i32 %[[VAL_442]], 32
// CHECK:         %[[VAL_446:.*]] = urem i32 %[[VAL_445]], 32
// CHECK:         %[[VAL_447:.*]] = udiv i32 %[[VAL_442]], 1024
// CHECK:         %[[VAL_448:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_449:.*]] = getelementptr inbounds float, float* %[[VAL_448]], i32 %[[VAL_442]]
// CHECK:         %[[VAL_450:.*]] = load float, float* %[[VAL_449]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_450]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_451:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_451]], float* %[[VAL_92]], float* %[[VAL_451]])
// CHECK:         %[[VAL_452:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_453:.*]] = getelementptr inbounds float, float* %[[VAL_452]], i32 %[[VAL_442]]
// CHECK:         %[[VAL_454:.*]] = load float, float* %[[VAL_453]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_454]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_455:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_455]], float* %[[VAL_90]], float* %[[VAL_455]])
// CHECK:         %[[VAL_456:.*]] = add i32 384, %[[VAL_135]]
// CHECK:         %[[VAL_457:.*]] = add i32 %[[VAL_136]], 384
// CHECK:         %[[VAL_458:.*]] = mul nuw nsw i32 %[[VAL_457]], 1
// CHECK:         %[[VAL_459:.*]] = add nuw nsw i32 0, %[[VAL_458]]
// CHECK:         %[[VAL_460:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_461:.*]] = add nuw nsw i32 %[[VAL_459]], %[[VAL_460]]
// CHECK:         %[[VAL_462:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_463:.*]] = add nuw nsw i32 %[[VAL_461]], %[[VAL_462]]
// CHECK:         %[[VAL_464:.*]] = udiv i32 %[[VAL_463]], 1
// CHECK:         %[[VAL_465:.*]] = urem i32 %[[VAL_464]], 32
// CHECK:         %[[VAL_466:.*]] = udiv i32 %[[VAL_463]], 32
// CHECK:         %[[VAL_467:.*]] = urem i32 %[[VAL_466]], 32
// CHECK:         %[[VAL_468:.*]] = udiv i32 %[[VAL_463]], 1024
// CHECK:         %[[VAL_469:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_470:.*]] = getelementptr inbounds float, float* %[[VAL_469]], i32 %[[VAL_463]]
// CHECK:         %[[VAL_471:.*]] = load float, float* %[[VAL_470]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_471]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_472:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_472]], float* %[[VAL_92]], float* %[[VAL_472]])
// CHECK:         %[[VAL_473:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_474:.*]] = getelementptr inbounds float, float* %[[VAL_473]], i32 %[[VAL_463]]
// CHECK:         %[[VAL_475:.*]] = load float, float* %[[VAL_474]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_475]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_476:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_476]], float* %[[VAL_90]], float* %[[VAL_476]])
// CHECK:         %[[VAL_477:.*]] = add i32 385, %[[VAL_135]]
// CHECK:         %[[VAL_478:.*]] = add i32 %[[VAL_136]], 385
// CHECK:         %[[VAL_479:.*]] = mul nuw nsw i32 %[[VAL_478]], 1
// CHECK:         %[[VAL_480:.*]] = add nuw nsw i32 0, %[[VAL_479]]
// CHECK:         %[[VAL_481:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_482:.*]] = add nuw nsw i32 %[[VAL_480]], %[[VAL_481]]
// CHECK:         %[[VAL_483:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_484:.*]] = add nuw nsw i32 %[[VAL_482]], %[[VAL_483]]
// CHECK:         %[[VAL_485:.*]] = udiv i32 %[[VAL_484]], 1
// CHECK:         %[[VAL_486:.*]] = urem i32 %[[VAL_485]], 32
// CHECK:         %[[VAL_487:.*]] = udiv i32 %[[VAL_484]], 32
// CHECK:         %[[VAL_488:.*]] = urem i32 %[[VAL_487]], 32
// CHECK:         %[[VAL_489:.*]] = udiv i32 %[[VAL_484]], 1024
// CHECK:         %[[VAL_490:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_491:.*]] = getelementptr inbounds float, float* %[[VAL_490]], i32 %[[VAL_484]]
// CHECK:         %[[VAL_492:.*]] = load float, float* %[[VAL_491]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_492]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_493:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_493]], float* %[[VAL_92]], float* %[[VAL_493]])
// CHECK:         %[[VAL_494:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_495:.*]] = getelementptr inbounds float, float* %[[VAL_494]], i32 %[[VAL_484]]
// CHECK:         %[[VAL_496:.*]] = load float, float* %[[VAL_495]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_496]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_497:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_497]], float* %[[VAL_90]], float* %[[VAL_497]])
// CHECK:         %[[VAL_498:.*]] = add i32 448, %[[VAL_135]]
// CHECK:         %[[VAL_499:.*]] = add i32 %[[VAL_136]], 448
// CHECK:         %[[VAL_500:.*]] = mul nuw nsw i32 %[[VAL_499]], 1
// CHECK:         %[[VAL_501:.*]] = add nuw nsw i32 0, %[[VAL_500]]
// CHECK:         %[[VAL_502:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_503:.*]] = add nuw nsw i32 %[[VAL_501]], %[[VAL_502]]
// CHECK:         %[[VAL_504:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_505:.*]] = add nuw nsw i32 %[[VAL_503]], %[[VAL_504]]
// CHECK:         %[[VAL_506:.*]] = udiv i32 %[[VAL_505]], 1
// CHECK:         %[[VAL_507:.*]] = urem i32 %[[VAL_506]], 32
// CHECK:         %[[VAL_508:.*]] = udiv i32 %[[VAL_505]], 32
// CHECK:         %[[VAL_509:.*]] = urem i32 %[[VAL_508]], 32
// CHECK:         %[[VAL_510:.*]] = udiv i32 %[[VAL_505]], 1024
// CHECK:         %[[VAL_511:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_512:.*]] = getelementptr inbounds float, float* %[[VAL_511]], i32 %[[VAL_505]]
// CHECK:         %[[VAL_513:.*]] = load float, float* %[[VAL_512]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_513]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_514:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_514]], float* %[[VAL_92]], float* %[[VAL_514]])
// CHECK:         %[[VAL_515:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_516:.*]] = getelementptr inbounds float, float* %[[VAL_515]], i32 %[[VAL_505]]
// CHECK:         %[[VAL_517:.*]] = load float, float* %[[VAL_516]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_517]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_518:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_518]], float* %[[VAL_90]], float* %[[VAL_518]])
// CHECK:         %[[VAL_519:.*]] = add i32 449, %[[VAL_135]]
// CHECK:         %[[VAL_520:.*]] = add i32 %[[VAL_136]], 449
// CHECK:         %[[VAL_521:.*]] = mul nuw nsw i32 %[[VAL_520]], 1
// CHECK:         %[[VAL_522:.*]] = add nuw nsw i32 0, %[[VAL_521]]
// CHECK:         %[[VAL_523:.*]] = mul nuw nsw i32 %[[VAL_203]], 32
// CHECK:         %[[VAL_524:.*]] = add nuw nsw i32 %[[VAL_522]], %[[VAL_523]]
// CHECK:         %[[VAL_525:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_526:.*]] = add nuw nsw i32 %[[VAL_524]], %[[VAL_525]]
// CHECK:         %[[VAL_527:.*]] = udiv i32 %[[VAL_526]], 1
// CHECK:         %[[VAL_528:.*]] = urem i32 %[[VAL_527]], 32
// CHECK:         %[[VAL_529:.*]] = udiv i32 %[[VAL_526]], 32
// CHECK:         %[[VAL_530:.*]] = urem i32 %[[VAL_529]], 32
// CHECK:         %[[VAL_531:.*]] = udiv i32 %[[VAL_526]], 1024
// CHECK:         %[[VAL_532:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_533:.*]] = getelementptr inbounds float, float* %[[VAL_532]], i32 %[[VAL_526]]
// CHECK:         %[[VAL_534:.*]] = load float, float* %[[VAL_533]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_534]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_535:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_535]], float* %[[VAL_92]], float* %[[VAL_535]])
// CHECK:         %[[VAL_536:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_537:.*]] = getelementptr inbounds float, float* %[[VAL_536]], i32 %[[VAL_526]]
// CHECK:         %[[VAL_538:.*]] = load float, float* %[[VAL_537]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_538]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_539:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_539]], float* %[[VAL_90]], float* %[[VAL_539]])
// CHECK:         br label %[[VAL_138]]
// CHECK:       output_is_full_tile-false:                        ; preds = %[[VAL_142]]
// CHECK:         %[[VAL_540:.*]] = add i32 %[[VAL_133]], %[[VAL_139]]
// CHECK:         %[[VAL_541:.*]] = add i32 0, %[[VAL_135]]
// CHECK:         %[[VAL_542:.*]] = add i32 %[[VAL_136]], 0
// CHECK:         %[[VAL_543:.*]] = icmp ult i32 %[[VAL_541]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_543]], label %[[VAL_544:.*]], label %[[VAL_545:.*]]
// CHECK:       output_x_in_tile-after:                           ; preds = %[[VAL_544]], %[[VAL_147]]
// CHECK:         %[[VAL_546:.*]] = add i32 1, %[[VAL_135]]
// CHECK:         %[[VAL_547:.*]] = add i32 %[[VAL_136]], 1
// CHECK:         %[[VAL_548:.*]] = icmp ult i32 %[[VAL_546]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_548]], label %[[VAL_549:.*]], label %[[VAL_550:.*]]
// CHECK:       output_x_in_tile-after88:                         ; preds = %[[VAL_549]], %[[VAL_545]]
// CHECK:         %[[VAL_551:.*]] = add i32 64, %[[VAL_135]]
// CHECK:         %[[VAL_552:.*]] = add i32 %[[VAL_136]], 64
// CHECK:         %[[VAL_553:.*]] = icmp ult i32 %[[VAL_551]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_553]], label %[[VAL_554:.*]], label %[[VAL_555:.*]]
// CHECK:       output_x_in_tile-after95:                         ; preds = %[[VAL_554]], %[[VAL_550]]
// CHECK:         %[[VAL_556:.*]] = add i32 65, %[[VAL_135]]
// CHECK:         %[[VAL_557:.*]] = add i32 %[[VAL_136]], 65
// CHECK:         %[[VAL_558:.*]] = icmp ult i32 %[[VAL_556]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_558]], label %[[VAL_559:.*]], label %[[VAL_560:.*]]
// CHECK:       output_x_in_tile-after102:                        ; preds = %[[VAL_559]], %[[VAL_555]]
// CHECK:         %[[VAL_561:.*]] = add i32 128, %[[VAL_135]]
// CHECK:         %[[VAL_562:.*]] = add i32 %[[VAL_136]], 128
// CHECK:         %[[VAL_563:.*]] = icmp ult i32 %[[VAL_561]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_563]], label %[[VAL_564:.*]], label %[[VAL_565:.*]]
// CHECK:       output_x_in_tile-after109:                        ; preds = %[[VAL_564]], %[[VAL_560]]
// CHECK:         %[[VAL_566:.*]] = add i32 129, %[[VAL_135]]
// CHECK:         %[[VAL_567:.*]] = add i32 %[[VAL_136]], 129
// CHECK:         %[[VAL_568:.*]] = icmp ult i32 %[[VAL_566]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_568]], label %[[VAL_569:.*]], label %[[VAL_570:.*]]
// CHECK:       output_x_in_tile-after116:                        ; preds = %[[VAL_569]], %[[VAL_565]]
// CHECK:         %[[VAL_571:.*]] = add i32 192, %[[VAL_135]]
// CHECK:         %[[VAL_572:.*]] = add i32 %[[VAL_136]], 192
// CHECK:         %[[VAL_573:.*]] = icmp ult i32 %[[VAL_571]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_573]], label %[[VAL_574:.*]], label %[[VAL_575:.*]]
// CHECK:       output_x_in_tile-after123:                        ; preds = %[[VAL_574]], %[[VAL_570]]
// CHECK:         %[[VAL_576:.*]] = add i32 193, %[[VAL_135]]
// CHECK:         %[[VAL_577:.*]] = add i32 %[[VAL_136]], 193
// CHECK:         %[[VAL_578:.*]] = icmp ult i32 %[[VAL_576]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_578]], label %[[VAL_579:.*]], label %[[VAL_580:.*]]
// CHECK:       output_x_in_tile-after130:                        ; preds = %[[VAL_579]], %[[VAL_575]]
// CHECK:         %[[VAL_581:.*]] = add i32 256, %[[VAL_135]]
// CHECK:         %[[VAL_582:.*]] = add i32 %[[VAL_136]], 256
// CHECK:         %[[VAL_583:.*]] = icmp ult i32 %[[VAL_581]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_583]], label %[[VAL_584:.*]], label %[[VAL_585:.*]]
// CHECK:       output_x_in_tile-after137:                        ; preds = %[[VAL_584]], %[[VAL_580]]
// CHECK:         %[[VAL_586:.*]] = add i32 257, %[[VAL_135]]
// CHECK:         %[[VAL_587:.*]] = add i32 %[[VAL_136]], 257
// CHECK:         %[[VAL_588:.*]] = icmp ult i32 %[[VAL_586]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_588]], label %[[VAL_589:.*]], label %[[VAL_590:.*]]
// CHECK:       output_x_in_tile-after144:                        ; preds = %[[VAL_589]], %[[VAL_585]]
// CHECK:         %[[VAL_591:.*]] = add i32 320, %[[VAL_135]]
// CHECK:         %[[VAL_592:.*]] = add i32 %[[VAL_136]], 320
// CHECK:         %[[VAL_593:.*]] = icmp ult i32 %[[VAL_591]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_593]], label %[[VAL_594:.*]], label %[[VAL_595:.*]]
// CHECK:       output_x_in_tile-after151:                        ; preds = %[[VAL_594]], %[[VAL_590]]
// CHECK:         %[[VAL_596:.*]] = add i32 321, %[[VAL_135]]
// CHECK:         %[[VAL_597:.*]] = add i32 %[[VAL_136]], 321
// CHECK:         %[[VAL_598:.*]] = icmp ult i32 %[[VAL_596]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_598]], label %[[VAL_599:.*]], label %[[VAL_600:.*]]
// CHECK:       output_x_in_tile-after158:                        ; preds = %[[VAL_599]], %[[VAL_595]]
// CHECK:         %[[VAL_601:.*]] = add i32 384, %[[VAL_135]]
// CHECK:         %[[VAL_602:.*]] = add i32 %[[VAL_136]], 384
// CHECK:         %[[VAL_603:.*]] = icmp ult i32 %[[VAL_601]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_603]], label %[[VAL_604:.*]], label %[[VAL_605:.*]]
// CHECK:       output_x_in_tile-after165:                        ; preds = %[[VAL_604]], %[[VAL_600]]
// CHECK:         %[[VAL_606:.*]] = add i32 385, %[[VAL_135]]
// CHECK:         %[[VAL_607:.*]] = add i32 %[[VAL_136]], 385
// CHECK:         %[[VAL_608:.*]] = icmp ult i32 %[[VAL_606]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_608]], label %[[VAL_609:.*]], label %[[VAL_610:.*]]
// CHECK:       output_x_in_tile-after172:                        ; preds = %[[VAL_609]], %[[VAL_605]]
// CHECK:         %[[VAL_611:.*]] = add i32 448, %[[VAL_135]]
// CHECK:         %[[VAL_612:.*]] = add i32 %[[VAL_136]], 448
// CHECK:         %[[VAL_613:.*]] = icmp ult i32 %[[VAL_611]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_613]], label %[[VAL_614:.*]], label %[[VAL_615:.*]]
// CHECK:       output_x_in_tile-after179:                        ; preds = %[[VAL_614]], %[[VAL_610]]
// CHECK:         %[[VAL_616:.*]] = add i32 449, %[[VAL_135]]
// CHECK:         %[[VAL_617:.*]] = add i32 %[[VAL_136]], 449
// CHECK:         %[[VAL_618:.*]] = icmp ult i32 %[[VAL_616]], %[[VAL_132]]
// CHECK:         br i1 %[[VAL_618]], label %[[VAL_619:.*]], label %[[VAL_148]]
// CHECK:       output_x_in_tile-after186:                        ; preds = %[[VAL_619]], %[[VAL_615]]
// CHECK:         br label %[[VAL_138]]
// CHECK:       output_x_in_tile-true:                            ; preds = %[[VAL_147]]
// CHECK:         %[[VAL_620:.*]] = mul nuw nsw i32 %[[VAL_542]], 1
// CHECK:         %[[VAL_621:.*]] = add nuw nsw i32 0, %[[VAL_620]]
// CHECK:         %[[VAL_622:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_623:.*]] = add nuw nsw i32 %[[VAL_621]], %[[VAL_622]]
// CHECK:         %[[VAL_624:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_625:.*]] = add nuw nsw i32 %[[VAL_623]], %[[VAL_624]]
// CHECK:         %[[VAL_626:.*]] = udiv i32 %[[VAL_625]], 1
// CHECK:         %[[VAL_627:.*]] = urem i32 %[[VAL_626]], 32
// CHECK:         %[[VAL_628:.*]] = udiv i32 %[[VAL_625]], 32
// CHECK:         %[[VAL_629:.*]] = urem i32 %[[VAL_628]], 32
// CHECK:         %[[VAL_630:.*]] = udiv i32 %[[VAL_625]], 1024
// CHECK:         %[[VAL_631:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_632:.*]] = getelementptr inbounds float, float* %[[VAL_631]], i32 %[[VAL_625]]
// CHECK:         %[[VAL_633:.*]] = load float, float* %[[VAL_632]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_633]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_634:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_634]], float* %[[VAL_92]], float* %[[VAL_634]])
// CHECK:         %[[VAL_635:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_636:.*]] = getelementptr inbounds float, float* %[[VAL_635]], i32 %[[VAL_625]]
// CHECK:         %[[VAL_637:.*]] = load float, float* %[[VAL_636]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_637]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_638:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_638]], float* %[[VAL_90]], float* %[[VAL_638]])
// CHECK:         br label %[[VAL_545]]
// CHECK:       output_x_in_tile-true87:                          ; preds = %[[VAL_545]]
// CHECK:         %[[VAL_639:.*]] = mul nuw nsw i32 %[[VAL_547]], 1
// CHECK:         %[[VAL_640:.*]] = add nuw nsw i32 0, %[[VAL_639]]
// CHECK:         %[[VAL_641:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_642:.*]] = add nuw nsw i32 %[[VAL_640]], %[[VAL_641]]
// CHECK:         %[[VAL_643:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_644:.*]] = add nuw nsw i32 %[[VAL_642]], %[[VAL_643]]
// CHECK:         %[[VAL_645:.*]] = udiv i32 %[[VAL_644]], 1
// CHECK:         %[[VAL_646:.*]] = urem i32 %[[VAL_645]], 32
// CHECK:         %[[VAL_647:.*]] = udiv i32 %[[VAL_644]], 32
// CHECK:         %[[VAL_648:.*]] = urem i32 %[[VAL_647]], 32
// CHECK:         %[[VAL_649:.*]] = udiv i32 %[[VAL_644]], 1024
// CHECK:         %[[VAL_650:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_651:.*]] = getelementptr inbounds float, float* %[[VAL_650]], i32 %[[VAL_644]]
// CHECK:         %[[VAL_652:.*]] = load float, float* %[[VAL_651]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_652]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_653:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_653]], float* %[[VAL_92]], float* %[[VAL_653]])
// CHECK:         %[[VAL_654:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_655:.*]] = getelementptr inbounds float, float* %[[VAL_654]], i32 %[[VAL_644]]
// CHECK:         %[[VAL_656:.*]] = load float, float* %[[VAL_655]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_656]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_657:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_657]], float* %[[VAL_90]], float* %[[VAL_657]])
// CHECK:         br label %[[VAL_550]]
// CHECK:       output_x_in_tile-true94:                          ; preds = %[[VAL_550]]
// CHECK:         %[[VAL_658:.*]] = mul nuw nsw i32 %[[VAL_552]], 1
// CHECK:         %[[VAL_659:.*]] = add nuw nsw i32 0, %[[VAL_658]]
// CHECK:         %[[VAL_660:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_661:.*]] = add nuw nsw i32 %[[VAL_659]], %[[VAL_660]]
// CHECK:         %[[VAL_662:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_663:.*]] = add nuw nsw i32 %[[VAL_661]], %[[VAL_662]]
// CHECK:         %[[VAL_664:.*]] = udiv i32 %[[VAL_663]], 1
// CHECK:         %[[VAL_665:.*]] = urem i32 %[[VAL_664]], 32
// CHECK:         %[[VAL_666:.*]] = udiv i32 %[[VAL_663]], 32
// CHECK:         %[[VAL_667:.*]] = urem i32 %[[VAL_666]], 32
// CHECK:         %[[VAL_668:.*]] = udiv i32 %[[VAL_663]], 1024
// CHECK:         %[[VAL_669:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_670:.*]] = getelementptr inbounds float, float* %[[VAL_669]], i32 %[[VAL_663]]
// CHECK:         %[[VAL_671:.*]] = load float, float* %[[VAL_670]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_671]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_672:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_672]], float* %[[VAL_92]], float* %[[VAL_672]])
// CHECK:         %[[VAL_673:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_674:.*]] = getelementptr inbounds float, float* %[[VAL_673]], i32 %[[VAL_663]]
// CHECK:         %[[VAL_675:.*]] = load float, float* %[[VAL_674]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_675]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_676:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_676]], float* %[[VAL_90]], float* %[[VAL_676]])
// CHECK:         br label %[[VAL_555]]
// CHECK:       output_x_in_tile-true101:                         ; preds = %[[VAL_555]]
// CHECK:         %[[VAL_677:.*]] = mul nuw nsw i32 %[[VAL_557]], 1
// CHECK:         %[[VAL_678:.*]] = add nuw nsw i32 0, %[[VAL_677]]
// CHECK:         %[[VAL_679:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_680:.*]] = add nuw nsw i32 %[[VAL_678]], %[[VAL_679]]
// CHECK:         %[[VAL_681:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_682:.*]] = add nuw nsw i32 %[[VAL_680]], %[[VAL_681]]
// CHECK:         %[[VAL_683:.*]] = udiv i32 %[[VAL_682]], 1
// CHECK:         %[[VAL_684:.*]] = urem i32 %[[VAL_683]], 32
// CHECK:         %[[VAL_685:.*]] = udiv i32 %[[VAL_682]], 32
// CHECK:         %[[VAL_686:.*]] = urem i32 %[[VAL_685]], 32
// CHECK:         %[[VAL_687:.*]] = udiv i32 %[[VAL_682]], 1024
// CHECK:         %[[VAL_688:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_689:.*]] = getelementptr inbounds float, float* %[[VAL_688]], i32 %[[VAL_682]]
// CHECK:         %[[VAL_690:.*]] = load float, float* %[[VAL_689]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_690]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_691:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_691]], float* %[[VAL_92]], float* %[[VAL_691]])
// CHECK:         %[[VAL_692:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_693:.*]] = getelementptr inbounds float, float* %[[VAL_692]], i32 %[[VAL_682]]
// CHECK:         %[[VAL_694:.*]] = load float, float* %[[VAL_693]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_694]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_695:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_695]], float* %[[VAL_90]], float* %[[VAL_695]])
// CHECK:         br label %[[VAL_560]]
// CHECK:       output_x_in_tile-true108:                         ; preds = %[[VAL_560]]
// CHECK:         %[[VAL_696:.*]] = mul nuw nsw i32 %[[VAL_562]], 1
// CHECK:         %[[VAL_697:.*]] = add nuw nsw i32 0, %[[VAL_696]]
// CHECK:         %[[VAL_698:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_699:.*]] = add nuw nsw i32 %[[VAL_697]], %[[VAL_698]]
// CHECK:         %[[VAL_700:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_701:.*]] = add nuw nsw i32 %[[VAL_699]], %[[VAL_700]]
// CHECK:         %[[VAL_702:.*]] = udiv i32 %[[VAL_701]], 1
// CHECK:         %[[VAL_703:.*]] = urem i32 %[[VAL_702]], 32
// CHECK:         %[[VAL_704:.*]] = udiv i32 %[[VAL_701]], 32
// CHECK:         %[[VAL_705:.*]] = urem i32 %[[VAL_704]], 32
// CHECK:         %[[VAL_706:.*]] = udiv i32 %[[VAL_701]], 1024
// CHECK:         %[[VAL_707:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_708:.*]] = getelementptr inbounds float, float* %[[VAL_707]], i32 %[[VAL_701]]
// CHECK:         %[[VAL_709:.*]] = load float, float* %[[VAL_708]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_709]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_710:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_710]], float* %[[VAL_92]], float* %[[VAL_710]])
// CHECK:         %[[VAL_711:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_712:.*]] = getelementptr inbounds float, float* %[[VAL_711]], i32 %[[VAL_701]]
// CHECK:         %[[VAL_713:.*]] = load float, float* %[[VAL_712]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_713]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_714:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_714]], float* %[[VAL_90]], float* %[[VAL_714]])
// CHECK:         br label %[[VAL_565]]
// CHECK:       output_x_in_tile-true115:                         ; preds = %[[VAL_565]]
// CHECK:         %[[VAL_715:.*]] = mul nuw nsw i32 %[[VAL_567]], 1
// CHECK:         %[[VAL_716:.*]] = add nuw nsw i32 0, %[[VAL_715]]
// CHECK:         %[[VAL_717:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_718:.*]] = add nuw nsw i32 %[[VAL_716]], %[[VAL_717]]
// CHECK:         %[[VAL_719:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_720:.*]] = add nuw nsw i32 %[[VAL_718]], %[[VAL_719]]
// CHECK:         %[[VAL_721:.*]] = udiv i32 %[[VAL_720]], 1
// CHECK:         %[[VAL_722:.*]] = urem i32 %[[VAL_721]], 32
// CHECK:         %[[VAL_723:.*]] = udiv i32 %[[VAL_720]], 32
// CHECK:         %[[VAL_724:.*]] = urem i32 %[[VAL_723]], 32
// CHECK:         %[[VAL_725:.*]] = udiv i32 %[[VAL_720]], 1024
// CHECK:         %[[VAL_726:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_727:.*]] = getelementptr inbounds float, float* %[[VAL_726]], i32 %[[VAL_720]]
// CHECK:         %[[VAL_728:.*]] = load float, float* %[[VAL_727]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_728]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_729:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_729]], float* %[[VAL_92]], float* %[[VAL_729]])
// CHECK:         %[[VAL_730:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_731:.*]] = getelementptr inbounds float, float* %[[VAL_730]], i32 %[[VAL_720]]
// CHECK:         %[[VAL_732:.*]] = load float, float* %[[VAL_731]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_732]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_733:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_733]], float* %[[VAL_90]], float* %[[VAL_733]])
// CHECK:         br label %[[VAL_570]]
// CHECK:       output_x_in_tile-true122:                         ; preds = %[[VAL_570]]
// CHECK:         %[[VAL_734:.*]] = mul nuw nsw i32 %[[VAL_572]], 1
// CHECK:         %[[VAL_735:.*]] = add nuw nsw i32 0, %[[VAL_734]]
// CHECK:         %[[VAL_736:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_737:.*]] = add nuw nsw i32 %[[VAL_735]], %[[VAL_736]]
// CHECK:         %[[VAL_738:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_739:.*]] = add nuw nsw i32 %[[VAL_737]], %[[VAL_738]]
// CHECK:         %[[VAL_740:.*]] = udiv i32 %[[VAL_739]], 1
// CHECK:         %[[VAL_741:.*]] = urem i32 %[[VAL_740]], 32
// CHECK:         %[[VAL_742:.*]] = udiv i32 %[[VAL_739]], 32
// CHECK:         %[[VAL_743:.*]] = urem i32 %[[VAL_742]], 32
// CHECK:         %[[VAL_744:.*]] = udiv i32 %[[VAL_739]], 1024
// CHECK:         %[[VAL_745:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_746:.*]] = getelementptr inbounds float, float* %[[VAL_745]], i32 %[[VAL_739]]
// CHECK:         %[[VAL_747:.*]] = load float, float* %[[VAL_746]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_747]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_748:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_748]], float* %[[VAL_92]], float* %[[VAL_748]])
// CHECK:         %[[VAL_749:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_750:.*]] = getelementptr inbounds float, float* %[[VAL_749]], i32 %[[VAL_739]]
// CHECK:         %[[VAL_751:.*]] = load float, float* %[[VAL_750]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_751]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_752:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_752]], float* %[[VAL_90]], float* %[[VAL_752]])
// CHECK:         br label %[[VAL_575]]
// CHECK:       output_x_in_tile-true129:                         ; preds = %[[VAL_575]]
// CHECK:         %[[VAL_753:.*]] = mul nuw nsw i32 %[[VAL_577]], 1
// CHECK:         %[[VAL_754:.*]] = add nuw nsw i32 0, %[[VAL_753]]
// CHECK:         %[[VAL_755:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_756:.*]] = add nuw nsw i32 %[[VAL_754]], %[[VAL_755]]
// CHECK:         %[[VAL_757:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_758:.*]] = add nuw nsw i32 %[[VAL_756]], %[[VAL_757]]
// CHECK:         %[[VAL_759:.*]] = udiv i32 %[[VAL_758]], 1
// CHECK:         %[[VAL_760:.*]] = urem i32 %[[VAL_759]], 32
// CHECK:         %[[VAL_761:.*]] = udiv i32 %[[VAL_758]], 32
// CHECK:         %[[VAL_762:.*]] = urem i32 %[[VAL_761]], 32
// CHECK:         %[[VAL_763:.*]] = udiv i32 %[[VAL_758]], 1024
// CHECK:         %[[VAL_764:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_765:.*]] = getelementptr inbounds float, float* %[[VAL_764]], i32 %[[VAL_758]]
// CHECK:         %[[VAL_766:.*]] = load float, float* %[[VAL_765]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_766]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_767:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_767]], float* %[[VAL_92]], float* %[[VAL_767]])
// CHECK:         %[[VAL_768:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_769:.*]] = getelementptr inbounds float, float* %[[VAL_768]], i32 %[[VAL_758]]
// CHECK:         %[[VAL_770:.*]] = load float, float* %[[VAL_769]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_770]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_771:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_771]], float* %[[VAL_90]], float* %[[VAL_771]])
// CHECK:         br label %[[VAL_580]]
// CHECK:       output_x_in_tile-true136:                         ; preds = %[[VAL_580]]
// CHECK:         %[[VAL_772:.*]] = mul nuw nsw i32 %[[VAL_582]], 1
// CHECK:         %[[VAL_773:.*]] = add nuw nsw i32 0, %[[VAL_772]]
// CHECK:         %[[VAL_774:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_775:.*]] = add nuw nsw i32 %[[VAL_773]], %[[VAL_774]]
// CHECK:         %[[VAL_776:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_777:.*]] = add nuw nsw i32 %[[VAL_775]], %[[VAL_776]]
// CHECK:         %[[VAL_778:.*]] = udiv i32 %[[VAL_777]], 1
// CHECK:         %[[VAL_779:.*]] = urem i32 %[[VAL_778]], 32
// CHECK:         %[[VAL_780:.*]] = udiv i32 %[[VAL_777]], 32
// CHECK:         %[[VAL_781:.*]] = urem i32 %[[VAL_780]], 32
// CHECK:         %[[VAL_782:.*]] = udiv i32 %[[VAL_777]], 1024
// CHECK:         %[[VAL_783:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_784:.*]] = getelementptr inbounds float, float* %[[VAL_783]], i32 %[[VAL_777]]
// CHECK:         %[[VAL_785:.*]] = load float, float* %[[VAL_784]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_785]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_786:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_786]], float* %[[VAL_92]], float* %[[VAL_786]])
// CHECK:         %[[VAL_787:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_788:.*]] = getelementptr inbounds float, float* %[[VAL_787]], i32 %[[VAL_777]]
// CHECK:         %[[VAL_789:.*]] = load float, float* %[[VAL_788]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_789]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_790:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_790]], float* %[[VAL_90]], float* %[[VAL_790]])
// CHECK:         br label %[[VAL_585]]
// CHECK:       output_x_in_tile-true143:                         ; preds = %[[VAL_585]]
// CHECK:         %[[VAL_791:.*]] = mul nuw nsw i32 %[[VAL_587]], 1
// CHECK:         %[[VAL_792:.*]] = add nuw nsw i32 0, %[[VAL_791]]
// CHECK:         %[[VAL_793:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_794:.*]] = add nuw nsw i32 %[[VAL_792]], %[[VAL_793]]
// CHECK:         %[[VAL_795:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_796:.*]] = add nuw nsw i32 %[[VAL_794]], %[[VAL_795]]
// CHECK:         %[[VAL_797:.*]] = udiv i32 %[[VAL_796]], 1
// CHECK:         %[[VAL_798:.*]] = urem i32 %[[VAL_797]], 32
// CHECK:         %[[VAL_799:.*]] = udiv i32 %[[VAL_796]], 32
// CHECK:         %[[VAL_800:.*]] = urem i32 %[[VAL_799]], 32
// CHECK:         %[[VAL_801:.*]] = udiv i32 %[[VAL_796]], 1024
// CHECK:         %[[VAL_802:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_803:.*]] = getelementptr inbounds float, float* %[[VAL_802]], i32 %[[VAL_796]]
// CHECK:         %[[VAL_804:.*]] = load float, float* %[[VAL_803]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_804]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_805:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_805]], float* %[[VAL_92]], float* %[[VAL_805]])
// CHECK:         %[[VAL_806:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_807:.*]] = getelementptr inbounds float, float* %[[VAL_806]], i32 %[[VAL_796]]
// CHECK:         %[[VAL_808:.*]] = load float, float* %[[VAL_807]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_808]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_809:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_809]], float* %[[VAL_90]], float* %[[VAL_809]])
// CHECK:         br label %[[VAL_590]]
// CHECK:       output_x_in_tile-true150:                         ; preds = %[[VAL_590]]
// CHECK:         %[[VAL_810:.*]] = mul nuw nsw i32 %[[VAL_592]], 1
// CHECK:         %[[VAL_811:.*]] = add nuw nsw i32 0, %[[VAL_810]]
// CHECK:         %[[VAL_812:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_813:.*]] = add nuw nsw i32 %[[VAL_811]], %[[VAL_812]]
// CHECK:         %[[VAL_814:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_815:.*]] = add nuw nsw i32 %[[VAL_813]], %[[VAL_814]]
// CHECK:         %[[VAL_816:.*]] = udiv i32 %[[VAL_815]], 1
// CHECK:         %[[VAL_817:.*]] = urem i32 %[[VAL_816]], 32
// CHECK:         %[[VAL_818:.*]] = udiv i32 %[[VAL_815]], 32
// CHECK:         %[[VAL_819:.*]] = urem i32 %[[VAL_818]], 32
// CHECK:         %[[VAL_820:.*]] = udiv i32 %[[VAL_815]], 1024
// CHECK:         %[[VAL_821:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_822:.*]] = getelementptr inbounds float, float* %[[VAL_821]], i32 %[[VAL_815]]
// CHECK:         %[[VAL_823:.*]] = load float, float* %[[VAL_822]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_823]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_824:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_824]], float* %[[VAL_92]], float* %[[VAL_824]])
// CHECK:         %[[VAL_825:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_826:.*]] = getelementptr inbounds float, float* %[[VAL_825]], i32 %[[VAL_815]]
// CHECK:         %[[VAL_827:.*]] = load float, float* %[[VAL_826]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_827]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_828:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_828]], float* %[[VAL_90]], float* %[[VAL_828]])
// CHECK:         br label %[[VAL_595]]
// CHECK:       output_x_in_tile-true157:                         ; preds = %[[VAL_595]]
// CHECK:         %[[VAL_829:.*]] = mul nuw nsw i32 %[[VAL_597]], 1
// CHECK:         %[[VAL_830:.*]] = add nuw nsw i32 0, %[[VAL_829]]
// CHECK:         %[[VAL_831:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_832:.*]] = add nuw nsw i32 %[[VAL_830]], %[[VAL_831]]
// CHECK:         %[[VAL_833:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_834:.*]] = add nuw nsw i32 %[[VAL_832]], %[[VAL_833]]
// CHECK:         %[[VAL_835:.*]] = udiv i32 %[[VAL_834]], 1
// CHECK:         %[[VAL_836:.*]] = urem i32 %[[VAL_835]], 32
// CHECK:         %[[VAL_837:.*]] = udiv i32 %[[VAL_834]], 32
// CHECK:         %[[VAL_838:.*]] = urem i32 %[[VAL_837]], 32
// CHECK:         %[[VAL_839:.*]] = udiv i32 %[[VAL_834]], 1024
// CHECK:         %[[VAL_840:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_841:.*]] = getelementptr inbounds float, float* %[[VAL_840]], i32 %[[VAL_834]]
// CHECK:         %[[VAL_842:.*]] = load float, float* %[[VAL_841]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_842]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_843:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_843]], float* %[[VAL_92]], float* %[[VAL_843]])
// CHECK:         %[[VAL_844:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_845:.*]] = getelementptr inbounds float, float* %[[VAL_844]], i32 %[[VAL_834]]
// CHECK:         %[[VAL_846:.*]] = load float, float* %[[VAL_845]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_846]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_847:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_847]], float* %[[VAL_90]], float* %[[VAL_847]])
// CHECK:         br label %[[VAL_600]]
// CHECK:       output_x_in_tile-true164:                         ; preds = %[[VAL_600]]
// CHECK:         %[[VAL_848:.*]] = mul nuw nsw i32 %[[VAL_602]], 1
// CHECK:         %[[VAL_849:.*]] = add nuw nsw i32 0, %[[VAL_848]]
// CHECK:         %[[VAL_850:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_851:.*]] = add nuw nsw i32 %[[VAL_849]], %[[VAL_850]]
// CHECK:         %[[VAL_852:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_853:.*]] = add nuw nsw i32 %[[VAL_851]], %[[VAL_852]]
// CHECK:         %[[VAL_854:.*]] = udiv i32 %[[VAL_853]], 1
// CHECK:         %[[VAL_855:.*]] = urem i32 %[[VAL_854]], 32
// CHECK:         %[[VAL_856:.*]] = udiv i32 %[[VAL_853]], 32
// CHECK:         %[[VAL_857:.*]] = urem i32 %[[VAL_856]], 32
// CHECK:         %[[VAL_858:.*]] = udiv i32 %[[VAL_853]], 1024
// CHECK:         %[[VAL_859:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_860:.*]] = getelementptr inbounds float, float* %[[VAL_859]], i32 %[[VAL_853]]
// CHECK:         %[[VAL_861:.*]] = load float, float* %[[VAL_860]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_861]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_862:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_862]], float* %[[VAL_92]], float* %[[VAL_862]])
// CHECK:         %[[VAL_863:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_864:.*]] = getelementptr inbounds float, float* %[[VAL_863]], i32 %[[VAL_853]]
// CHECK:         %[[VAL_865:.*]] = load float, float* %[[VAL_864]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_865]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_866:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_866]], float* %[[VAL_90]], float* %[[VAL_866]])
// CHECK:         br label %[[VAL_605]]
// CHECK:       output_x_in_tile-true171:                         ; preds = %[[VAL_605]]
// CHECK:         %[[VAL_867:.*]] = mul nuw nsw i32 %[[VAL_607]], 1
// CHECK:         %[[VAL_868:.*]] = add nuw nsw i32 0, %[[VAL_867]]
// CHECK:         %[[VAL_869:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_870:.*]] = add nuw nsw i32 %[[VAL_868]], %[[VAL_869]]
// CHECK:         %[[VAL_871:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_872:.*]] = add nuw nsw i32 %[[VAL_870]], %[[VAL_871]]
// CHECK:         %[[VAL_873:.*]] = udiv i32 %[[VAL_872]], 1
// CHECK:         %[[VAL_874:.*]] = urem i32 %[[VAL_873]], 32
// CHECK:         %[[VAL_875:.*]] = udiv i32 %[[VAL_872]], 32
// CHECK:         %[[VAL_876:.*]] = urem i32 %[[VAL_875]], 32
// CHECK:         %[[VAL_877:.*]] = udiv i32 %[[VAL_872]], 1024
// CHECK:         %[[VAL_878:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_879:.*]] = getelementptr inbounds float, float* %[[VAL_878]], i32 %[[VAL_872]]
// CHECK:         %[[VAL_880:.*]] = load float, float* %[[VAL_879]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_880]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_881:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_881]], float* %[[VAL_92]], float* %[[VAL_881]])
// CHECK:         %[[VAL_882:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_883:.*]] = getelementptr inbounds float, float* %[[VAL_882]], i32 %[[VAL_872]]
// CHECK:         %[[VAL_884:.*]] = load float, float* %[[VAL_883]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_884]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_885:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_885]], float* %[[VAL_90]], float* %[[VAL_885]])
// CHECK:         br label %[[VAL_610]]
// CHECK:       output_x_in_tile-true178:                         ; preds = %[[VAL_610]]
// CHECK:         %[[VAL_886:.*]] = mul nuw nsw i32 %[[VAL_612]], 1
// CHECK:         %[[VAL_887:.*]] = add nuw nsw i32 0, %[[VAL_886]]
// CHECK:         %[[VAL_888:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_889:.*]] = add nuw nsw i32 %[[VAL_887]], %[[VAL_888]]
// CHECK:         %[[VAL_890:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_891:.*]] = add nuw nsw i32 %[[VAL_889]], %[[VAL_890]]
// CHECK:         %[[VAL_892:.*]] = udiv i32 %[[VAL_891]], 1
// CHECK:         %[[VAL_893:.*]] = urem i32 %[[VAL_892]], 32
// CHECK:         %[[VAL_894:.*]] = udiv i32 %[[VAL_891]], 32
// CHECK:         %[[VAL_895:.*]] = urem i32 %[[VAL_894]], 32
// CHECK:         %[[VAL_896:.*]] = udiv i32 %[[VAL_891]], 1024
// CHECK:         %[[VAL_897:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_898:.*]] = getelementptr inbounds float, float* %[[VAL_897]], i32 %[[VAL_891]]
// CHECK:         %[[VAL_899:.*]] = load float, float* %[[VAL_898]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_899]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_900:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_900]], float* %[[VAL_92]], float* %[[VAL_900]])
// CHECK:         %[[VAL_901:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_902:.*]] = getelementptr inbounds float, float* %[[VAL_901]], i32 %[[VAL_891]]
// CHECK:         %[[VAL_903:.*]] = load float, float* %[[VAL_902]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_903]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_904:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_904]], float* %[[VAL_90]], float* %[[VAL_904]])
// CHECK:         br label %[[VAL_615]]
// CHECK:       output_x_in_tile-true185:                         ; preds = %[[VAL_615]]
// CHECK:         %[[VAL_905:.*]] = mul nuw nsw i32 %[[VAL_617]], 1
// CHECK:         %[[VAL_906:.*]] = add nuw nsw i32 0, %[[VAL_905]]
// CHECK:         %[[VAL_907:.*]] = mul nuw nsw i32 %[[VAL_540]], 32
// CHECK:         %[[VAL_908:.*]] = add nuw nsw i32 %[[VAL_906]], %[[VAL_907]]
// CHECK:         %[[VAL_909:.*]] = mul nuw nsw i32 %[[VAL_128]], 2048
// CHECK:         %[[VAL_910:.*]] = add nuw nsw i32 %[[VAL_908]], %[[VAL_909]]
// CHECK:         %[[VAL_911:.*]] = udiv i32 %[[VAL_910]], 1
// CHECK:         %[[VAL_912:.*]] = urem i32 %[[VAL_911]], 32
// CHECK:         %[[VAL_913:.*]] = udiv i32 %[[VAL_910]], 32
// CHECK:         %[[VAL_914:.*]] = urem i32 %[[VAL_913]], 32
// CHECK:         %[[VAL_915:.*]] = udiv i32 %[[VAL_910]], 1024
// CHECK:         %[[VAL_916:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_917:.*]] = getelementptr inbounds float, float* %[[VAL_916]], i32 %[[VAL_910]]
// CHECK:         %[[VAL_918:.*]] = load float, float* %[[VAL_917]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_918]], float* %[[VAL_92]], align 4
// CHECK:         %[[VAL_919:.*]] = getelementptr inbounds float, float* %[[VAL_91]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_919]], float* %[[VAL_92]], float* %[[VAL_919]])
// CHECK:         %[[VAL_920:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_95]] to float*
// CHECK:         %[[VAL_921:.*]] = getelementptr inbounds float, float* %[[VAL_920]], i32 %[[VAL_910]]
// CHECK:         %[[VAL_922:.*]] = load float, float* %[[VAL_921]], align 4, !invariant.load !8
// CHECK:         store float %[[VAL_922]], float* %[[VAL_90]], align 4
// CHECK:         %[[VAL_923:.*]] = getelementptr inbounds float, float* %[[VAL_89]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_923]], float* %[[VAL_90]], float* %[[VAL_923]])
// CHECK:         br label %[[VAL_148]]
// CHECK:       intra_warp_reduce_write-true:                     ; preds = %[[VAL_141]]
// CHECK:         %[[VAL_924:.*]] = getelementptr inbounds [1 x [32 x float]], [1 x [32 x float]] addrspace(3)* @shared_cache_0, i32 0, i32 0, i32 %[[VAL_172]]
// CHECK:         %[[VAL_925:.*]] = addrspacecast float addrspace(3)* %[[VAL_924]] to float*
// CHECK:         %[[VAL_926:.*]] = load float, float* %[[VAL_161]], align 4
// CHECK:         store float %[[VAL_926]], float* %[[VAL_925]], align 4
// CHECK:         br label %[[VAL_175]]
// CHECK:       inter_warp_reduce-true:                           ; preds = %[[VAL_175]]
// CHECK:         %[[VAL_927:.*]] = getelementptr inbounds [1 x [32 x float]], [1 x [32 x float]] addrspace(3)* @shared_cache_0, i32 0, i32 0, i32 %[[VAL_152]]
// CHECK:         %[[VAL_928:.*]] = addrspacecast float addrspace(3)* %[[VAL_927]] to float*
// CHECK:         store float %[[VAL_114]], float* %[[VAL_82]], align 4
// CHECK:         %[[VAL_929:.*]] = icmp ult i32 %[[VAL_150]], 1
// CHECK:         %[[VAL_930:.*]] = select i1 %[[VAL_929]], float* %[[VAL_928]], float* %[[VAL_82]]
// CHECK:         %[[VAL_931:.*]] = load float, float* %[[VAL_930]], align 4
// CHECK:         %[[VAL_932:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_931]], i32 16, i32 31)
// CHECK:         store float %[[VAL_932]], float* %[[VAL_81]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_930]], float* %[[VAL_81]], float* %[[VAL_930]])
// CHECK:         %[[VAL_933:.*]] = load float, float* %[[VAL_930]], align 4
// CHECK:         %[[VAL_934:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_933]], i32 8, i32 31)
// CHECK:         store float %[[VAL_934]], float* %[[VAL_80]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_930]], float* %[[VAL_80]], float* %[[VAL_930]])
// CHECK:         %[[VAL_935:.*]] = load float, float* %[[VAL_930]], align 4
// CHECK:         %[[VAL_936:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_935]], i32 4, i32 31)
// CHECK:         store float %[[VAL_936]], float* %[[VAL_79]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_930]], float* %[[VAL_79]], float* %[[VAL_930]])
// CHECK:         %[[VAL_937:.*]] = load float, float* %[[VAL_930]], align 4
// CHECK:         %[[VAL_938:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_937]], i32 2, i32 31)
// CHECK:         store float %[[VAL_938]], float* %[[VAL_78]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_930]], float* %[[VAL_78]], float* %[[VAL_930]])
// CHECK:         %[[VAL_939:.*]] = load float, float* %[[VAL_930]], align 4
// CHECK:         %[[VAL_940:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_939]], i32 1, i32 31)
// CHECK:         store float %[[VAL_940]], float* %[[VAL_77]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_930]], float* %[[VAL_77]], float* %[[VAL_930]])
// CHECK:         %[[VAL_941:.*]] = icmp eq i32 %[[VAL_150]], 0
// CHECK:         br i1 %[[VAL_941]], label %[[VAL_942:.*]], label %[[VAL_179]]
// CHECK:       reduction_atomic_update-after:                    ; preds = %[[VAL_942]], %[[VAL_177]]
// CHECK:         br label %[[VAL_178]]
// CHECK:       reduction_atomic_update-true:                     ; preds = %[[VAL_177]]
// CHECK:         %[[VAL_943:.*]] = load float, float* %[[VAL_928]], align 4
// CHECK:         %[[VAL_944:.*]] = atomicrmw fadd float* %[[VAL_160]], float %[[VAL_943]] seq_cst, align 4
// CHECK:         br label %[[VAL_179]]
// CHECK:       intra_warp_reduce_write-true224:                  ; preds = %[[VAL_178]]
// CHECK:         %[[VAL_945:.*]] = getelementptr inbounds [1 x [32 x float]], [1 x [32 x float]] addrspace(3)* @shared_cache_1, i32 0, i32 0, i32 %[[VAL_196]]
// CHECK:         %[[VAL_946:.*]] = addrspacecast float addrspace(3)* %[[VAL_945]] to float*
// CHECK:         %[[VAL_947:.*]] = load float, float* %[[VAL_185]], align 4
// CHECK:         store float %[[VAL_947]], float* %[[VAL_946]], align 4
// CHECK:         br label %[[VAL_199]]
// CHECK:       inter_warp_reduce-true226:                        ; preds = %[[VAL_199]]
// CHECK:         %[[VAL_948:.*]] = getelementptr inbounds [1 x [32 x float]], [1 x [32 x float]] addrspace(3)* @shared_cache_1, i32 0, i32 0, i32 %[[VAL_152]]
// CHECK:         %[[VAL_949:.*]] = addrspacecast float addrspace(3)* %[[VAL_948]] to float*
// CHECK:         store float %[[VAL_116]], float* %[[VAL_71]], align 4
// CHECK:         %[[VAL_950:.*]] = icmp ult i32 %[[VAL_150]], 1
// CHECK:         %[[VAL_951:.*]] = select i1 %[[VAL_950]], float* %[[VAL_949]], float* %[[VAL_71]]
// CHECK:         %[[VAL_952:.*]] = load float, float* %[[VAL_951]], align 4
// CHECK:         %[[VAL_953:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_952]], i32 16, i32 31)
// CHECK:         store float %[[VAL_953]], float* %[[VAL_70]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_951]], float* %[[VAL_70]], float* %[[VAL_951]])
// CHECK:         %[[VAL_954:.*]] = load float, float* %[[VAL_951]], align 4
// CHECK:         %[[VAL_955:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_954]], i32 8, i32 31)
// CHECK:         store float %[[VAL_955]], float* %[[VAL_69]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_951]], float* %[[VAL_69]], float* %[[VAL_951]])
// CHECK:         %[[VAL_956:.*]] = load float, float* %[[VAL_951]], align 4
// CHECK:         %[[VAL_957:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_956]], i32 4, i32 31)
// CHECK:         store float %[[VAL_957]], float* %[[VAL_68]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_951]], float* %[[VAL_68]], float* %[[VAL_951]])
// CHECK:         %[[VAL_958:.*]] = load float, float* %[[VAL_951]], align 4
// CHECK:         %[[VAL_959:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_958]], i32 2, i32 31)
// CHECK:         store float %[[VAL_959]], float* %[[VAL_67]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_951]], float* %[[VAL_67]], float* %[[VAL_951]])
// CHECK:         %[[VAL_960:.*]] = load float, float* %[[VAL_951]], align 4
// CHECK:         %[[VAL_961:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_960]], i32 1, i32 31)
// CHECK:         store float %[[VAL_961]], float* %[[VAL_66]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_951]], float* %[[VAL_66]], float* %[[VAL_951]])
// CHECK:         %[[VAL_962:.*]] = icmp eq i32 %[[VAL_150]], 0
// CHECK:         br i1 %[[VAL_962]], label %[[VAL_963:.*]], label %[[VAL_202]]
// CHECK:       reduction_atomic_update-after240:                 ; preds = %[[VAL_964:.*]], %[[VAL_201]]
// CHECK:         br label %[[VAL_112]]
// CHECK:       reduction_atomic_update-true239:                  ; preds = %[[VAL_201]]
// CHECK:         %[[VAL_965:.*]] = load float, float* %[[VAL_949]], align 4
// CHECK:         %[[VAL_966:.*]] = bitcast float* %[[VAL_184]] to i32*
// CHECK:         %[[VAL_967:.*]] = bitcast i32* %[[VAL_64]] to float*
// CHECK:         %[[VAL_968:.*]] = load i32, i32* %[[VAL_966]], align 4
// CHECK:         store i32 %[[VAL_968]], i32* %[[VAL_65]], align 4
// CHECK:         br label %[[VAL_969:.*]]
// CHECK:       atomic_op_loop_exit:                              ; preds = %[[VAL_970:.*]], %[[VAL_969]]
// CHECK:         br label %[[VAL_202]]
// CHECK:       atomic_op_loop_body:                              ; preds = %[[VAL_970]], %[[VAL_963]]
// CHECK:         %[[VAL_971:.*]] = load i32, i32* %[[VAL_65]], align 4
// CHECK:         store i32 %[[VAL_971]], i32* %[[VAL_64]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_967]], float* %[[VAL_949]], float* %[[VAL_967]])
// CHECK:         %[[VAL_972:.*]] = load i32, i32* %[[VAL_64]], align 4
// CHECK:         %[[VAL_973:.*]] = icmp eq i32 %[[VAL_971]], %[[VAL_972]]
// CHECK:         br i1 %[[VAL_973]], label %[[VAL_964]], label %[[VAL_970]]
// CHECK:       atomic_op_loop_cas:                               ; preds = %[[VAL_969]]
// CHECK:         %[[VAL_974:.*]] = cmpxchg i32* %[[VAL_966]], i32 %[[VAL_971]], i32 %[[VAL_972]] seq_cst seq_cst, align 4
// CHECK:         %[[VAL_975:.*]] = extractvalue { i32, i1 } %[[VAL_974]], 0
// CHECK:         store i32 %[[VAL_975]], i32* %[[VAL_65]], align 4
// CHECK:         %[[VAL_976:.*]] = extractvalue { i32, i1 } %[[VAL_974]], 1
// CHECK:         br i1 %[[VAL_976]], label %[[VAL_964]], label %[[VAL_969]]
// CHECK:       entry:
// CHECK:         %[[VAL_977:.*]] = alloca float, align 4
// CHECK:         %[[VAL_978:.*]] = load float, float* %[[VAL_979:.*]], align 4
// CHECK:         %[[VAL_980:.*]] = load float, float* %[[VAL_981:.*]], align 4
// CHECK:         %[[VAL_982:.*]] = fadd float %[[VAL_978]], %[[VAL_980]]
// CHECK:         store float %[[VAL_982]], float* %[[VAL_977]], align 4
// CHECK:         %[[VAL_983:.*]] = load float, float* %[[VAL_977]], align 4
// CHECK:         store float %[[VAL_983]], float* %[[VAL_984:.*]], align 4
// CHECK:         ret void
// CHECK:       entry:
// CHECK:         %[[VAL_985:.*]] = alloca float, align 4
// CHECK:         %[[VAL_986:.*]] = load float, float* %[[VAL_987:.*]], align 4
// CHECK:         %[[VAL_988:.*]] = load float, float* %[[VAL_989:.*]], align 4
// CHECK:         %[[VAL_990:.*]] = call float @llvm.maxnum.f32(float %[[VAL_986]], float %[[VAL_988]])
// CHECK:         store float %[[VAL_990]], float* %[[VAL_985]], align 4
// CHECK:         %[[VAL_991:.*]] = load float, float* %[[VAL_985]], align 4
// CHECK:         store float %[[VAL_991]], float* %[[VAL_992:.*]], align 4
// CHECK:         ret void

HloModule Test

Add {
  lhsadd = f32[] parameter(0)
  rhsadd = f32[] parameter(1)
  ROOT add = f32[] add(lhsadd, rhsadd)
}

Max {
  lhsmax = f32[] parameter(0)
  rhsmax = f32[] parameter(1)
  ROOT max = f32[] maximum(lhsmax, rhsmax)
}


fused_reduce {
  p0 = f32[2,32,32]{2,1,0} parameter(0)
  init1 = f32[] parameter(1)
  init2 = f32[] parameter(2)
  r1 = f32[2,32]{1,0} reduce(p0, init1), dimensions={2}, to_apply=Add
  r2 = f32[2,32]{1,0} reduce(p0, init2), dimensions={2}, to_apply=Max
  ROOT tuple = (f32[2,32]{1,0}, f32[2,32]{1,0}) tuple(r1, r2)
}

ENTRY reduce {
  p = f32[2,32,32]{2,1,0} parameter(0)
  i = f32[] parameter(1)
  j = f32[] parameter(2)
  ROOT fusion = (f32[2,32]{1,0}, f32[2,32]{1,0}) fusion(p, i, j),
   kind=kInput, calls=fused_reduce
}
