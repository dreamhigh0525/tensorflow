// RUN: hlo_to_llvm_ir %s | FileCheck %s

// NOTE: Assertions have been autogenerated by utils/generate-test-checks.py

// CHECK-LABEL: entry:
// CHECK:         %[[VAL_0:.*]] = alloca float, align 4
// CHECK:         %[[VAL_1:.*]] = alloca float, align 4
// CHECK:         %[[VAL_2:.*]] = alloca float, align 4
// CHECK:         %[[VAL_3:.*]] = alloca float, align 4
// CHECK:         %[[VAL_4:.*]] = alloca float, align 4
// CHECK:         %[[VAL_5:.*]] = alloca float, align 4
// CHECK:         %[[VAL_6:.*]] = alloca float, align 4
// CHECK:         %[[VAL_7:.*]] = alloca float, align 4
// CHECK:         %[[VAL_8:.*]] = alloca float, align 4
// CHECK:         %[[VAL_9:.*]] = alloca float, align 4
// CHECK:         %[[VAL_10:.*]] = alloca float, align 4
// CHECK:         %[[VAL_11:.*]] = alloca float, align 4
// CHECK:         %[[VAL_12:.*]] = alloca float, align 4
// CHECK:         %[[VAL_13:.*]] = alloca float, align 4
// CHECK:         %[[VAL_14:.*]] = alloca float, align 4
// CHECK:         %[[VAL_15:.*]] = alloca float, align 4
// CHECK:         %[[VAL_16:.*]] = alloca float, align 4
// CHECK:         %[[VAL_17:.*]] = alloca float, align 4
// CHECK:         %[[VAL_18:.*]] = alloca float, align 4
// CHECK:         %[[VAL_19:.*]] = alloca float, align 4
// CHECK:         %[[VAL_20:.*]] = alloca float, align 4
// CHECK:         %[[VAL_21:.*]] = alloca float, align 4
// CHECK:         %[[VAL_22:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_23:.*]] = alloca float, align 4
// CHECK:         %[[VAL_24:.*]] = alloca float, align 4
// CHECK:         %[[VAL_25:.*]] = alloca float, align 4
// CHECK:         %[[VAL_26:.*]] = alloca float, align 4
// CHECK:         %[[VAL_27:.*]] = getelementptr inbounds i8, i8* %[[VAL_28:.*]], i64 0
// CHECK:         %[[VAL_29:.*]] = bitcast i8* %[[VAL_27]] to [2 x [32 x [32 x float]]]*
// CHECK:         %[[VAL_30:.*]] = getelementptr inbounds i8, i8* %[[VAL_31:.*]], i64 0
// CHECK:         %[[VAL_32:.*]] = bitcast i8* %[[VAL_30]] to float*
// CHECK:         %[[VAL_33:.*]] = getelementptr inbounds i8, i8* %[[VAL_34:.*]], i64 0
// CHECK:         %[[VAL_35:.*]] = bitcast i8* %[[VAL_33]] to float*
// CHECK:         %[[VAL_36:.*]] = getelementptr inbounds i8, i8* %[[VAL_37:.*]], i64 0
// CHECK:         %[[VAL_38:.*]] = bitcast i8* %[[VAL_36]] to [2 x [32 x float]]*
// CHECK:         %[[VAL_39:.*]] = getelementptr inbounds i8, i8* %[[VAL_40:.*]], i64 0
// CHECK:         %[[VAL_41:.*]] = bitcast i8* %[[VAL_39]] to [2 x [32 x float]]*
// CHECK:         %[[VAL_42:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y(), !range !2
// CHECK:         %[[VAL_43:.*]] = icmp eq i32 %[[VAL_42]], 0
// CHECK:         br i1 %[[VAL_43]], label %[[VAL_44:.*]], label %[[VAL_45:.*]]
// CHECK:       reduce-group-0-after:                             ; preds = %[[VAL_46:.*]], %[[VAL_47:.*]]
// CHECK:         ret void
// CHECK:       reduce-group-0-true:                              ; preds = %[[VAL_47]]
// CHECK:         %[[VAL_48:.*]] = load float, float* %[[VAL_32]], align 4, !invariant.load !3
// CHECK:         %[[VAL_49:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         store float %[[VAL_48]], float* %[[VAL_49]], align 4
// CHECK:         %[[VAL_50:.*]] = load float, float* %[[VAL_35]], align 4, !invariant.load !3
// CHECK:         %[[VAL_51:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         store float %[[VAL_50]], float* %[[VAL_51]], align 4
// CHECK:         %[[VAL_52:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !4
// CHECK:         %[[VAL_53:.*]] = urem i32 %[[VAL_52]], 32
// CHECK:         %[[VAL_54:.*]] = udiv i32 %[[VAL_52]], 32
// CHECK:         %[[VAL_55:.*]] = urem i32 %[[VAL_52]], 32
// CHECK:         %[[VAL_56:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !5
// CHECK:         %[[VAL_57:.*]] = udiv i32 %[[VAL_56]], 1
// CHECK:         %[[VAL_58:.*]] = urem i32 %[[VAL_57]], 1
// CHECK:         %[[VAL_59:.*]] = udiv i32 %[[VAL_56]], 1
// CHECK:         %[[VAL_60:.*]] = urem i32 %[[VAL_59]], 64
// CHECK:         %[[VAL_61:.*]] = udiv i32 %[[VAL_56]], 64
// CHECK:         %[[VAL_62:.*]] = mul i32 %[[VAL_61]], 1
// CHECK:         %[[VAL_63:.*]] = icmp eq i32 %[[VAL_60]], 63
// CHECK:         %[[VAL_64:.*]] = select i1 %[[VAL_63]], i32 1, i32 1
// CHECK:         %[[VAL_65:.*]] = icmp eq i32 %[[VAL_58]], 0
// CHECK:         %[[VAL_66:.*]] = select i1 %[[VAL_65]], i32 32, i32 512
// CHECK:         %[[VAL_67:.*]] = mul i32 %[[VAL_60]], 1
// CHECK:         %[[VAL_68:.*]] = mul i32 %[[VAL_58]], 512
// CHECK:         %[[VAL_69:.*]] = mul i32 %[[VAL_53]], 2
// CHECK:         %[[VAL_70:.*]] = add i32 %[[VAL_68]], %[[VAL_69]]
// CHECK:         store i32 %[[VAL_54]], i32* %[[VAL_22]], align 4
// CHECK:         br label %[[VAL_71:.*]]
// CHECK:       output_y_in_tile.loop_header:                     ; preds = %[[VAL_72:.*]], %[[VAL_44]]
// CHECK:         %[[VAL_73:.*]] = load i32, i32* %[[VAL_22]], align 4
// CHECK:         %[[VAL_74:.*]] = icmp uge i32 %[[VAL_73]], %[[VAL_64]]
// CHECK:         br i1 %[[VAL_74]], label %[[VAL_75:.*]], label %[[VAL_76:.*]]
// CHECK:       output_y_in_tile.loop_body:                       ; preds = %[[VAL_71]]
// CHECK:         %[[VAL_77:.*]] = add nuw nsw i32 %[[VAL_73]], 1
// CHECK:         store i32 %[[VAL_77]], i32* %[[VAL_22]], align 4
// CHECK:         %[[VAL_78:.*]] = icmp eq i32 %[[VAL_73]], %[[VAL_54]]
// CHECK:         %[[VAL_79:.*]] = icmp eq i32 512, %[[VAL_66]]
// CHECK:         br i1 %[[VAL_79]], label %[[VAL_80:.*]], label %[[VAL_81:.*]]
// CHECK:       output_is_full_tile-after:                        ; preds = %[[VAL_82:.*]], %[[VAL_80]]
// CHECK:         br label %[[VAL_71]], !llvm.loop !6
// CHECK:       output_y_in_tile.loop_exit:                       ; preds = %[[VAL_71]]
// CHECK:         %[[VAL_83:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !4
// CHECK:         %[[VAL_84:.*]] = urem i32 %[[VAL_83]], 32
// CHECK:         %[[VAL_85:.*]] = udiv i32 %[[VAL_83]], 32
// CHECK:         %[[VAL_86:.*]] = urem i32 %[[VAL_83]], 32
// CHECK:         %[[VAL_87:.*]] = mul i32 %[[VAL_84]], 2
// CHECK:         %[[VAL_88:.*]] = add i32 %[[VAL_67]], %[[VAL_85]]
// CHECK:         %[[VAL_89:.*]] = add i32 %[[VAL_68]], %[[VAL_87]]
// CHECK:         %[[VAL_90:.*]] = add i32 %[[VAL_89]], 0
// CHECK:         %[[VAL_91:.*]] = udiv i32 %[[VAL_88]], 1
// CHECK:         %[[VAL_92:.*]] = urem i32 %[[VAL_91]], 32
// CHECK:         %[[VAL_93:.*]] = udiv i32 %[[VAL_88]], 32
// CHECK:         %[[VAL_94:.*]] = getelementptr inbounds [2 x [32 x float]], [2 x [32 x float]]* %[[VAL_38]], i32 0, i32 %[[VAL_93]], i32 %[[VAL_92]]
// CHECK:         %[[VAL_95:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         %[[VAL_96:.*]] = load float, float* %[[VAL_95]], align 4
// CHECK:         %[[VAL_97:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_96]], i32 16, i32 31)
// CHECK:         store float %[[VAL_97]], float* %[[VAL_21]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_95]], float* %[[VAL_21]], float* %[[VAL_95]])
// CHECK:         %[[VAL_98:.*]] = load float, float* %[[VAL_95]], align 4
// CHECK:         %[[VAL_99:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_98]], i32 8, i32 31)
// CHECK:         store float %[[VAL_99]], float* %[[VAL_20]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_95]], float* %[[VAL_20]], float* %[[VAL_95]])
// CHECK:         %[[VAL_100:.*]] = load float, float* %[[VAL_95]], align 4
// CHECK:         %[[VAL_101:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_100]], i32 4, i32 31)
// CHECK:         store float %[[VAL_101]], float* %[[VAL_19]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_95]], float* %[[VAL_19]], float* %[[VAL_95]])
// CHECK:         %[[VAL_102:.*]] = load float, float* %[[VAL_95]], align 4
// CHECK:         %[[VAL_103:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_102]], i32 2, i32 31)
// CHECK:         store float %[[VAL_103]], float* %[[VAL_18]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_95]], float* %[[VAL_18]], float* %[[VAL_95]])
// CHECK:         %[[VAL_104:.*]] = load float, float* %[[VAL_95]], align 4
// CHECK:         %[[VAL_105:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_104]], i32 1, i32 31)
// CHECK:         store float %[[VAL_105]], float* %[[VAL_17]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_95]], float* %[[VAL_17]], float* %[[VAL_95]])
// CHECK:         %[[VAL_106:.*]] = udiv i32 %[[VAL_84]], 32
// CHECK:         %[[VAL_107:.*]] = icmp eq i32 %[[VAL_86]], 0
// CHECK:         br i1 %[[VAL_107]], label %[[VAL_108:.*]], label %[[VAL_109:.*]]
// CHECK:       intra_warp_reduce_write-after:                    ; preds = %[[VAL_108]], %[[VAL_75]]
// CHECK:         call void @llvm.nvvm.barrier0()
// CHECK:         %[[VAL_110:.*]] = icmp eq i32 %[[VAL_106]], 0
// CHECK:         br i1 %[[VAL_110]], label %[[VAL_111:.*]], label %[[VAL_112:.*]]
// CHECK:       inter_warp_reduce-after:                          ; preds = %[[VAL_113:.*]], %[[VAL_109]]
// CHECK:         %[[VAL_114:.*]] = add i32 %[[VAL_89]], 0
// CHECK:         %[[VAL_115:.*]] = udiv i32 %[[VAL_88]], 1
// CHECK:         %[[VAL_116:.*]] = urem i32 %[[VAL_115]], 32
// CHECK:         %[[VAL_117:.*]] = udiv i32 %[[VAL_88]], 32
// CHECK:         %[[VAL_118:.*]] = getelementptr inbounds [2 x [32 x float]], [2 x [32 x float]]* %[[VAL_41]], i32 0, i32 %[[VAL_117]], i32 %[[VAL_116]]
// CHECK:         %[[VAL_119:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         %[[VAL_120:.*]] = load float, float* %[[VAL_119]], align 4
// CHECK:         %[[VAL_121:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_120]], i32 16, i32 31)
// CHECK:         store float %[[VAL_121]], float* %[[VAL_10]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_119]], float* %[[VAL_10]], float* %[[VAL_119]])
// CHECK:         %[[VAL_122:.*]] = load float, float* %[[VAL_119]], align 4
// CHECK:         %[[VAL_123:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_122]], i32 8, i32 31)
// CHECK:         store float %[[VAL_123]], float* %[[VAL_9]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_119]], float* %[[VAL_9]], float* %[[VAL_119]])
// CHECK:         %[[VAL_124:.*]] = load float, float* %[[VAL_119]], align 4
// CHECK:         %[[VAL_125:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_124]], i32 4, i32 31)
// CHECK:         store float %[[VAL_125]], float* %[[VAL_8]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_119]], float* %[[VAL_8]], float* %[[VAL_119]])
// CHECK:         %[[VAL_126:.*]] = load float, float* %[[VAL_119]], align 4
// CHECK:         %[[VAL_127:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_126]], i32 2, i32 31)
// CHECK:         store float %[[VAL_127]], float* %[[VAL_7]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_119]], float* %[[VAL_7]], float* %[[VAL_119]])
// CHECK:         %[[VAL_128:.*]] = load float, float* %[[VAL_119]], align 4
// CHECK:         %[[VAL_129:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_128]], i32 1, i32 31)
// CHECK:         store float %[[VAL_129]], float* %[[VAL_6]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_119]], float* %[[VAL_6]], float* %[[VAL_119]])
// CHECK:         %[[VAL_130:.*]] = udiv i32 %[[VAL_84]], 32
// CHECK:         %[[VAL_131:.*]] = icmp eq i32 %[[VAL_86]], 0
// CHECK:         br i1 %[[VAL_131]], label %[[VAL_132:.*]], label %[[VAL_133:.*]]
// CHECK:       intra_warp_reduce_write-after225:                 ; preds = %[[VAL_132]], %[[VAL_112]]
// CHECK:         call void @llvm.nvvm.barrier0()
// CHECK:         %[[VAL_134:.*]] = icmp eq i32 %[[VAL_130]], 0
// CHECK:         br i1 %[[VAL_134]], label %[[VAL_135:.*]], label %[[VAL_46]]
// CHECK:       inter_warp_reduce-after227:                       ; preds = %[[VAL_136:.*]], %[[VAL_133]]
// CHECK:         br label %[[VAL_45]]
// CHECK:       output_is_full_tile-true:                         ; preds = %[[VAL_76]]
// CHECK:         %[[VAL_137:.*]] = add i32 %[[VAL_67]], %[[VAL_73]]
// CHECK:         %[[VAL_138:.*]] = add i32 0, %[[VAL_69]]
// CHECK:         %[[VAL_139:.*]] = add i32 %[[VAL_70]], 0
// CHECK:         %[[VAL_140:.*]] = mul nuw nsw i32 %[[VAL_139]], 1
// CHECK:         %[[VAL_141:.*]] = add nuw nsw i32 0, %[[VAL_140]]
// CHECK:         %[[VAL_142:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_143:.*]] = add nuw nsw i32 %[[VAL_141]], %[[VAL_142]]
// CHECK:         %[[VAL_144:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_145:.*]] = add nuw nsw i32 %[[VAL_143]], %[[VAL_144]]
// CHECK:         %[[VAL_146:.*]] = udiv i32 %[[VAL_145]], 1
// CHECK:         %[[VAL_147:.*]] = urem i32 %[[VAL_146]], 32
// CHECK:         %[[VAL_148:.*]] = udiv i32 %[[VAL_145]], 32
// CHECK:         %[[VAL_149:.*]] = urem i32 %[[VAL_148]], 32
// CHECK:         %[[VAL_150:.*]] = udiv i32 %[[VAL_145]], 1024
// CHECK:         %[[VAL_151:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_152:.*]] = getelementptr inbounds float, float* %[[VAL_151]], i32 %[[VAL_145]]
// CHECK:         %[[VAL_153:.*]] = load float, float* %[[VAL_152]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_153]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_154:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_154]], float* %[[VAL_26]], float* %[[VAL_154]])
// CHECK:         %[[VAL_155:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_156:.*]] = getelementptr inbounds float, float* %[[VAL_155]], i32 %[[VAL_145]]
// CHECK:         %[[VAL_157:.*]] = load float, float* %[[VAL_156]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_157]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_158:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_158]], float* %[[VAL_24]], float* %[[VAL_158]])
// CHECK:         %[[VAL_159:.*]] = add i32 1, %[[VAL_69]]
// CHECK:         %[[VAL_160:.*]] = add i32 %[[VAL_70]], 1
// CHECK:         %[[VAL_161:.*]] = mul nuw nsw i32 %[[VAL_160]], 1
// CHECK:         %[[VAL_162:.*]] = add nuw nsw i32 0, %[[VAL_161]]
// CHECK:         %[[VAL_163:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_164:.*]] = add nuw nsw i32 %[[VAL_162]], %[[VAL_163]]
// CHECK:         %[[VAL_165:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_166:.*]] = add nuw nsw i32 %[[VAL_164]], %[[VAL_165]]
// CHECK:         %[[VAL_167:.*]] = udiv i32 %[[VAL_166]], 1
// CHECK:         %[[VAL_168:.*]] = urem i32 %[[VAL_167]], 32
// CHECK:         %[[VAL_169:.*]] = udiv i32 %[[VAL_166]], 32
// CHECK:         %[[VAL_170:.*]] = urem i32 %[[VAL_169]], 32
// CHECK:         %[[VAL_171:.*]] = udiv i32 %[[VAL_166]], 1024
// CHECK:         %[[VAL_172:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_173:.*]] = getelementptr inbounds float, float* %[[VAL_172]], i32 %[[VAL_166]]
// CHECK:         %[[VAL_174:.*]] = load float, float* %[[VAL_173]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_174]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_175:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_175]], float* %[[VAL_26]], float* %[[VAL_175]])
// CHECK:         %[[VAL_176:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_177:.*]] = getelementptr inbounds float, float* %[[VAL_176]], i32 %[[VAL_166]]
// CHECK:         %[[VAL_178:.*]] = load float, float* %[[VAL_177]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_178]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_179:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_179]], float* %[[VAL_24]], float* %[[VAL_179]])
// CHECK:         %[[VAL_180:.*]] = add i32 64, %[[VAL_69]]
// CHECK:         %[[VAL_181:.*]] = add i32 %[[VAL_70]], 64
// CHECK:         %[[VAL_182:.*]] = mul nuw nsw i32 %[[VAL_181]], 1
// CHECK:         %[[VAL_183:.*]] = add nuw nsw i32 0, %[[VAL_182]]
// CHECK:         %[[VAL_184:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_185:.*]] = add nuw nsw i32 %[[VAL_183]], %[[VAL_184]]
// CHECK:         %[[VAL_186:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_187:.*]] = add nuw nsw i32 %[[VAL_185]], %[[VAL_186]]
// CHECK:         %[[VAL_188:.*]] = udiv i32 %[[VAL_187]], 1
// CHECK:         %[[VAL_189:.*]] = urem i32 %[[VAL_188]], 32
// CHECK:         %[[VAL_190:.*]] = udiv i32 %[[VAL_187]], 32
// CHECK:         %[[VAL_191:.*]] = urem i32 %[[VAL_190]], 32
// CHECK:         %[[VAL_192:.*]] = udiv i32 %[[VAL_187]], 1024
// CHECK:         %[[VAL_193:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_194:.*]] = getelementptr inbounds float, float* %[[VAL_193]], i32 %[[VAL_187]]
// CHECK:         %[[VAL_195:.*]] = load float, float* %[[VAL_194]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_195]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_196:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_196]], float* %[[VAL_26]], float* %[[VAL_196]])
// CHECK:         %[[VAL_197:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_198:.*]] = getelementptr inbounds float, float* %[[VAL_197]], i32 %[[VAL_187]]
// CHECK:         %[[VAL_199:.*]] = load float, float* %[[VAL_198]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_199]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_200:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_200]], float* %[[VAL_24]], float* %[[VAL_200]])
// CHECK:         %[[VAL_201:.*]] = add i32 65, %[[VAL_69]]
// CHECK:         %[[VAL_202:.*]] = add i32 %[[VAL_70]], 65
// CHECK:         %[[VAL_203:.*]] = mul nuw nsw i32 %[[VAL_202]], 1
// CHECK:         %[[VAL_204:.*]] = add nuw nsw i32 0, %[[VAL_203]]
// CHECK:         %[[VAL_205:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_206:.*]] = add nuw nsw i32 %[[VAL_204]], %[[VAL_205]]
// CHECK:         %[[VAL_207:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_208:.*]] = add nuw nsw i32 %[[VAL_206]], %[[VAL_207]]
// CHECK:         %[[VAL_209:.*]] = udiv i32 %[[VAL_208]], 1
// CHECK:         %[[VAL_210:.*]] = urem i32 %[[VAL_209]], 32
// CHECK:         %[[VAL_211:.*]] = udiv i32 %[[VAL_208]], 32
// CHECK:         %[[VAL_212:.*]] = urem i32 %[[VAL_211]], 32
// CHECK:         %[[VAL_213:.*]] = udiv i32 %[[VAL_208]], 1024
// CHECK:         %[[VAL_214:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_215:.*]] = getelementptr inbounds float, float* %[[VAL_214]], i32 %[[VAL_208]]
// CHECK:         %[[VAL_216:.*]] = load float, float* %[[VAL_215]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_216]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_217:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_217]], float* %[[VAL_26]], float* %[[VAL_217]])
// CHECK:         %[[VAL_218:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_219:.*]] = getelementptr inbounds float, float* %[[VAL_218]], i32 %[[VAL_208]]
// CHECK:         %[[VAL_220:.*]] = load float, float* %[[VAL_219]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_220]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_221:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_221]], float* %[[VAL_24]], float* %[[VAL_221]])
// CHECK:         %[[VAL_222:.*]] = add i32 128, %[[VAL_69]]
// CHECK:         %[[VAL_223:.*]] = add i32 %[[VAL_70]], 128
// CHECK:         %[[VAL_224:.*]] = mul nuw nsw i32 %[[VAL_223]], 1
// CHECK:         %[[VAL_225:.*]] = add nuw nsw i32 0, %[[VAL_224]]
// CHECK:         %[[VAL_226:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_227:.*]] = add nuw nsw i32 %[[VAL_225]], %[[VAL_226]]
// CHECK:         %[[VAL_228:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_229:.*]] = add nuw nsw i32 %[[VAL_227]], %[[VAL_228]]
// CHECK:         %[[VAL_230:.*]] = udiv i32 %[[VAL_229]], 1
// CHECK:         %[[VAL_231:.*]] = urem i32 %[[VAL_230]], 32
// CHECK:         %[[VAL_232:.*]] = udiv i32 %[[VAL_229]], 32
// CHECK:         %[[VAL_233:.*]] = urem i32 %[[VAL_232]], 32
// CHECK:         %[[VAL_234:.*]] = udiv i32 %[[VAL_229]], 1024
// CHECK:         %[[VAL_235:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_236:.*]] = getelementptr inbounds float, float* %[[VAL_235]], i32 %[[VAL_229]]
// CHECK:         %[[VAL_237:.*]] = load float, float* %[[VAL_236]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_237]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_238:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_238]], float* %[[VAL_26]], float* %[[VAL_238]])
// CHECK:         %[[VAL_239:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_240:.*]] = getelementptr inbounds float, float* %[[VAL_239]], i32 %[[VAL_229]]
// CHECK:         %[[VAL_241:.*]] = load float, float* %[[VAL_240]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_241]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_242:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_242]], float* %[[VAL_24]], float* %[[VAL_242]])
// CHECK:         %[[VAL_243:.*]] = add i32 129, %[[VAL_69]]
// CHECK:         %[[VAL_244:.*]] = add i32 %[[VAL_70]], 129
// CHECK:         %[[VAL_245:.*]] = mul nuw nsw i32 %[[VAL_244]], 1
// CHECK:         %[[VAL_246:.*]] = add nuw nsw i32 0, %[[VAL_245]]
// CHECK:         %[[VAL_247:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_248:.*]] = add nuw nsw i32 %[[VAL_246]], %[[VAL_247]]
// CHECK:         %[[VAL_249:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_250:.*]] = add nuw nsw i32 %[[VAL_248]], %[[VAL_249]]
// CHECK:         %[[VAL_251:.*]] = udiv i32 %[[VAL_250]], 1
// CHECK:         %[[VAL_252:.*]] = urem i32 %[[VAL_251]], 32
// CHECK:         %[[VAL_253:.*]] = udiv i32 %[[VAL_250]], 32
// CHECK:         %[[VAL_254:.*]] = urem i32 %[[VAL_253]], 32
// CHECK:         %[[VAL_255:.*]] = udiv i32 %[[VAL_250]], 1024
// CHECK:         %[[VAL_256:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_257:.*]] = getelementptr inbounds float, float* %[[VAL_256]], i32 %[[VAL_250]]
// CHECK:         %[[VAL_258:.*]] = load float, float* %[[VAL_257]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_258]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_259:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_259]], float* %[[VAL_26]], float* %[[VAL_259]])
// CHECK:         %[[VAL_260:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_261:.*]] = getelementptr inbounds float, float* %[[VAL_260]], i32 %[[VAL_250]]
// CHECK:         %[[VAL_262:.*]] = load float, float* %[[VAL_261]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_262]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_263:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_263]], float* %[[VAL_24]], float* %[[VAL_263]])
// CHECK:         %[[VAL_264:.*]] = add i32 192, %[[VAL_69]]
// CHECK:         %[[VAL_265:.*]] = add i32 %[[VAL_70]], 192
// CHECK:         %[[VAL_266:.*]] = mul nuw nsw i32 %[[VAL_265]], 1
// CHECK:         %[[VAL_267:.*]] = add nuw nsw i32 0, %[[VAL_266]]
// CHECK:         %[[VAL_268:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_269:.*]] = add nuw nsw i32 %[[VAL_267]], %[[VAL_268]]
// CHECK:         %[[VAL_270:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_271:.*]] = add nuw nsw i32 %[[VAL_269]], %[[VAL_270]]
// CHECK:         %[[VAL_272:.*]] = udiv i32 %[[VAL_271]], 1
// CHECK:         %[[VAL_273:.*]] = urem i32 %[[VAL_272]], 32
// CHECK:         %[[VAL_274:.*]] = udiv i32 %[[VAL_271]], 32
// CHECK:         %[[VAL_275:.*]] = urem i32 %[[VAL_274]], 32
// CHECK:         %[[VAL_276:.*]] = udiv i32 %[[VAL_271]], 1024
// CHECK:         %[[VAL_277:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_278:.*]] = getelementptr inbounds float, float* %[[VAL_277]], i32 %[[VAL_271]]
// CHECK:         %[[VAL_279:.*]] = load float, float* %[[VAL_278]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_279]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_280:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_280]], float* %[[VAL_26]], float* %[[VAL_280]])
// CHECK:         %[[VAL_281:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_282:.*]] = getelementptr inbounds float, float* %[[VAL_281]], i32 %[[VAL_271]]
// CHECK:         %[[VAL_283:.*]] = load float, float* %[[VAL_282]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_283]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_284:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_284]], float* %[[VAL_24]], float* %[[VAL_284]])
// CHECK:         %[[VAL_285:.*]] = add i32 193, %[[VAL_69]]
// CHECK:         %[[VAL_286:.*]] = add i32 %[[VAL_70]], 193
// CHECK:         %[[VAL_287:.*]] = mul nuw nsw i32 %[[VAL_286]], 1
// CHECK:         %[[VAL_288:.*]] = add nuw nsw i32 0, %[[VAL_287]]
// CHECK:         %[[VAL_289:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_290:.*]] = add nuw nsw i32 %[[VAL_288]], %[[VAL_289]]
// CHECK:         %[[VAL_291:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_292:.*]] = add nuw nsw i32 %[[VAL_290]], %[[VAL_291]]
// CHECK:         %[[VAL_293:.*]] = udiv i32 %[[VAL_292]], 1
// CHECK:         %[[VAL_294:.*]] = urem i32 %[[VAL_293]], 32
// CHECK:         %[[VAL_295:.*]] = udiv i32 %[[VAL_292]], 32
// CHECK:         %[[VAL_296:.*]] = urem i32 %[[VAL_295]], 32
// CHECK:         %[[VAL_297:.*]] = udiv i32 %[[VAL_292]], 1024
// CHECK:         %[[VAL_298:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_299:.*]] = getelementptr inbounds float, float* %[[VAL_298]], i32 %[[VAL_292]]
// CHECK:         %[[VAL_300:.*]] = load float, float* %[[VAL_299]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_300]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_301:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_301]], float* %[[VAL_26]], float* %[[VAL_301]])
// CHECK:         %[[VAL_302:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_303:.*]] = getelementptr inbounds float, float* %[[VAL_302]], i32 %[[VAL_292]]
// CHECK:         %[[VAL_304:.*]] = load float, float* %[[VAL_303]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_304]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_305:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_305]], float* %[[VAL_24]], float* %[[VAL_305]])
// CHECK:         %[[VAL_306:.*]] = add i32 256, %[[VAL_69]]
// CHECK:         %[[VAL_307:.*]] = add i32 %[[VAL_70]], 256
// CHECK:         %[[VAL_308:.*]] = mul nuw nsw i32 %[[VAL_307]], 1
// CHECK:         %[[VAL_309:.*]] = add nuw nsw i32 0, %[[VAL_308]]
// CHECK:         %[[VAL_310:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_311:.*]] = add nuw nsw i32 %[[VAL_309]], %[[VAL_310]]
// CHECK:         %[[VAL_312:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_313:.*]] = add nuw nsw i32 %[[VAL_311]], %[[VAL_312]]
// CHECK:         %[[VAL_314:.*]] = udiv i32 %[[VAL_313]], 1
// CHECK:         %[[VAL_315:.*]] = urem i32 %[[VAL_314]], 32
// CHECK:         %[[VAL_316:.*]] = udiv i32 %[[VAL_313]], 32
// CHECK:         %[[VAL_317:.*]] = urem i32 %[[VAL_316]], 32
// CHECK:         %[[VAL_318:.*]] = udiv i32 %[[VAL_313]], 1024
// CHECK:         %[[VAL_319:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_320:.*]] = getelementptr inbounds float, float* %[[VAL_319]], i32 %[[VAL_313]]
// CHECK:         %[[VAL_321:.*]] = load float, float* %[[VAL_320]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_321]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_322:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_322]], float* %[[VAL_26]], float* %[[VAL_322]])
// CHECK:         %[[VAL_323:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_324:.*]] = getelementptr inbounds float, float* %[[VAL_323]], i32 %[[VAL_313]]
// CHECK:         %[[VAL_325:.*]] = load float, float* %[[VAL_324]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_325]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_326:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_326]], float* %[[VAL_24]], float* %[[VAL_326]])
// CHECK:         %[[VAL_327:.*]] = add i32 257, %[[VAL_69]]
// CHECK:         %[[VAL_328:.*]] = add i32 %[[VAL_70]], 257
// CHECK:         %[[VAL_329:.*]] = mul nuw nsw i32 %[[VAL_328]], 1
// CHECK:         %[[VAL_330:.*]] = add nuw nsw i32 0, %[[VAL_329]]
// CHECK:         %[[VAL_331:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_332:.*]] = add nuw nsw i32 %[[VAL_330]], %[[VAL_331]]
// CHECK:         %[[VAL_333:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_334:.*]] = add nuw nsw i32 %[[VAL_332]], %[[VAL_333]]
// CHECK:         %[[VAL_335:.*]] = udiv i32 %[[VAL_334]], 1
// CHECK:         %[[VAL_336:.*]] = urem i32 %[[VAL_335]], 32
// CHECK:         %[[VAL_337:.*]] = udiv i32 %[[VAL_334]], 32
// CHECK:         %[[VAL_338:.*]] = urem i32 %[[VAL_337]], 32
// CHECK:         %[[VAL_339:.*]] = udiv i32 %[[VAL_334]], 1024
// CHECK:         %[[VAL_340:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_341:.*]] = getelementptr inbounds float, float* %[[VAL_340]], i32 %[[VAL_334]]
// CHECK:         %[[VAL_342:.*]] = load float, float* %[[VAL_341]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_342]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_343:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_343]], float* %[[VAL_26]], float* %[[VAL_343]])
// CHECK:         %[[VAL_344:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_345:.*]] = getelementptr inbounds float, float* %[[VAL_344]], i32 %[[VAL_334]]
// CHECK:         %[[VAL_346:.*]] = load float, float* %[[VAL_345]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_346]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_347:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_347]], float* %[[VAL_24]], float* %[[VAL_347]])
// CHECK:         %[[VAL_348:.*]] = add i32 320, %[[VAL_69]]
// CHECK:         %[[VAL_349:.*]] = add i32 %[[VAL_70]], 320
// CHECK:         %[[VAL_350:.*]] = mul nuw nsw i32 %[[VAL_349]], 1
// CHECK:         %[[VAL_351:.*]] = add nuw nsw i32 0, %[[VAL_350]]
// CHECK:         %[[VAL_352:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_353:.*]] = add nuw nsw i32 %[[VAL_351]], %[[VAL_352]]
// CHECK:         %[[VAL_354:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_355:.*]] = add nuw nsw i32 %[[VAL_353]], %[[VAL_354]]
// CHECK:         %[[VAL_356:.*]] = udiv i32 %[[VAL_355]], 1
// CHECK:         %[[VAL_357:.*]] = urem i32 %[[VAL_356]], 32
// CHECK:         %[[VAL_358:.*]] = udiv i32 %[[VAL_355]], 32
// CHECK:         %[[VAL_359:.*]] = urem i32 %[[VAL_358]], 32
// CHECK:         %[[VAL_360:.*]] = udiv i32 %[[VAL_355]], 1024
// CHECK:         %[[VAL_361:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_362:.*]] = getelementptr inbounds float, float* %[[VAL_361]], i32 %[[VAL_355]]
// CHECK:         %[[VAL_363:.*]] = load float, float* %[[VAL_362]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_363]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_364:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_364]], float* %[[VAL_26]], float* %[[VAL_364]])
// CHECK:         %[[VAL_365:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_366:.*]] = getelementptr inbounds float, float* %[[VAL_365]], i32 %[[VAL_355]]
// CHECK:         %[[VAL_367:.*]] = load float, float* %[[VAL_366]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_367]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_368:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_368]], float* %[[VAL_24]], float* %[[VAL_368]])
// CHECK:         %[[VAL_369:.*]] = add i32 321, %[[VAL_69]]
// CHECK:         %[[VAL_370:.*]] = add i32 %[[VAL_70]], 321
// CHECK:         %[[VAL_371:.*]] = mul nuw nsw i32 %[[VAL_370]], 1
// CHECK:         %[[VAL_372:.*]] = add nuw nsw i32 0, %[[VAL_371]]
// CHECK:         %[[VAL_373:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_374:.*]] = add nuw nsw i32 %[[VAL_372]], %[[VAL_373]]
// CHECK:         %[[VAL_375:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_376:.*]] = add nuw nsw i32 %[[VAL_374]], %[[VAL_375]]
// CHECK:         %[[VAL_377:.*]] = udiv i32 %[[VAL_376]], 1
// CHECK:         %[[VAL_378:.*]] = urem i32 %[[VAL_377]], 32
// CHECK:         %[[VAL_379:.*]] = udiv i32 %[[VAL_376]], 32
// CHECK:         %[[VAL_380:.*]] = urem i32 %[[VAL_379]], 32
// CHECK:         %[[VAL_381:.*]] = udiv i32 %[[VAL_376]], 1024
// CHECK:         %[[VAL_382:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_383:.*]] = getelementptr inbounds float, float* %[[VAL_382]], i32 %[[VAL_376]]
// CHECK:         %[[VAL_384:.*]] = load float, float* %[[VAL_383]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_384]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_385:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_385]], float* %[[VAL_26]], float* %[[VAL_385]])
// CHECK:         %[[VAL_386:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_387:.*]] = getelementptr inbounds float, float* %[[VAL_386]], i32 %[[VAL_376]]
// CHECK:         %[[VAL_388:.*]] = load float, float* %[[VAL_387]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_388]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_389:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_389]], float* %[[VAL_24]], float* %[[VAL_389]])
// CHECK:         %[[VAL_390:.*]] = add i32 384, %[[VAL_69]]
// CHECK:         %[[VAL_391:.*]] = add i32 %[[VAL_70]], 384
// CHECK:         %[[VAL_392:.*]] = mul nuw nsw i32 %[[VAL_391]], 1
// CHECK:         %[[VAL_393:.*]] = add nuw nsw i32 0, %[[VAL_392]]
// CHECK:         %[[VAL_394:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_395:.*]] = add nuw nsw i32 %[[VAL_393]], %[[VAL_394]]
// CHECK:         %[[VAL_396:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_397:.*]] = add nuw nsw i32 %[[VAL_395]], %[[VAL_396]]
// CHECK:         %[[VAL_398:.*]] = udiv i32 %[[VAL_397]], 1
// CHECK:         %[[VAL_399:.*]] = urem i32 %[[VAL_398]], 32
// CHECK:         %[[VAL_400:.*]] = udiv i32 %[[VAL_397]], 32
// CHECK:         %[[VAL_401:.*]] = urem i32 %[[VAL_400]], 32
// CHECK:         %[[VAL_402:.*]] = udiv i32 %[[VAL_397]], 1024
// CHECK:         %[[VAL_403:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_404:.*]] = getelementptr inbounds float, float* %[[VAL_403]], i32 %[[VAL_397]]
// CHECK:         %[[VAL_405:.*]] = load float, float* %[[VAL_404]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_405]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_406:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_406]], float* %[[VAL_26]], float* %[[VAL_406]])
// CHECK:         %[[VAL_407:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_408:.*]] = getelementptr inbounds float, float* %[[VAL_407]], i32 %[[VAL_397]]
// CHECK:         %[[VAL_409:.*]] = load float, float* %[[VAL_408]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_409]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_410:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_410]], float* %[[VAL_24]], float* %[[VAL_410]])
// CHECK:         %[[VAL_411:.*]] = add i32 385, %[[VAL_69]]
// CHECK:         %[[VAL_412:.*]] = add i32 %[[VAL_70]], 385
// CHECK:         %[[VAL_413:.*]] = mul nuw nsw i32 %[[VAL_412]], 1
// CHECK:         %[[VAL_414:.*]] = add nuw nsw i32 0, %[[VAL_413]]
// CHECK:         %[[VAL_415:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_416:.*]] = add nuw nsw i32 %[[VAL_414]], %[[VAL_415]]
// CHECK:         %[[VAL_417:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_418:.*]] = add nuw nsw i32 %[[VAL_416]], %[[VAL_417]]
// CHECK:         %[[VAL_419:.*]] = udiv i32 %[[VAL_418]], 1
// CHECK:         %[[VAL_420:.*]] = urem i32 %[[VAL_419]], 32
// CHECK:         %[[VAL_421:.*]] = udiv i32 %[[VAL_418]], 32
// CHECK:         %[[VAL_422:.*]] = urem i32 %[[VAL_421]], 32
// CHECK:         %[[VAL_423:.*]] = udiv i32 %[[VAL_418]], 1024
// CHECK:         %[[VAL_424:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_425:.*]] = getelementptr inbounds float, float* %[[VAL_424]], i32 %[[VAL_418]]
// CHECK:         %[[VAL_426:.*]] = load float, float* %[[VAL_425]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_426]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_427:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_427]], float* %[[VAL_26]], float* %[[VAL_427]])
// CHECK:         %[[VAL_428:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_429:.*]] = getelementptr inbounds float, float* %[[VAL_428]], i32 %[[VAL_418]]
// CHECK:         %[[VAL_430:.*]] = load float, float* %[[VAL_429]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_430]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_431:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_431]], float* %[[VAL_24]], float* %[[VAL_431]])
// CHECK:         %[[VAL_432:.*]] = add i32 448, %[[VAL_69]]
// CHECK:         %[[VAL_433:.*]] = add i32 %[[VAL_70]], 448
// CHECK:         %[[VAL_434:.*]] = mul nuw nsw i32 %[[VAL_433]], 1
// CHECK:         %[[VAL_435:.*]] = add nuw nsw i32 0, %[[VAL_434]]
// CHECK:         %[[VAL_436:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_437:.*]] = add nuw nsw i32 %[[VAL_435]], %[[VAL_436]]
// CHECK:         %[[VAL_438:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_439:.*]] = add nuw nsw i32 %[[VAL_437]], %[[VAL_438]]
// CHECK:         %[[VAL_440:.*]] = udiv i32 %[[VAL_439]], 1
// CHECK:         %[[VAL_441:.*]] = urem i32 %[[VAL_440]], 32
// CHECK:         %[[VAL_442:.*]] = udiv i32 %[[VAL_439]], 32
// CHECK:         %[[VAL_443:.*]] = urem i32 %[[VAL_442]], 32
// CHECK:         %[[VAL_444:.*]] = udiv i32 %[[VAL_439]], 1024
// CHECK:         %[[VAL_445:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_446:.*]] = getelementptr inbounds float, float* %[[VAL_445]], i32 %[[VAL_439]]
// CHECK:         %[[VAL_447:.*]] = load float, float* %[[VAL_446]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_447]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_448:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_448]], float* %[[VAL_26]], float* %[[VAL_448]])
// CHECK:         %[[VAL_449:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_450:.*]] = getelementptr inbounds float, float* %[[VAL_449]], i32 %[[VAL_439]]
// CHECK:         %[[VAL_451:.*]] = load float, float* %[[VAL_450]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_451]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_452:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_452]], float* %[[VAL_24]], float* %[[VAL_452]])
// CHECK:         %[[VAL_453:.*]] = add i32 449, %[[VAL_69]]
// CHECK:         %[[VAL_454:.*]] = add i32 %[[VAL_70]], 449
// CHECK:         %[[VAL_455:.*]] = mul nuw nsw i32 %[[VAL_454]], 1
// CHECK:         %[[VAL_456:.*]] = add nuw nsw i32 0, %[[VAL_455]]
// CHECK:         %[[VAL_457:.*]] = mul nuw nsw i32 %[[VAL_137]], 32
// CHECK:         %[[VAL_458:.*]] = add nuw nsw i32 %[[VAL_456]], %[[VAL_457]]
// CHECK:         %[[VAL_459:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_460:.*]] = add nuw nsw i32 %[[VAL_458]], %[[VAL_459]]
// CHECK:         %[[VAL_461:.*]] = udiv i32 %[[VAL_460]], 1
// CHECK:         %[[VAL_462:.*]] = urem i32 %[[VAL_461]], 32
// CHECK:         %[[VAL_463:.*]] = udiv i32 %[[VAL_460]], 32
// CHECK:         %[[VAL_464:.*]] = urem i32 %[[VAL_463]], 32
// CHECK:         %[[VAL_465:.*]] = udiv i32 %[[VAL_460]], 1024
// CHECK:         %[[VAL_466:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_467:.*]] = getelementptr inbounds float, float* %[[VAL_466]], i32 %[[VAL_460]]
// CHECK:         %[[VAL_468:.*]] = load float, float* %[[VAL_467]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_468]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_469:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_469]], float* %[[VAL_26]], float* %[[VAL_469]])
// CHECK:         %[[VAL_470:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_471:.*]] = getelementptr inbounds float, float* %[[VAL_470]], i32 %[[VAL_460]]
// CHECK:         %[[VAL_472:.*]] = load float, float* %[[VAL_471]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_472]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_473:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_473]], float* %[[VAL_24]], float* %[[VAL_473]])
// CHECK:         br label %[[VAL_72]]
// CHECK:       output_is_full_tile-false:                        ; preds = %[[VAL_76]]
// CHECK:         %[[VAL_474:.*]] = add i32 %[[VAL_67]], %[[VAL_73]]
// CHECK:         %[[VAL_475:.*]] = add i32 0, %[[VAL_69]]
// CHECK:         %[[VAL_476:.*]] = add i32 %[[VAL_70]], 0
// CHECK:         %[[VAL_477:.*]] = icmp ult i32 %[[VAL_475]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_477]], label %[[VAL_478:.*]], label %[[VAL_479:.*]]
// CHECK:       output_x_in_tile-after:                           ; preds = %[[VAL_478]], %[[VAL_81]]
// CHECK:         %[[VAL_480:.*]] = add i32 1, %[[VAL_69]]
// CHECK:         %[[VAL_481:.*]] = add i32 %[[VAL_70]], 1
// CHECK:         %[[VAL_482:.*]] = icmp ult i32 %[[VAL_480]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_482]], label %[[VAL_483:.*]], label %[[VAL_484:.*]]
// CHECK:       output_x_in_tile-after88:                         ; preds = %[[VAL_483]], %[[VAL_479]]
// CHECK:         %[[VAL_485:.*]] = add i32 64, %[[VAL_69]]
// CHECK:         %[[VAL_486:.*]] = add i32 %[[VAL_70]], 64
// CHECK:         %[[VAL_487:.*]] = icmp ult i32 %[[VAL_485]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_487]], label %[[VAL_488:.*]], label %[[VAL_489:.*]]
// CHECK:       output_x_in_tile-after95:                         ; preds = %[[VAL_488]], %[[VAL_484]]
// CHECK:         %[[VAL_490:.*]] = add i32 65, %[[VAL_69]]
// CHECK:         %[[VAL_491:.*]] = add i32 %[[VAL_70]], 65
// CHECK:         %[[VAL_492:.*]] = icmp ult i32 %[[VAL_490]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_492]], label %[[VAL_493:.*]], label %[[VAL_494:.*]]
// CHECK:       output_x_in_tile-after102:                        ; preds = %[[VAL_493]], %[[VAL_489]]
// CHECK:         %[[VAL_495:.*]] = add i32 128, %[[VAL_69]]
// CHECK:         %[[VAL_496:.*]] = add i32 %[[VAL_70]], 128
// CHECK:         %[[VAL_497:.*]] = icmp ult i32 %[[VAL_495]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_497]], label %[[VAL_498:.*]], label %[[VAL_499:.*]]
// CHECK:       output_x_in_tile-after109:                        ; preds = %[[VAL_498]], %[[VAL_494]]
// CHECK:         %[[VAL_500:.*]] = add i32 129, %[[VAL_69]]
// CHECK:         %[[VAL_501:.*]] = add i32 %[[VAL_70]], 129
// CHECK:         %[[VAL_502:.*]] = icmp ult i32 %[[VAL_500]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_502]], label %[[VAL_503:.*]], label %[[VAL_504:.*]]
// CHECK:       output_x_in_tile-after116:                        ; preds = %[[VAL_503]], %[[VAL_499]]
// CHECK:         %[[VAL_505:.*]] = add i32 192, %[[VAL_69]]
// CHECK:         %[[VAL_506:.*]] = add i32 %[[VAL_70]], 192
// CHECK:         %[[VAL_507:.*]] = icmp ult i32 %[[VAL_505]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_507]], label %[[VAL_508:.*]], label %[[VAL_509:.*]]
// CHECK:       output_x_in_tile-after123:                        ; preds = %[[VAL_508]], %[[VAL_504]]
// CHECK:         %[[VAL_510:.*]] = add i32 193, %[[VAL_69]]
// CHECK:         %[[VAL_511:.*]] = add i32 %[[VAL_70]], 193
// CHECK:         %[[VAL_512:.*]] = icmp ult i32 %[[VAL_510]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_512]], label %[[VAL_513:.*]], label %[[VAL_514:.*]]
// CHECK:       output_x_in_tile-after130:                        ; preds = %[[VAL_513]], %[[VAL_509]]
// CHECK:         %[[VAL_515:.*]] = add i32 256, %[[VAL_69]]
// CHECK:         %[[VAL_516:.*]] = add i32 %[[VAL_70]], 256
// CHECK:         %[[VAL_517:.*]] = icmp ult i32 %[[VAL_515]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_517]], label %[[VAL_518:.*]], label %[[VAL_519:.*]]
// CHECK:       output_x_in_tile-after137:                        ; preds = %[[VAL_518]], %[[VAL_514]]
// CHECK:         %[[VAL_520:.*]] = add i32 257, %[[VAL_69]]
// CHECK:         %[[VAL_521:.*]] = add i32 %[[VAL_70]], 257
// CHECK:         %[[VAL_522:.*]] = icmp ult i32 %[[VAL_520]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_522]], label %[[VAL_523:.*]], label %[[VAL_524:.*]]
// CHECK:       output_x_in_tile-after144:                        ; preds = %[[VAL_523]], %[[VAL_519]]
// CHECK:         %[[VAL_525:.*]] = add i32 320, %[[VAL_69]]
// CHECK:         %[[VAL_526:.*]] = add i32 %[[VAL_70]], 320
// CHECK:         %[[VAL_527:.*]] = icmp ult i32 %[[VAL_525]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_527]], label %[[VAL_528:.*]], label %[[VAL_529:.*]]
// CHECK:       output_x_in_tile-after151:                        ; preds = %[[VAL_528]], %[[VAL_524]]
// CHECK:         %[[VAL_530:.*]] = add i32 321, %[[VAL_69]]
// CHECK:         %[[VAL_531:.*]] = add i32 %[[VAL_70]], 321
// CHECK:         %[[VAL_532:.*]] = icmp ult i32 %[[VAL_530]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_532]], label %[[VAL_533:.*]], label %[[VAL_534:.*]]
// CHECK:       output_x_in_tile-after158:                        ; preds = %[[VAL_533]], %[[VAL_529]]
// CHECK:         %[[VAL_535:.*]] = add i32 384, %[[VAL_69]]
// CHECK:         %[[VAL_536:.*]] = add i32 %[[VAL_70]], 384
// CHECK:         %[[VAL_537:.*]] = icmp ult i32 %[[VAL_535]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_537]], label %[[VAL_538:.*]], label %[[VAL_539:.*]]
// CHECK:       output_x_in_tile-after165:                        ; preds = %[[VAL_538]], %[[VAL_534]]
// CHECK:         %[[VAL_540:.*]] = add i32 385, %[[VAL_69]]
// CHECK:         %[[VAL_541:.*]] = add i32 %[[VAL_70]], 385
// CHECK:         %[[VAL_542:.*]] = icmp ult i32 %[[VAL_540]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_542]], label %[[VAL_543:.*]], label %[[VAL_544:.*]]
// CHECK:       output_x_in_tile-after172:                        ; preds = %[[VAL_543]], %[[VAL_539]]
// CHECK:         %[[VAL_545:.*]] = add i32 448, %[[VAL_69]]
// CHECK:         %[[VAL_546:.*]] = add i32 %[[VAL_70]], 448
// CHECK:         %[[VAL_547:.*]] = icmp ult i32 %[[VAL_545]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_547]], label %[[VAL_548:.*]], label %[[VAL_549:.*]]
// CHECK:       output_x_in_tile-after179:                        ; preds = %[[VAL_548]], %[[VAL_544]]
// CHECK:         %[[VAL_550:.*]] = add i32 449, %[[VAL_69]]
// CHECK:         %[[VAL_551:.*]] = add i32 %[[VAL_70]], 449
// CHECK:         %[[VAL_552:.*]] = icmp ult i32 %[[VAL_550]], %[[VAL_66]]
// CHECK:         br i1 %[[VAL_552]], label %[[VAL_553:.*]], label %[[VAL_82]]
// CHECK:       output_x_in_tile-after186:                        ; preds = %[[VAL_553]], %[[VAL_549]]
// CHECK:         br label %[[VAL_72]]
// CHECK:       output_x_in_tile-true:                            ; preds = %[[VAL_81]]
// CHECK:         %[[VAL_554:.*]] = mul nuw nsw i32 %[[VAL_476]], 1
// CHECK:         %[[VAL_555:.*]] = add nuw nsw i32 0, %[[VAL_554]]
// CHECK:         %[[VAL_556:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_557:.*]] = add nuw nsw i32 %[[VAL_555]], %[[VAL_556]]
// CHECK:         %[[VAL_558:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_559:.*]] = add nuw nsw i32 %[[VAL_557]], %[[VAL_558]]
// CHECK:         %[[VAL_560:.*]] = udiv i32 %[[VAL_559]], 1
// CHECK:         %[[VAL_561:.*]] = urem i32 %[[VAL_560]], 32
// CHECK:         %[[VAL_562:.*]] = udiv i32 %[[VAL_559]], 32
// CHECK:         %[[VAL_563:.*]] = urem i32 %[[VAL_562]], 32
// CHECK:         %[[VAL_564:.*]] = udiv i32 %[[VAL_559]], 1024
// CHECK:         %[[VAL_565:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_566:.*]] = getelementptr inbounds float, float* %[[VAL_565]], i32 %[[VAL_559]]
// CHECK:         %[[VAL_567:.*]] = load float, float* %[[VAL_566]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_567]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_568:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_568]], float* %[[VAL_26]], float* %[[VAL_568]])
// CHECK:         %[[VAL_569:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_570:.*]] = getelementptr inbounds float, float* %[[VAL_569]], i32 %[[VAL_559]]
// CHECK:         %[[VAL_571:.*]] = load float, float* %[[VAL_570]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_571]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_572:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_572]], float* %[[VAL_24]], float* %[[VAL_572]])
// CHECK:         br label %[[VAL_479]]
// CHECK:       output_x_in_tile-true87:                          ; preds = %[[VAL_479]]
// CHECK:         %[[VAL_573:.*]] = mul nuw nsw i32 %[[VAL_481]], 1
// CHECK:         %[[VAL_574:.*]] = add nuw nsw i32 0, %[[VAL_573]]
// CHECK:         %[[VAL_575:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_576:.*]] = add nuw nsw i32 %[[VAL_574]], %[[VAL_575]]
// CHECK:         %[[VAL_577:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_578:.*]] = add nuw nsw i32 %[[VAL_576]], %[[VAL_577]]
// CHECK:         %[[VAL_579:.*]] = udiv i32 %[[VAL_578]], 1
// CHECK:         %[[VAL_580:.*]] = urem i32 %[[VAL_579]], 32
// CHECK:         %[[VAL_581:.*]] = udiv i32 %[[VAL_578]], 32
// CHECK:         %[[VAL_582:.*]] = urem i32 %[[VAL_581]], 32
// CHECK:         %[[VAL_583:.*]] = udiv i32 %[[VAL_578]], 1024
// CHECK:         %[[VAL_584:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_585:.*]] = getelementptr inbounds float, float* %[[VAL_584]], i32 %[[VAL_578]]
// CHECK:         %[[VAL_586:.*]] = load float, float* %[[VAL_585]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_586]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_587:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_587]], float* %[[VAL_26]], float* %[[VAL_587]])
// CHECK:         %[[VAL_588:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_589:.*]] = getelementptr inbounds float, float* %[[VAL_588]], i32 %[[VAL_578]]
// CHECK:         %[[VAL_590:.*]] = load float, float* %[[VAL_589]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_590]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_591:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_591]], float* %[[VAL_24]], float* %[[VAL_591]])
// CHECK:         br label %[[VAL_484]]
// CHECK:       output_x_in_tile-true94:                          ; preds = %[[VAL_484]]
// CHECK:         %[[VAL_592:.*]] = mul nuw nsw i32 %[[VAL_486]], 1
// CHECK:         %[[VAL_593:.*]] = add nuw nsw i32 0, %[[VAL_592]]
// CHECK:         %[[VAL_594:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_595:.*]] = add nuw nsw i32 %[[VAL_593]], %[[VAL_594]]
// CHECK:         %[[VAL_596:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_597:.*]] = add nuw nsw i32 %[[VAL_595]], %[[VAL_596]]
// CHECK:         %[[VAL_598:.*]] = udiv i32 %[[VAL_597]], 1
// CHECK:         %[[VAL_599:.*]] = urem i32 %[[VAL_598]], 32
// CHECK:         %[[VAL_600:.*]] = udiv i32 %[[VAL_597]], 32
// CHECK:         %[[VAL_601:.*]] = urem i32 %[[VAL_600]], 32
// CHECK:         %[[VAL_602:.*]] = udiv i32 %[[VAL_597]], 1024
// CHECK:         %[[VAL_603:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_604:.*]] = getelementptr inbounds float, float* %[[VAL_603]], i32 %[[VAL_597]]
// CHECK:         %[[VAL_605:.*]] = load float, float* %[[VAL_604]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_605]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_606:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_606]], float* %[[VAL_26]], float* %[[VAL_606]])
// CHECK:         %[[VAL_607:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_608:.*]] = getelementptr inbounds float, float* %[[VAL_607]], i32 %[[VAL_597]]
// CHECK:         %[[VAL_609:.*]] = load float, float* %[[VAL_608]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_609]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_610:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_610]], float* %[[VAL_24]], float* %[[VAL_610]])
// CHECK:         br label %[[VAL_489]]
// CHECK:       output_x_in_tile-true101:                         ; preds = %[[VAL_489]]
// CHECK:         %[[VAL_611:.*]] = mul nuw nsw i32 %[[VAL_491]], 1
// CHECK:         %[[VAL_612:.*]] = add nuw nsw i32 0, %[[VAL_611]]
// CHECK:         %[[VAL_613:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_614:.*]] = add nuw nsw i32 %[[VAL_612]], %[[VAL_613]]
// CHECK:         %[[VAL_615:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_616:.*]] = add nuw nsw i32 %[[VAL_614]], %[[VAL_615]]
// CHECK:         %[[VAL_617:.*]] = udiv i32 %[[VAL_616]], 1
// CHECK:         %[[VAL_618:.*]] = urem i32 %[[VAL_617]], 32
// CHECK:         %[[VAL_619:.*]] = udiv i32 %[[VAL_616]], 32
// CHECK:         %[[VAL_620:.*]] = urem i32 %[[VAL_619]], 32
// CHECK:         %[[VAL_621:.*]] = udiv i32 %[[VAL_616]], 1024
// CHECK:         %[[VAL_622:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_623:.*]] = getelementptr inbounds float, float* %[[VAL_622]], i32 %[[VAL_616]]
// CHECK:         %[[VAL_624:.*]] = load float, float* %[[VAL_623]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_624]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_625:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_625]], float* %[[VAL_26]], float* %[[VAL_625]])
// CHECK:         %[[VAL_626:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_627:.*]] = getelementptr inbounds float, float* %[[VAL_626]], i32 %[[VAL_616]]
// CHECK:         %[[VAL_628:.*]] = load float, float* %[[VAL_627]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_628]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_629:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_629]], float* %[[VAL_24]], float* %[[VAL_629]])
// CHECK:         br label %[[VAL_494]]
// CHECK:       output_x_in_tile-true108:                         ; preds = %[[VAL_494]]
// CHECK:         %[[VAL_630:.*]] = mul nuw nsw i32 %[[VAL_496]], 1
// CHECK:         %[[VAL_631:.*]] = add nuw nsw i32 0, %[[VAL_630]]
// CHECK:         %[[VAL_632:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_633:.*]] = add nuw nsw i32 %[[VAL_631]], %[[VAL_632]]
// CHECK:         %[[VAL_634:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_635:.*]] = add nuw nsw i32 %[[VAL_633]], %[[VAL_634]]
// CHECK:         %[[VAL_636:.*]] = udiv i32 %[[VAL_635]], 1
// CHECK:         %[[VAL_637:.*]] = urem i32 %[[VAL_636]], 32
// CHECK:         %[[VAL_638:.*]] = udiv i32 %[[VAL_635]], 32
// CHECK:         %[[VAL_639:.*]] = urem i32 %[[VAL_638]], 32
// CHECK:         %[[VAL_640:.*]] = udiv i32 %[[VAL_635]], 1024
// CHECK:         %[[VAL_641:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_642:.*]] = getelementptr inbounds float, float* %[[VAL_641]], i32 %[[VAL_635]]
// CHECK:         %[[VAL_643:.*]] = load float, float* %[[VAL_642]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_643]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_644:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_644]], float* %[[VAL_26]], float* %[[VAL_644]])
// CHECK:         %[[VAL_645:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_646:.*]] = getelementptr inbounds float, float* %[[VAL_645]], i32 %[[VAL_635]]
// CHECK:         %[[VAL_647:.*]] = load float, float* %[[VAL_646]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_647]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_648:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_648]], float* %[[VAL_24]], float* %[[VAL_648]])
// CHECK:         br label %[[VAL_499]]
// CHECK:       output_x_in_tile-true115:                         ; preds = %[[VAL_499]]
// CHECK:         %[[VAL_649:.*]] = mul nuw nsw i32 %[[VAL_501]], 1
// CHECK:         %[[VAL_650:.*]] = add nuw nsw i32 0, %[[VAL_649]]
// CHECK:         %[[VAL_651:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_652:.*]] = add nuw nsw i32 %[[VAL_650]], %[[VAL_651]]
// CHECK:         %[[VAL_653:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_654:.*]] = add nuw nsw i32 %[[VAL_652]], %[[VAL_653]]
// CHECK:         %[[VAL_655:.*]] = udiv i32 %[[VAL_654]], 1
// CHECK:         %[[VAL_656:.*]] = urem i32 %[[VAL_655]], 32
// CHECK:         %[[VAL_657:.*]] = udiv i32 %[[VAL_654]], 32
// CHECK:         %[[VAL_658:.*]] = urem i32 %[[VAL_657]], 32
// CHECK:         %[[VAL_659:.*]] = udiv i32 %[[VAL_654]], 1024
// CHECK:         %[[VAL_660:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_661:.*]] = getelementptr inbounds float, float* %[[VAL_660]], i32 %[[VAL_654]]
// CHECK:         %[[VAL_662:.*]] = load float, float* %[[VAL_661]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_662]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_663:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_663]], float* %[[VAL_26]], float* %[[VAL_663]])
// CHECK:         %[[VAL_664:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_665:.*]] = getelementptr inbounds float, float* %[[VAL_664]], i32 %[[VAL_654]]
// CHECK:         %[[VAL_666:.*]] = load float, float* %[[VAL_665]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_666]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_667:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_667]], float* %[[VAL_24]], float* %[[VAL_667]])
// CHECK:         br label %[[VAL_504]]
// CHECK:       output_x_in_tile-true122:                         ; preds = %[[VAL_504]]
// CHECK:         %[[VAL_668:.*]] = mul nuw nsw i32 %[[VAL_506]], 1
// CHECK:         %[[VAL_669:.*]] = add nuw nsw i32 0, %[[VAL_668]]
// CHECK:         %[[VAL_670:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_671:.*]] = add nuw nsw i32 %[[VAL_669]], %[[VAL_670]]
// CHECK:         %[[VAL_672:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_673:.*]] = add nuw nsw i32 %[[VAL_671]], %[[VAL_672]]
// CHECK:         %[[VAL_674:.*]] = udiv i32 %[[VAL_673]], 1
// CHECK:         %[[VAL_675:.*]] = urem i32 %[[VAL_674]], 32
// CHECK:         %[[VAL_676:.*]] = udiv i32 %[[VAL_673]], 32
// CHECK:         %[[VAL_677:.*]] = urem i32 %[[VAL_676]], 32
// CHECK:         %[[VAL_678:.*]] = udiv i32 %[[VAL_673]], 1024
// CHECK:         %[[VAL_679:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_680:.*]] = getelementptr inbounds float, float* %[[VAL_679]], i32 %[[VAL_673]]
// CHECK:         %[[VAL_681:.*]] = load float, float* %[[VAL_680]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_681]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_682:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_682]], float* %[[VAL_26]], float* %[[VAL_682]])
// CHECK:         %[[VAL_683:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_684:.*]] = getelementptr inbounds float, float* %[[VAL_683]], i32 %[[VAL_673]]
// CHECK:         %[[VAL_685:.*]] = load float, float* %[[VAL_684]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_685]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_686:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_686]], float* %[[VAL_24]], float* %[[VAL_686]])
// CHECK:         br label %[[VAL_509]]
// CHECK:       output_x_in_tile-true129:                         ; preds = %[[VAL_509]]
// CHECK:         %[[VAL_687:.*]] = mul nuw nsw i32 %[[VAL_511]], 1
// CHECK:         %[[VAL_688:.*]] = add nuw nsw i32 0, %[[VAL_687]]
// CHECK:         %[[VAL_689:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_690:.*]] = add nuw nsw i32 %[[VAL_688]], %[[VAL_689]]
// CHECK:         %[[VAL_691:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_692:.*]] = add nuw nsw i32 %[[VAL_690]], %[[VAL_691]]
// CHECK:         %[[VAL_693:.*]] = udiv i32 %[[VAL_692]], 1
// CHECK:         %[[VAL_694:.*]] = urem i32 %[[VAL_693]], 32
// CHECK:         %[[VAL_695:.*]] = udiv i32 %[[VAL_692]], 32
// CHECK:         %[[VAL_696:.*]] = urem i32 %[[VAL_695]], 32
// CHECK:         %[[VAL_697:.*]] = udiv i32 %[[VAL_692]], 1024
// CHECK:         %[[VAL_698:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_699:.*]] = getelementptr inbounds float, float* %[[VAL_698]], i32 %[[VAL_692]]
// CHECK:         %[[VAL_700:.*]] = load float, float* %[[VAL_699]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_700]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_701:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_701]], float* %[[VAL_26]], float* %[[VAL_701]])
// CHECK:         %[[VAL_702:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_703:.*]] = getelementptr inbounds float, float* %[[VAL_702]], i32 %[[VAL_692]]
// CHECK:         %[[VAL_704:.*]] = load float, float* %[[VAL_703]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_704]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_705:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_705]], float* %[[VAL_24]], float* %[[VAL_705]])
// CHECK:         br label %[[VAL_514]]
// CHECK:       output_x_in_tile-true136:                         ; preds = %[[VAL_514]]
// CHECK:         %[[VAL_706:.*]] = mul nuw nsw i32 %[[VAL_516]], 1
// CHECK:         %[[VAL_707:.*]] = add nuw nsw i32 0, %[[VAL_706]]
// CHECK:         %[[VAL_708:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_709:.*]] = add nuw nsw i32 %[[VAL_707]], %[[VAL_708]]
// CHECK:         %[[VAL_710:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_711:.*]] = add nuw nsw i32 %[[VAL_709]], %[[VAL_710]]
// CHECK:         %[[VAL_712:.*]] = udiv i32 %[[VAL_711]], 1
// CHECK:         %[[VAL_713:.*]] = urem i32 %[[VAL_712]], 32
// CHECK:         %[[VAL_714:.*]] = udiv i32 %[[VAL_711]], 32
// CHECK:         %[[VAL_715:.*]] = urem i32 %[[VAL_714]], 32
// CHECK:         %[[VAL_716:.*]] = udiv i32 %[[VAL_711]], 1024
// CHECK:         %[[VAL_717:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_718:.*]] = getelementptr inbounds float, float* %[[VAL_717]], i32 %[[VAL_711]]
// CHECK:         %[[VAL_719:.*]] = load float, float* %[[VAL_718]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_719]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_720:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_720]], float* %[[VAL_26]], float* %[[VAL_720]])
// CHECK:         %[[VAL_721:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_722:.*]] = getelementptr inbounds float, float* %[[VAL_721]], i32 %[[VAL_711]]
// CHECK:         %[[VAL_723:.*]] = load float, float* %[[VAL_722]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_723]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_724:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_724]], float* %[[VAL_24]], float* %[[VAL_724]])
// CHECK:         br label %[[VAL_519]]
// CHECK:       output_x_in_tile-true143:                         ; preds = %[[VAL_519]]
// CHECK:         %[[VAL_725:.*]] = mul nuw nsw i32 %[[VAL_521]], 1
// CHECK:         %[[VAL_726:.*]] = add nuw nsw i32 0, %[[VAL_725]]
// CHECK:         %[[VAL_727:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_728:.*]] = add nuw nsw i32 %[[VAL_726]], %[[VAL_727]]
// CHECK:         %[[VAL_729:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_730:.*]] = add nuw nsw i32 %[[VAL_728]], %[[VAL_729]]
// CHECK:         %[[VAL_731:.*]] = udiv i32 %[[VAL_730]], 1
// CHECK:         %[[VAL_732:.*]] = urem i32 %[[VAL_731]], 32
// CHECK:         %[[VAL_733:.*]] = udiv i32 %[[VAL_730]], 32
// CHECK:         %[[VAL_734:.*]] = urem i32 %[[VAL_733]], 32
// CHECK:         %[[VAL_735:.*]] = udiv i32 %[[VAL_730]], 1024
// CHECK:         %[[VAL_736:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_737:.*]] = getelementptr inbounds float, float* %[[VAL_736]], i32 %[[VAL_730]]
// CHECK:         %[[VAL_738:.*]] = load float, float* %[[VAL_737]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_738]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_739:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_739]], float* %[[VAL_26]], float* %[[VAL_739]])
// CHECK:         %[[VAL_740:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_741:.*]] = getelementptr inbounds float, float* %[[VAL_740]], i32 %[[VAL_730]]
// CHECK:         %[[VAL_742:.*]] = load float, float* %[[VAL_741]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_742]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_743:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_743]], float* %[[VAL_24]], float* %[[VAL_743]])
// CHECK:         br label %[[VAL_524]]
// CHECK:       output_x_in_tile-true150:                         ; preds = %[[VAL_524]]
// CHECK:         %[[VAL_744:.*]] = mul nuw nsw i32 %[[VAL_526]], 1
// CHECK:         %[[VAL_745:.*]] = add nuw nsw i32 0, %[[VAL_744]]
// CHECK:         %[[VAL_746:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_747:.*]] = add nuw nsw i32 %[[VAL_745]], %[[VAL_746]]
// CHECK:         %[[VAL_748:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_749:.*]] = add nuw nsw i32 %[[VAL_747]], %[[VAL_748]]
// CHECK:         %[[VAL_750:.*]] = udiv i32 %[[VAL_749]], 1
// CHECK:         %[[VAL_751:.*]] = urem i32 %[[VAL_750]], 32
// CHECK:         %[[VAL_752:.*]] = udiv i32 %[[VAL_749]], 32
// CHECK:         %[[VAL_753:.*]] = urem i32 %[[VAL_752]], 32
// CHECK:         %[[VAL_754:.*]] = udiv i32 %[[VAL_749]], 1024
// CHECK:         %[[VAL_755:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_756:.*]] = getelementptr inbounds float, float* %[[VAL_755]], i32 %[[VAL_749]]
// CHECK:         %[[VAL_757:.*]] = load float, float* %[[VAL_756]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_757]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_758:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_758]], float* %[[VAL_26]], float* %[[VAL_758]])
// CHECK:         %[[VAL_759:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_760:.*]] = getelementptr inbounds float, float* %[[VAL_759]], i32 %[[VAL_749]]
// CHECK:         %[[VAL_761:.*]] = load float, float* %[[VAL_760]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_761]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_762:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_762]], float* %[[VAL_24]], float* %[[VAL_762]])
// CHECK:         br label %[[VAL_529]]
// CHECK:       output_x_in_tile-true157:                         ; preds = %[[VAL_529]]
// CHECK:         %[[VAL_763:.*]] = mul nuw nsw i32 %[[VAL_531]], 1
// CHECK:         %[[VAL_764:.*]] = add nuw nsw i32 0, %[[VAL_763]]
// CHECK:         %[[VAL_765:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_766:.*]] = add nuw nsw i32 %[[VAL_764]], %[[VAL_765]]
// CHECK:         %[[VAL_767:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_768:.*]] = add nuw nsw i32 %[[VAL_766]], %[[VAL_767]]
// CHECK:         %[[VAL_769:.*]] = udiv i32 %[[VAL_768]], 1
// CHECK:         %[[VAL_770:.*]] = urem i32 %[[VAL_769]], 32
// CHECK:         %[[VAL_771:.*]] = udiv i32 %[[VAL_768]], 32
// CHECK:         %[[VAL_772:.*]] = urem i32 %[[VAL_771]], 32
// CHECK:         %[[VAL_773:.*]] = udiv i32 %[[VAL_768]], 1024
// CHECK:         %[[VAL_774:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_775:.*]] = getelementptr inbounds float, float* %[[VAL_774]], i32 %[[VAL_768]]
// CHECK:         %[[VAL_776:.*]] = load float, float* %[[VAL_775]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_776]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_777:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_777]], float* %[[VAL_26]], float* %[[VAL_777]])
// CHECK:         %[[VAL_778:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_779:.*]] = getelementptr inbounds float, float* %[[VAL_778]], i32 %[[VAL_768]]
// CHECK:         %[[VAL_780:.*]] = load float, float* %[[VAL_779]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_780]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_781:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_781]], float* %[[VAL_24]], float* %[[VAL_781]])
// CHECK:         br label %[[VAL_534]]
// CHECK:       output_x_in_tile-true164:                         ; preds = %[[VAL_534]]
// CHECK:         %[[VAL_782:.*]] = mul nuw nsw i32 %[[VAL_536]], 1
// CHECK:         %[[VAL_783:.*]] = add nuw nsw i32 0, %[[VAL_782]]
// CHECK:         %[[VAL_784:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_785:.*]] = add nuw nsw i32 %[[VAL_783]], %[[VAL_784]]
// CHECK:         %[[VAL_786:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_787:.*]] = add nuw nsw i32 %[[VAL_785]], %[[VAL_786]]
// CHECK:         %[[VAL_788:.*]] = udiv i32 %[[VAL_787]], 1
// CHECK:         %[[VAL_789:.*]] = urem i32 %[[VAL_788]], 32
// CHECK:         %[[VAL_790:.*]] = udiv i32 %[[VAL_787]], 32
// CHECK:         %[[VAL_791:.*]] = urem i32 %[[VAL_790]], 32
// CHECK:         %[[VAL_792:.*]] = udiv i32 %[[VAL_787]], 1024
// CHECK:         %[[VAL_793:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_794:.*]] = getelementptr inbounds float, float* %[[VAL_793]], i32 %[[VAL_787]]
// CHECK:         %[[VAL_795:.*]] = load float, float* %[[VAL_794]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_795]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_796:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_796]], float* %[[VAL_26]], float* %[[VAL_796]])
// CHECK:         %[[VAL_797:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_798:.*]] = getelementptr inbounds float, float* %[[VAL_797]], i32 %[[VAL_787]]
// CHECK:         %[[VAL_799:.*]] = load float, float* %[[VAL_798]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_799]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_800:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_800]], float* %[[VAL_24]], float* %[[VAL_800]])
// CHECK:         br label %[[VAL_539]]
// CHECK:       output_x_in_tile-true171:                         ; preds = %[[VAL_539]]
// CHECK:         %[[VAL_801:.*]] = mul nuw nsw i32 %[[VAL_541]], 1
// CHECK:         %[[VAL_802:.*]] = add nuw nsw i32 0, %[[VAL_801]]
// CHECK:         %[[VAL_803:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_804:.*]] = add nuw nsw i32 %[[VAL_802]], %[[VAL_803]]
// CHECK:         %[[VAL_805:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_806:.*]] = add nuw nsw i32 %[[VAL_804]], %[[VAL_805]]
// CHECK:         %[[VAL_807:.*]] = udiv i32 %[[VAL_806]], 1
// CHECK:         %[[VAL_808:.*]] = urem i32 %[[VAL_807]], 32
// CHECK:         %[[VAL_809:.*]] = udiv i32 %[[VAL_806]], 32
// CHECK:         %[[VAL_810:.*]] = urem i32 %[[VAL_809]], 32
// CHECK:         %[[VAL_811:.*]] = udiv i32 %[[VAL_806]], 1024
// CHECK:         %[[VAL_812:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_813:.*]] = getelementptr inbounds float, float* %[[VAL_812]], i32 %[[VAL_806]]
// CHECK:         %[[VAL_814:.*]] = load float, float* %[[VAL_813]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_814]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_815:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_815]], float* %[[VAL_26]], float* %[[VAL_815]])
// CHECK:         %[[VAL_816:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_817:.*]] = getelementptr inbounds float, float* %[[VAL_816]], i32 %[[VAL_806]]
// CHECK:         %[[VAL_818:.*]] = load float, float* %[[VAL_817]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_818]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_819:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_819]], float* %[[VAL_24]], float* %[[VAL_819]])
// CHECK:         br label %[[VAL_544]]
// CHECK:       output_x_in_tile-true178:                         ; preds = %[[VAL_544]]
// CHECK:         %[[VAL_820:.*]] = mul nuw nsw i32 %[[VAL_546]], 1
// CHECK:         %[[VAL_821:.*]] = add nuw nsw i32 0, %[[VAL_820]]
// CHECK:         %[[VAL_822:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_823:.*]] = add nuw nsw i32 %[[VAL_821]], %[[VAL_822]]
// CHECK:         %[[VAL_824:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_825:.*]] = add nuw nsw i32 %[[VAL_823]], %[[VAL_824]]
// CHECK:         %[[VAL_826:.*]] = udiv i32 %[[VAL_825]], 1
// CHECK:         %[[VAL_827:.*]] = urem i32 %[[VAL_826]], 32
// CHECK:         %[[VAL_828:.*]] = udiv i32 %[[VAL_825]], 32
// CHECK:         %[[VAL_829:.*]] = urem i32 %[[VAL_828]], 32
// CHECK:         %[[VAL_830:.*]] = udiv i32 %[[VAL_825]], 1024
// CHECK:         %[[VAL_831:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_832:.*]] = getelementptr inbounds float, float* %[[VAL_831]], i32 %[[VAL_825]]
// CHECK:         %[[VAL_833:.*]] = load float, float* %[[VAL_832]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_833]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_834:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_834]], float* %[[VAL_26]], float* %[[VAL_834]])
// CHECK:         %[[VAL_835:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_836:.*]] = getelementptr inbounds float, float* %[[VAL_835]], i32 %[[VAL_825]]
// CHECK:         %[[VAL_837:.*]] = load float, float* %[[VAL_836]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_837]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_838:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_838]], float* %[[VAL_24]], float* %[[VAL_838]])
// CHECK:         br label %[[VAL_549]]
// CHECK:       output_x_in_tile-true185:                         ; preds = %[[VAL_549]]
// CHECK:         %[[VAL_839:.*]] = mul nuw nsw i32 %[[VAL_551]], 1
// CHECK:         %[[VAL_840:.*]] = add nuw nsw i32 0, %[[VAL_839]]
// CHECK:         %[[VAL_841:.*]] = mul nuw nsw i32 %[[VAL_474]], 32
// CHECK:         %[[VAL_842:.*]] = add nuw nsw i32 %[[VAL_840]], %[[VAL_841]]
// CHECK:         %[[VAL_843:.*]] = mul nuw nsw i32 %[[VAL_62]], 2048
// CHECK:         %[[VAL_844:.*]] = add nuw nsw i32 %[[VAL_842]], %[[VAL_843]]
// CHECK:         %[[VAL_845:.*]] = udiv i32 %[[VAL_844]], 1
// CHECK:         %[[VAL_846:.*]] = urem i32 %[[VAL_845]], 32
// CHECK:         %[[VAL_847:.*]] = udiv i32 %[[VAL_844]], 32
// CHECK:         %[[VAL_848:.*]] = urem i32 %[[VAL_847]], 32
// CHECK:         %[[VAL_849:.*]] = udiv i32 %[[VAL_844]], 1024
// CHECK:         %[[VAL_850:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_851:.*]] = getelementptr inbounds float, float* %[[VAL_850]], i32 %[[VAL_844]]
// CHECK:         %[[VAL_852:.*]] = load float, float* %[[VAL_851]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_852]], float* %[[VAL_26]], align 4
// CHECK:         %[[VAL_853:.*]] = getelementptr inbounds float, float* %[[VAL_25]], i32 0
// CHECK:         call void @region_1_4(float* %[[VAL_853]], float* %[[VAL_26]], float* %[[VAL_853]])
// CHECK:         %[[VAL_854:.*]] = bitcast [2 x [32 x [32 x float]]]* %[[VAL_29]] to float*
// CHECK:         %[[VAL_855:.*]] = getelementptr inbounds float, float* %[[VAL_854]], i32 %[[VAL_844]]
// CHECK:         %[[VAL_856:.*]] = load float, float* %[[VAL_855]], align 4, !invariant.load !3
// CHECK:         store float %[[VAL_856]], float* %[[VAL_24]], align 4
// CHECK:         %[[VAL_857:.*]] = getelementptr inbounds float, float* %[[VAL_23]], i32 0
// CHECK:         call void @region_2_9(float* %[[VAL_857]], float* %[[VAL_24]], float* %[[VAL_857]])
// CHECK:         br label %[[VAL_82]]
// CHECK:       intra_warp_reduce_write-true:                     ; preds = %[[VAL_75]]
// CHECK:         %[[VAL_858:.*]] = getelementptr inbounds [1 x [32 x float]], [1 x [32 x float]] addrspace(3)* @shared_cache_0, i32 0, i32 0, i32 %[[VAL_106]]
// CHECK:         %[[VAL_859:.*]] = addrspacecast float addrspace(3)* %[[VAL_858]] to float*
// CHECK:         %[[VAL_860:.*]] = load float, float* %[[VAL_95]], align 4
// CHECK:         store float %[[VAL_860]], float* %[[VAL_859]], align 4
// CHECK:         br label %[[VAL_109]]
// CHECK:       inter_warp_reduce-true:                           ; preds = %[[VAL_109]]
// CHECK:         %[[VAL_861:.*]] = getelementptr inbounds [1 x [32 x float]], [1 x [32 x float]] addrspace(3)* @shared_cache_0, i32 0, i32 0, i32 %[[VAL_86]]
// CHECK:         %[[VAL_862:.*]] = addrspacecast float addrspace(3)* %[[VAL_861]] to float*
// CHECK:         store float %[[VAL_48]], float* %[[VAL_16]], align 4
// CHECK:         %[[VAL_863:.*]] = icmp ult i32 %[[VAL_84]], 1
// CHECK:         %[[VAL_864:.*]] = select i1 %[[VAL_863]], float* %[[VAL_862]], float* %[[VAL_16]]
// CHECK:         %[[VAL_865:.*]] = load float, float* %[[VAL_864]], align 4
// CHECK:         %[[VAL_866:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_865]], i32 16, i32 31)
// CHECK:         store float %[[VAL_866]], float* %[[VAL_15]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_864]], float* %[[VAL_15]], float* %[[VAL_864]])
// CHECK:         %[[VAL_867:.*]] = load float, float* %[[VAL_864]], align 4
// CHECK:         %[[VAL_868:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_867]], i32 8, i32 31)
// CHECK:         store float %[[VAL_868]], float* %[[VAL_14]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_864]], float* %[[VAL_14]], float* %[[VAL_864]])
// CHECK:         %[[VAL_869:.*]] = load float, float* %[[VAL_864]], align 4
// CHECK:         %[[VAL_870:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_869]], i32 4, i32 31)
// CHECK:         store float %[[VAL_870]], float* %[[VAL_13]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_864]], float* %[[VAL_13]], float* %[[VAL_864]])
// CHECK:         %[[VAL_871:.*]] = load float, float* %[[VAL_864]], align 4
// CHECK:         %[[VAL_872:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_871]], i32 2, i32 31)
// CHECK:         store float %[[VAL_872]], float* %[[VAL_12]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_864]], float* %[[VAL_12]], float* %[[VAL_864]])
// CHECK:         %[[VAL_873:.*]] = load float, float* %[[VAL_864]], align 4
// CHECK:         %[[VAL_874:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_873]], i32 1, i32 31)
// CHECK:         store float %[[VAL_874]], float* %[[VAL_11]], align 4
// CHECK:         call void @region_1_4(float* %[[VAL_864]], float* %[[VAL_11]], float* %[[VAL_864]])
// CHECK:         %[[VAL_875:.*]] = icmp eq i32 %[[VAL_84]], 0
// CHECK:         br i1 %[[VAL_875]], label %[[VAL_876:.*]], label %[[VAL_113]]
// CHECK:       reduction_write_output-after:                     ; preds = %[[VAL_876]], %[[VAL_111]]
// CHECK:         br label %[[VAL_112]]
// CHECK:       reduction_write_output-true:                      ; preds = %[[VAL_111]]
// CHECK:         %[[VAL_877:.*]] = load float, float* %[[VAL_862]], align 4
// CHECK:         store float %[[VAL_877]], float* %[[VAL_94]], align 4
// CHECK:         br label %[[VAL_113]]
// CHECK:       intra_warp_reduce_write-true224:                  ; preds = %[[VAL_112]]
// CHECK:         %[[VAL_878:.*]] = getelementptr inbounds [1 x [32 x float]], [1 x [32 x float]] addrspace(3)* @shared_cache_1, i32 0, i32 0, i32 %[[VAL_130]]
// CHECK:         %[[VAL_879:.*]] = addrspacecast float addrspace(3)* %[[VAL_878]] to float*
// CHECK:         %[[VAL_880:.*]] = load float, float* %[[VAL_119]], align 4
// CHECK:         store float %[[VAL_880]], float* %[[VAL_879]], align 4
// CHECK:         br label %[[VAL_133]]
// CHECK:       inter_warp_reduce-true226:                        ; preds = %[[VAL_133]]
// CHECK:         %[[VAL_881:.*]] = getelementptr inbounds [1 x [32 x float]], [1 x [32 x float]] addrspace(3)* @shared_cache_1, i32 0, i32 0, i32 %[[VAL_86]]
// CHECK:         %[[VAL_882:.*]] = addrspacecast float addrspace(3)* %[[VAL_881]] to float*
// CHECK:         store float %[[VAL_50]], float* %[[VAL_5]], align 4
// CHECK:         %[[VAL_883:.*]] = icmp ult i32 %[[VAL_84]], 1
// CHECK:         %[[VAL_884:.*]] = select i1 %[[VAL_883]], float* %[[VAL_882]], float* %[[VAL_5]]
// CHECK:         %[[VAL_885:.*]] = load float, float* %[[VAL_884]], align 4
// CHECK:         %[[VAL_886:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_885]], i32 16, i32 31)
// CHECK:         store float %[[VAL_886]], float* %[[VAL_4]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_884]], float* %[[VAL_4]], float* %[[VAL_884]])
// CHECK:         %[[VAL_887:.*]] = load float, float* %[[VAL_884]], align 4
// CHECK:         %[[VAL_888:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_887]], i32 8, i32 31)
// CHECK:         store float %[[VAL_888]], float* %[[VAL_3]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_884]], float* %[[VAL_3]], float* %[[VAL_884]])
// CHECK:         %[[VAL_889:.*]] = load float, float* %[[VAL_884]], align 4
// CHECK:         %[[VAL_890:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_889]], i32 4, i32 31)
// CHECK:         store float %[[VAL_890]], float* %[[VAL_2]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_884]], float* %[[VAL_2]], float* %[[VAL_884]])
// CHECK:         %[[VAL_891:.*]] = load float, float* %[[VAL_884]], align 4
// CHECK:         %[[VAL_892:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_891]], i32 2, i32 31)
// CHECK:         store float %[[VAL_892]], float* %[[VAL_1]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_884]], float* %[[VAL_1]], float* %[[VAL_884]])
// CHECK:         %[[VAL_893:.*]] = load float, float* %[[VAL_884]], align 4
// CHECK:         %[[VAL_894:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_893]], i32 1, i32 31)
// CHECK:         store float %[[VAL_894]], float* %[[VAL_0]], align 4
// CHECK:         call void @region_2_9(float* %[[VAL_884]], float* %[[VAL_0]], float* %[[VAL_884]])
// CHECK:         %[[VAL_895:.*]] = icmp eq i32 %[[VAL_84]], 0
// CHECK:         br i1 %[[VAL_895]], label %[[VAL_896:.*]], label %[[VAL_136]]
// CHECK:       reduction_write_output-after240:                  ; preds = %[[VAL_896]], %[[VAL_135]]
// CHECK:         br label %[[VAL_46]]
// CHECK:       reduction_write_output-true239:                   ; preds = %[[VAL_135]]
// CHECK:         %[[VAL_897:.*]] = load float, float* %[[VAL_882]], align 4
// CHECK:         store float %[[VAL_897]], float* %[[VAL_118]], align 4
// CHECK:         br label %[[VAL_136]]
// CHECK:       entry:
// CHECK:         %[[VAL_898:.*]] = alloca float, align 4
// CHECK:         %[[VAL_899:.*]] = load float, float* %[[VAL_900:.*]], align 4
// CHECK:         %[[VAL_901:.*]] = load float, float* %[[VAL_902:.*]], align 4
// CHECK:         %[[VAL_903:.*]] = fadd float %[[VAL_899]], %[[VAL_901]]
// CHECK:         store float %[[VAL_903]], float* %[[VAL_898]], align 4
// CHECK:         %[[VAL_904:.*]] = load float, float* %[[VAL_898]], align 4
// CHECK:         store float %[[VAL_904]], float* %[[VAL_905:.*]], align 4
// CHECK:         ret void
// CHECK:       entry:
// CHECK:         %[[VAL_906:.*]] = alloca float, align 4
// CHECK:         %[[VAL_907:.*]] = load float, float* %[[VAL_908:.*]], align 4
// CHECK:         %[[VAL_909:.*]] = load float, float* %[[VAL_910:.*]], align 4
// CHECK:         %[[VAL_911:.*]] = call float @llvm.maxnum.f32(float %[[VAL_907]], float %[[VAL_909]])
// CHECK:         store float %[[VAL_911]], float* %[[VAL_906]], align 4
// CHECK:         %[[VAL_912:.*]] = load float, float* %[[VAL_906]], align 4
// CHECK:         store float %[[VAL_912]], float* %[[VAL_913:.*]], align 4
// CHECK:         ret void

HloModule Test

Add {
  lhsadd = f32[] parameter(0)
  rhsadd = f32[] parameter(1)
  ROOT add = f32[] add(lhsadd, rhsadd)
}

Max {
  lhsmax = f32[] parameter(0)
  rhsmax = f32[] parameter(1)
  ROOT max = f32[] maximum(lhsmax, rhsmax)
}


fused_reduce {
  p0 = f32[2,32,32]{2,1,0} parameter(0)
  init1 = f32[] parameter(1)
  init2 = f32[] parameter(2)
  r1 = f32[2,32]{1,0} reduce(p0, init1), dimensions={2}, to_apply=Add
  r2 = f32[2,32]{1,0} reduce(p0, init2), dimensions={2}, to_apply=Max
  ROOT tuple = (f32[2,32]{1,0}, f32[2,32]{1,0}) tuple(r1, r2)
}

ENTRY reduce {
  p = f32[2,32,32]{2,1,0} parameter(0)
  i = f32[] parameter(1)
  j = f32[] parameter(2)
  ROOT fusion = (f32[2,32]{1,0}, f32[2,32]{1,0}) fusion(p, i, j),
   kind=kInput, calls=fused_reduce
}
