// RUN: hlo_to_llvm_ir %s | FileCheck %s

// NOTE: Assertions have been autogenerated by utils/generate-test-checks.py

// CHECK-LABEL: entry:
// CHECK:         %[[VAL_0:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !8
// CHECK:         %[[VAL_1:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !9
// CHECK:         %[[VAL_2:.*]] = mul nuw nsw i32 %[[VAL_0]], 2
// CHECK:         %[[VAL_3:.*]] = add nuw nsw i32 %[[VAL_2]], %[[VAL_1]]
// CHECK:         %[[VAL_4:.*]] = icmp ult i32 %[[VAL_3]], 2
// CHECK:         call void @llvm.assume(i1 %[[VAL_4]])
// CHECK:         %[[VAL_5:.*]] = udiv i32 %[[VAL_3]], 1
// CHECK:         %[[VAL_6:.*]] = icmp ult i32 %[[VAL_3]], 2
// CHECK:         br i1 %[[VAL_6]], label %[[VAL_7:.*]], label %[[VAL_8:.*]]
// CHECK:       indices.in_bounds-after:                          ; preds = %[[VAL_7]], %[[VAL_9:.*]]
// CHECK:         ret void
// CHECK:       indices.in_bounds-true:                           ; preds = %[[VAL_9]]
// CHECK:         %[[VAL_10:.*]] = getelementptr inbounds i32, ptr %[[VAL_11:.*]], i32 %[[VAL_3]]
// CHECK:         %[[VAL_12:.*]] = load i32, ptr %[[VAL_10]], align 4, !invariant.load !10
// CHECK:         %[[VAL_13:.*]] = getelementptr inbounds i32, ptr %[[VAL_14:.*]], i32 %[[VAL_3]]
// CHECK:         %[[VAL_15:.*]] = load i32, ptr %[[VAL_13]], align 4, !invariant.load !10
// CHECK:         %[[VAL_16:.*]] = add i32 %[[VAL_12]], %[[VAL_15]]
// CHECK:         %[[VAL_17:.*]] = getelementptr inbounds i32, ptr %[[VAL_18:.*]], i32 %[[VAL_3]]
// CHECK:         store i32 %[[VAL_16]], ptr %[[VAL_17]], align 4
// CHECK:         br label %[[VAL_8]]
// CHECK:       entry:
// CHECK:         %[[VAL_19:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !8
// CHECK:         %[[VAL_20:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !11
// CHECK:         %[[VAL_21:.*]] = mul nuw nsw i32 %[[VAL_19]], 6
// CHECK:         %[[VAL_22:.*]] = add nuw nsw i32 %[[VAL_21]], %[[VAL_20]]
// CHECK:         %[[VAL_23:.*]] = icmp ult i32 %[[VAL_22]], 6
// CHECK:         call void @llvm.assume(i1 %[[VAL_23]])
// CHECK:         %[[VAL_24:.*]] = udiv i32 %[[VAL_22]], 1
// CHECK:         %[[VAL_25:.*]] = urem i32 %[[VAL_24]], 3
// CHECK:         %[[VAL_26:.*]] = udiv i32 %[[VAL_22]], 3
// CHECK:         %[[VAL_27:.*]] = icmp ult i32 %[[VAL_22]], 6
// CHECK:         br i1 %[[VAL_27]], label %[[VAL_28:.*]], label %[[VAL_29:.*]]
// CHECK:       updates.in_bounds-after:                          ; preds = %[[VAL_28]], %[[VAL_30:.*]]
// CHECK:         ret void
// CHECK:       updates.in_bounds-true:                           ; preds = %[[VAL_30]]
// CHECK:         %[[VAL_31:.*]] = getelementptr inbounds i32, ptr %[[VAL_32:.*]], i32 %[[VAL_22]]
// CHECK:         %[[VAL_33:.*]] = load i32, ptr %[[VAL_31]], align 4, !invariant.load !10
// CHECK:         %[[VAL_34:.*]] = getelementptr inbounds i32, ptr %[[VAL_35:.*]], i32 %[[VAL_22]]
// CHECK:         %[[VAL_36:.*]] = load i32, ptr %[[VAL_34]], align 4, !invariant.load !10
// CHECK:         %[[VAL_37:.*]] = add i32 %[[VAL_33]], %[[VAL_36]]
// CHECK:         %[[VAL_38:.*]] = getelementptr inbounds i32, ptr %[[VAL_39:.*]], i32 %[[VAL_22]]
// CHECK:         store i32 %[[VAL_37]], ptr %[[VAL_38]], align 4
// CHECK:         br label %[[VAL_29]]
// CHECK:       entry:
// CHECK:         %[[VAL_40:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !8
// CHECK:         %[[VAL_41:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !12
// CHECK:         %[[VAL_42:.*]] = mul nuw nsw i32 %[[VAL_40]], 9
// CHECK:         %[[VAL_43:.*]] = add nuw nsw i32 %[[VAL_42]], %[[VAL_41]]
// CHECK:         %[[VAL_44:.*]] = icmp ult i32 %[[VAL_43]], 9
// CHECK:         call void @llvm.assume(i1 %[[VAL_44]])
// CHECK:         %[[VAL_45:.*]] = udiv i32 %[[VAL_43]], 1
// CHECK:         %[[VAL_46:.*]] = urem i32 %[[VAL_45]], 3
// CHECK:         %[[VAL_47:.*]] = udiv i32 %[[VAL_43]], 3
// CHECK:         %[[VAL_48:.*]] = icmp ult i32 %[[VAL_43]], 9
// CHECK:         br i1 %[[VAL_48]], label %[[VAL_49:.*]], label %[[VAL_50:.*]]
// CHECK:       operand.in_bounds-after:                          ; preds = %[[VAL_49]], %[[VAL_51:.*]]
// CHECK:         ret void
// CHECK:       operand.in_bounds-true:                           ; preds = %[[VAL_51]]
// CHECK:         %[[VAL_52:.*]] = getelementptr inbounds i32, ptr %[[VAL_53:.*]], i32 %[[VAL_43]]
// CHECK:         %[[VAL_54:.*]] = load i32, ptr %[[VAL_52]], align 4, !invariant.load !10
// CHECK:         %[[VAL_55:.*]] = getelementptr inbounds i32, ptr %[[VAL_56:.*]], i32 %[[VAL_43]]
// CHECK:         %[[VAL_57:.*]] = load i32, ptr %[[VAL_55]], align 4, !invariant.load !10
// CHECK:         %[[VAL_58:.*]] = add i32 %[[VAL_54]], %[[VAL_57]]
// CHECK:         %[[VAL_59:.*]] = getelementptr inbounds i32, ptr %[[VAL_60:.*]], i32 %[[VAL_43]]
// CHECK:         store i32 %[[VAL_58]], ptr %[[VAL_59]], align 4
// CHECK:         br label %[[VAL_50]]
// CHECK:       entry:
// CHECK:         %[[VAL_61:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_62:.*]] = getelementptr inbounds i8, ptr %[[VAL_63:.*]], i64 128
// CHECK:         %[[VAL_64:.*]] = getelementptr inbounds i8, ptr %[[VAL_63]], i64 0
// CHECK:         %[[VAL_65:.*]] = getelementptr inbounds i8, ptr %[[VAL_66:.*]], i64 0
// CHECK:         %[[VAL_67:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !8
// CHECK:         %[[VAL_68:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !11
// CHECK:         %[[VAL_69:.*]] = mul nuw nsw i32 %[[VAL_67]], 6
// CHECK:         %[[VAL_70:.*]] = add nuw nsw i32 %[[VAL_69]], %[[VAL_68]]
// CHECK:         %[[VAL_71:.*]] = icmp ult i32 %[[VAL_70]], 6
// CHECK:         call void @llvm.assume(i1 %[[VAL_71]])
// CHECK:         %[[VAL_72:.*]] = udiv i32 %[[VAL_70]], 1
// CHECK:         %[[VAL_73:.*]] = urem i32 %[[VAL_72]], 3
// CHECK:         %[[VAL_74:.*]] = udiv i32 %[[VAL_70]], 3
// CHECK:         %[[VAL_75:.*]] = icmp ult i32 %[[VAL_70]], 6
// CHECK:         br i1 %[[VAL_75]], label %[[VAL_76:.*]], label %[[VAL_77:.*]]
// CHECK:       scatter.in_bounds-after:                          ; preds = %[[VAL_78:.*]], %[[VAL_79:.*]]
// CHECK:         ret void
// CHECK:       scatter.in_bounds-true:                           ; preds = %[[VAL_79]]
// CHECK:         %[[VAL_80:.*]] = getelementptr inbounds [2 x i32], ptr %[[VAL_62]], i32 0, i32 %[[VAL_74]]
// CHECK:         %[[VAL_81:.*]] = load i32, ptr %[[VAL_80]], align 4, !invariant.load !10
// CHECK:         %[[VAL_82:.*]] = add i32 0, %[[VAL_81]]
// CHECK:         %[[VAL_83:.*]] = icmp ult i32 %[[VAL_81]], 3
// CHECK:         %[[VAL_84:.*]] = and i1 true, %[[VAL_83]]
// CHECK:         br i1 %[[VAL_84]], label %[[VAL_85:.*]], label %[[VAL_78]]
// CHECK:       scatter.in_bounds-after3:                         ; preds = %[[VAL_85]], %[[VAL_76]]
// CHECK:         br label %[[VAL_77]]
// CHECK:       scatter.in_bounds-true2:                          ; preds = %[[VAL_76]]
// CHECK:         %[[VAL_86:.*]] = getelementptr inbounds [3 x [3 x i32]], ptr %[[VAL_65]], i32 0, i32 %[[VAL_82]], i32 %[[VAL_73]]
// CHECK:         %[[VAL_87:.*]] = getelementptr inbounds i32, ptr %[[VAL_64]], i32 %[[VAL_70]]
// CHECK:         %[[VAL_88:.*]] = load i32, ptr %[[VAL_87]], align 4, !invariant.load !10
// CHECK:         store i32 %[[VAL_88]], ptr %[[VAL_61]], align 4
// CHECK:         %[[VAL_89:.*]] = load i32, ptr %[[VAL_61]], align 4
// CHECK:         store atomic i32 %[[VAL_89]], ptr %[[VAL_86]] unordered, align 4
// CHECK:         br label %[[VAL_78]]

HloModule TensorFlowScatterV1

update_s32 (lhs: s32[], rhs: s32[]) -> s32[] {
  lhs = s32[] parameter(0)
  ROOT rhs = s32[] parameter(1)
}

ENTRY main {
  p0 = s32[3,3] parameter(0)
  operand = s32[3,3] add(p0, p0)
  p1 = s32[2] parameter(1)
  indices = s32[2] add(p1, p1)
  p2 = s32[2,3] parameter(2)
  updates = s32[2,3] add(p2, p2)
  ROOT scatter = s32[3,3] scatter(operand, indices, updates),
      to_apply=update_s32,
      update_window_dims={1},
      inserted_window_dims={0},
      scatter_dims_to_operand_dims={0},
      index_vector_dim=1
}
