// RUN: hlo_to_llvm_ir %s | FileCheck %s

// NOTE: Assertions have been autogenerated by utils/generate-test-checks.py

// CHECK-LABEL: entry:
// CHECK:         %[[VAL_0:.*]] = getelementptr inbounds i8, ptr %[[VAL_1:.*]], i64 0
// CHECK:         %[[VAL_2:.*]] = getelementptr inbounds i8, ptr %[[VAL_1]], i64 0
// CHECK:         %[[VAL_3:.*]] = getelementptr inbounds i8, ptr %[[VAL_4:.*]], i64 128
// CHECK:         %[[VAL_5:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !8
// CHECK:         %[[VAL_6:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !8
// CHECK:         %[[VAL_7:.*]] = mul nuw nsw i32 %[[VAL_5]], 1
// CHECK:         %[[VAL_8:.*]] = add nuw nsw i32 %[[VAL_7]], %[[VAL_6]]
// CHECK:         %[[VAL_9:.*]] = icmp ult i32 %[[VAL_8]], 1
// CHECK:         call void @llvm.assume(i1 %[[VAL_9]])
// CHECK:         %[[VAL_10:.*]] = mul nuw nsw i32 %[[VAL_8]], 2
// CHECK:         %[[VAL_11:.*]] = udiv i32 %[[VAL_10]], 1
// CHECK:         %[[VAL_12:.*]] = add nuw nsw i32 %[[VAL_10]], 1
// CHECK:         %[[VAL_13:.*]] = udiv i32 %[[VAL_12]], 1
// CHECK:         %[[VAL_14:.*]] = icmp ult i32 %[[VAL_10]], 2
// CHECK:         br i1 %[[VAL_14]], label %[[VAL_15:.*]], label %[[VAL_16:.*]]
// CHECK:       indices.in_bounds-after:                          ; preds = %[[VAL_15]], %[[VAL_17:.*]]
// CHECK:         ret void
// CHECK:       indices.in_bounds-true:                           ; preds = %[[VAL_17]]
// CHECK:         %[[VAL_18:.*]] = getelementptr inbounds i32, ptr %[[VAL_0]], i32 %[[VAL_10]]
// CHECK:         %[[VAL_19:.*]] = load i32, ptr %[[VAL_18]], align 4, !invariant.load !9
// CHECK:         %[[VAL_20:.*]] = getelementptr inbounds i32, ptr %[[VAL_2]], i32 %[[VAL_10]]
// CHECK:         %[[VAL_21:.*]] = load i32, ptr %[[VAL_20]], align 4, !invariant.load !9
// CHECK:         %[[VAL_22:.*]] = add i32 %[[VAL_19]], %[[VAL_21]]
// CHECK:         %[[VAL_23:.*]] = getelementptr inbounds i32, ptr %[[VAL_3]], i32 %[[VAL_10]]
// CHECK:         store i32 %[[VAL_22]], ptr %[[VAL_23]], align 4
// CHECK:         %[[VAL_24:.*]] = getelementptr inbounds i32, ptr %[[VAL_0]], i32 %[[VAL_12]]
// CHECK:         %[[VAL_25:.*]] = load i32, ptr %[[VAL_24]], align 4, !invariant.load !9
// CHECK:         %[[VAL_26:.*]] = getelementptr inbounds i32, ptr %[[VAL_2]], i32 %[[VAL_12]]
// CHECK:         %[[VAL_27:.*]] = load i32, ptr %[[VAL_26]], align 4, !invariant.load !9
// CHECK:         %[[VAL_28:.*]] = add i32 %[[VAL_25]], %[[VAL_27]]
// CHECK:         %[[VAL_29:.*]] = getelementptr inbounds i32, ptr %[[VAL_3]], i32 %[[VAL_12]]
// CHECK:         store i32 %[[VAL_28]], ptr %[[VAL_29]], align 4
// CHECK:         br label %[[VAL_16]]
// CHECK:       entry:
// CHECK:         %[[VAL_30:.*]] = getelementptr inbounds i8, ptr %[[VAL_31:.*]], i64 0
// CHECK:         %[[VAL_32:.*]] = getelementptr inbounds i8, ptr %[[VAL_31]], i64 0
// CHECK:         %[[VAL_33:.*]] = getelementptr inbounds i8, ptr %[[VAL_34:.*]], i64 0
// CHECK:         %[[VAL_35:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !8
// CHECK:         %[[VAL_36:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !10
// CHECK:         %[[VAL_37:.*]] = mul nuw nsw i32 %[[VAL_35]], 3
// CHECK:         %[[VAL_38:.*]] = add nuw nsw i32 %[[VAL_37]], %[[VAL_36]]
// CHECK:         %[[VAL_39:.*]] = icmp ult i32 %[[VAL_38]], 3
// CHECK:         call void @llvm.assume(i1 %[[VAL_39]])
// CHECK:         %[[VAL_40:.*]] = mul nuw nsw i32 %[[VAL_38]], 2
// CHECK:         %[[VAL_41:.*]] = udiv i32 %[[VAL_40]], 1
// CHECK:         %[[VAL_42:.*]] = urem i32 %[[VAL_41]], 3
// CHECK:         %[[VAL_43:.*]] = udiv i32 %[[VAL_40]], 3
// CHECK:         %[[VAL_44:.*]] = add nuw nsw i32 %[[VAL_40]], 1
// CHECK:         %[[VAL_45:.*]] = udiv i32 %[[VAL_44]], 1
// CHECK:         %[[VAL_46:.*]] = urem i32 %[[VAL_45]], 3
// CHECK:         %[[VAL_47:.*]] = udiv i32 %[[VAL_44]], 3
// CHECK:         %[[VAL_48:.*]] = icmp ult i32 %[[VAL_40]], 6
// CHECK:         br i1 %[[VAL_48]], label %[[VAL_49:.*]], label %[[VAL_50:.*]]
// CHECK:       updates.in_bounds-after:                          ; preds = %[[VAL_49]], %[[VAL_51:.*]]
// CHECK:         ret void
// CHECK:       updates.in_bounds-true:                           ; preds = %[[VAL_51]]
// CHECK:         %[[VAL_52:.*]] = getelementptr inbounds i32, ptr %[[VAL_30]], i32 %[[VAL_40]]
// CHECK:         %[[VAL_53:.*]] = load i32, ptr %[[VAL_52]], align 4, !invariant.load !9
// CHECK:         %[[VAL_54:.*]] = getelementptr inbounds i32, ptr %[[VAL_32]], i32 %[[VAL_40]]
// CHECK:         %[[VAL_55:.*]] = load i32, ptr %[[VAL_54]], align 4, !invariant.load !9
// CHECK:         %[[VAL_56:.*]] = add i32 %[[VAL_53]], %[[VAL_55]]
// CHECK:         %[[VAL_57:.*]] = getelementptr inbounds i32, ptr %[[VAL_33]], i32 %[[VAL_40]]
// CHECK:         store i32 %[[VAL_56]], ptr %[[VAL_57]], align 4
// CHECK:         %[[VAL_58:.*]] = getelementptr inbounds i32, ptr %[[VAL_30]], i32 %[[VAL_44]]
// CHECK:         %[[VAL_59:.*]] = load i32, ptr %[[VAL_58]], align 4, !invariant.load !9
// CHECK:         %[[VAL_60:.*]] = getelementptr inbounds i32, ptr %[[VAL_32]], i32 %[[VAL_44]]
// CHECK:         %[[VAL_61:.*]] = load i32, ptr %[[VAL_60]], align 4, !invariant.load !9
// CHECK:         %[[VAL_62:.*]] = add i32 %[[VAL_59]], %[[VAL_61]]
// CHECK:         %[[VAL_63:.*]] = getelementptr inbounds i32, ptr %[[VAL_33]], i32 %[[VAL_44]]
// CHECK:         store i32 %[[VAL_62]], ptr %[[VAL_63]], align 4
// CHECK:         br label %[[VAL_50]]
// CHECK:       entry:
// CHECK:         %[[VAL_64:.*]] = getelementptr inbounds i8, ptr %[[VAL_65:.*]], i64 0
// CHECK:         %[[VAL_66:.*]] = getelementptr inbounds i8, ptr %[[VAL_65]], i64 0
// CHECK:         %[[VAL_67:.*]] = getelementptr inbounds i8, ptr %[[VAL_68:.*]], i64 0
// CHECK:         %[[VAL_69:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !8
// CHECK:         %[[VAL_70:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !11
// CHECK:         %[[VAL_71:.*]] = mul nuw nsw i32 %[[VAL_69]], 9
// CHECK:         %[[VAL_72:.*]] = add nuw nsw i32 %[[VAL_71]], %[[VAL_70]]
// CHECK:         %[[VAL_73:.*]] = icmp ult i32 %[[VAL_72]], 9
// CHECK:         call void @llvm.assume(i1 %[[VAL_73]])
// CHECK:         %[[VAL_74:.*]] = udiv i32 %[[VAL_72]], 1
// CHECK:         %[[VAL_75:.*]] = urem i32 %[[VAL_74]], 3
// CHECK:         %[[VAL_76:.*]] = udiv i32 %[[VAL_72]], 3
// CHECK:         %[[VAL_77:.*]] = icmp ult i32 %[[VAL_72]], 9
// CHECK:         br i1 %[[VAL_77]], label %[[VAL_78:.*]], label %[[VAL_79:.*]]
// CHECK:       operand.in_bounds-after:                          ; preds = %[[VAL_78]], %[[VAL_80:.*]]
// CHECK:         ret void
// CHECK:       operand.in_bounds-true:                           ; preds = %[[VAL_80]]
// CHECK:         %[[VAL_81:.*]] = getelementptr inbounds i32, ptr %[[VAL_64]], i32 %[[VAL_72]]
// CHECK:         %[[VAL_82:.*]] = load i32, ptr %[[VAL_81]], align 4, !invariant.load !9
// CHECK:         %[[VAL_83:.*]] = getelementptr inbounds i32, ptr %[[VAL_66]], i32 %[[VAL_72]]
// CHECK:         %[[VAL_84:.*]] = load i32, ptr %[[VAL_83]], align 4, !invariant.load !9
// CHECK:         %[[VAL_85:.*]] = add i32 %[[VAL_82]], %[[VAL_84]]
// CHECK:         %[[VAL_86:.*]] = getelementptr inbounds i32, ptr %[[VAL_67]], i32 %[[VAL_72]]
// CHECK:         store i32 %[[VAL_85]], ptr %[[VAL_86]], align 4
// CHECK:         br label %[[VAL_79]]
// CHECK:       entry:
// CHECK:         %[[VAL_87:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_88:.*]] = getelementptr inbounds i8, ptr %[[VAL_89:.*]], i64 128
// CHECK:         %[[VAL_90:.*]] = getelementptr inbounds i8, ptr %[[VAL_89]], i64 0
// CHECK:         %[[VAL_91:.*]] = getelementptr inbounds i8, ptr %[[VAL_92:.*]], i64 0
// CHECK:         %[[VAL_93:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !8
// CHECK:         %[[VAL_94:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !12
// CHECK:         %[[VAL_95:.*]] = mul nuw nsw i32 %[[VAL_93]], 6
// CHECK:         %[[VAL_96:.*]] = add nuw nsw i32 %[[VAL_95]], %[[VAL_94]]
// CHECK:         %[[VAL_97:.*]] = icmp ult i32 %[[VAL_96]], 6
// CHECK:         call void @llvm.assume(i1 %[[VAL_97]])
// CHECK:         %[[VAL_98:.*]] = udiv i32 %[[VAL_96]], 1
// CHECK:         %[[VAL_99:.*]] = urem i32 %[[VAL_98]], 3
// CHECK:         %[[VAL_100:.*]] = udiv i32 %[[VAL_96]], 3
// CHECK:         %[[VAL_101:.*]] = icmp ult i32 %[[VAL_96]], 6
// CHECK:         br i1 %[[VAL_101]], label %[[VAL_102:.*]], label %[[VAL_103:.*]]
// CHECK:       scatter.in_bounds-after:                          ; preds = %[[VAL_104:.*]], %[[VAL_105:.*]]
// CHECK:         ret void
// CHECK:       scatter.in_bounds-true:                           ; preds = %[[VAL_105]]
// CHECK:         %[[VAL_106:.*]] = getelementptr inbounds [2 x i32], ptr %[[VAL_88]], i32 0, i32 %[[VAL_100]]
// CHECK:         %[[VAL_107:.*]] = load i32, ptr %[[VAL_106]], align 4, !invariant.load !9
// CHECK:         %[[VAL_108:.*]] = add i32 0, %[[VAL_107]]
// CHECK:         %[[VAL_109:.*]] = icmp ult i32 %[[VAL_107]], 3
// CHECK:         %[[VAL_110:.*]] = and i1 true, %[[VAL_109]]
// CHECK:         br i1 %[[VAL_110]], label %[[VAL_111:.*]], label %[[VAL_104]]
// CHECK:       scatter.in_bounds-after3:                         ; preds = %[[VAL_111]], %[[VAL_102]]
// CHECK:         br label %[[VAL_103]]
// CHECK:       scatter.in_bounds-true2:                          ; preds = %[[VAL_102]]
// CHECK:         %[[VAL_112:.*]] = getelementptr inbounds [3 x [3 x i32]], ptr %[[VAL_91]], i32 0, i32 %[[VAL_108]], i32 %[[VAL_99]]
// CHECK:         %[[VAL_113:.*]] = getelementptr inbounds i32, ptr %[[VAL_90]], i32 %[[VAL_96]]
// CHECK:         %[[VAL_114:.*]] = load i32, ptr %[[VAL_113]], align 4, !invariant.load !9
// CHECK:         store i32 %[[VAL_114]], ptr %[[VAL_87]], align 4
// CHECK:         %[[VAL_115:.*]] = load i32, ptr %[[VAL_87]], align 4
// CHECK:         store atomic i32 %[[VAL_115]], ptr %[[VAL_112]] unordered, align 4
// CHECK:         br label %[[VAL_104]]

HloModule TensorFlowScatterV1

update_s32 (lhs: s32[], rhs: s32[]) -> s32[] {
  lhs = s32[] parameter(0)
  ROOT rhs = s32[] parameter(1)
}

ENTRY main {
  p0 = s32[3,3] parameter(0)
  operand = s32[3,3] add(p0, p0)
  p1 = s32[2] parameter(1)
  indices = s32[2] add(p1, p1)
  p2 = s32[2,3] parameter(2)
  updates = s32[2,3] add(p2, p2)
  ROOT scatter = s32[3,3] scatter(operand, indices, updates),
      to_apply=update_s32,
      update_window_dims={1},
      inserted_window_dims={0},
      scatter_dims_to_operand_dims={0},
      index_vector_dim=1
}
