op {
  graph_op_name: "CTCBeamSearchDecoder"
  endpoint {
    name: "CTCBeamSearchDecoder"
  }
  summary: "Performs beam search decoding on the logits given in input."
  description: <<END
A note about the attribute merge_repeated: For the beam search decoder,
this means that if consecutive entries in a beam are the same, only
the first of these is emitted.  That is, when the top path is "A B B B B",
"A B" is returned if merge_repeated = True but "A B B B B" is
returned if merge_repeated = False.
END
}
op {
  graph_op_name: "CTCGreedyDecoder"
  endpoint {
    name: "CTCGreedyDecoder"
  }
  summary: "Performs greedy decoding on the logits given in inputs."
  description: <<END
A note about the attribute merge_repeated: if enabled, when
consecutive logits' maximum indices are the same, only the first of
these is emitted.  Labeling the blank '*', the sequence "A B B * B B"
becomes "A B B" if merge_repeated = True and "A B B B B" if
merge_repeated = False.

Regardless of the value of merge_repeated, if the maximum index of a given
time and batch corresponds to the blank, index `(num_classes - 1)`, no new
element is emitted.
END
}
op {
  graph_op_name: "CTCLoss"
  endpoint {
    name: "CTCLoss"
  }
  summary: "Calculates the CTC Loss (log probability) for each batch entry.  Also calculates"
  description: <<END
the gradient.  This class performs the softmax operation for you, so inputs
should be e.g. linear projections of outputs by an LSTM.
END
}
op {
  graph_op_name: "CacheDataset"
  endpoint {
    name: "CacheDataset"
  }
  summary: "Creates a dataset that caches elements from `input_dataset`."
  description: <<END
A CacheDataset will iterate over the input_dataset, and store tensors. If the
cache already exists, the cache will be used. If the cache is inappropriate
(e.g. cannot be opened, contains tensors of the wrong shape / size), an error
will the returned when used.
END
}
op {
  graph_op_name: "Cast"
  endpoint {
    name: "Cast"
  }
  summary: "Cast x of type SrcT to y of DstT."
}
op {
  graph_op_name: "Ceil"
  endpoint {
    name: "Ceil"
  }
  summary: "Returns element-wise smallest integer in not less than x."
}
op {
  graph_op_name: "CheckNumerics"
  endpoint {
    name: "CheckNumerics"
  }
  summary: "Checks a tensor for NaN and Inf values."
  description: <<END
When run, reports an `InvalidArgument` error if `tensor` has any values
that are not a number (NaN) or infinity (Inf). Otherwise, passes `tensor` as-is.
END
}
op {
  graph_op_name: "Cholesky"
  endpoint {
    name: "Cholesky"
  }
  summary: "Computes the Cholesky decomposition of one or more square matrices."
  description: <<END
The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
form square matrices.

The input has to be symmetric and positive definite. Only the lower-triangular
part of the input will be used for this operation. The upper-triangular part
will not be read.

The output is a tensor of the same shape as the input
containing the Cholesky decompositions for all input submatrices `[..., :, :]`.

**Note**: The gradient computation on GPU is faster for large matrices but
not for large batch dimensions when the submatrices are small. In this
case it might be faster to use the CPU.
END
}
op {
  graph_op_name: "CholeskyGrad"
  endpoint {
    name: "CholeskyGrad"
  }
  summary: "Computes the reverse mode backpropagated gradient of the Cholesky algorithm."
  description: <<END
For an explanation see "Differentiation of the Cholesky algorithm" by
Iain Murray http://arxiv.org/abs/1602.07527.
END
}
op {
  graph_op_name: "CompareAndBitpack"
  endpoint {
    name: "CompareAndBitpack"
  }
  summary: "Compare values of `input` to `threshold` and pack resulting bits into a `uint8`."
  description: <<END
Each comparison returns a boolean `true` (if `input_value > threshold`)
or and `false` otherwise.

This operation is useful for Locality-Sensitive-Hashing (LSH) and other
algorithms that use hashing approximations of cosine and `L2` distances;
codes can be generated from an input via:

```python
codebook_size = 50
codebook_bits = codebook_size * 32
codebook = tf.get_variable('codebook', [x.shape[-1].value, codebook_bits],
                           dtype=x.dtype,
                           initializer=tf.orthogonal_initializer())
codes = compare_and_threshold(tf.matmul(x, codebook), threshold=0.)
codes = tf.bitcast(codes, tf.int32)  # go from uint8 to int32
# now codes has shape x.shape[:-1] + [codebook_size]
```

**NOTE**: Currently, the innermost dimension of the tensor must be divisible
by 8.

Given an `input` shaped `[s0, s1, ..., s_n]`, the output is
a `uint8` tensor shaped `[s0, s1, ..., s_n / 8]`.
END
}
op {
  graph_op_name: "Complex"
  endpoint {
    name: "Complex"
  }
  summary: "Converts two real numbers to a complex number."
  description: <<END
Given a tensor `real` representing the real part of a complex number, and a
tensor `imag` representing the imaginary part of a complex number, this
operation returns complex numbers elementwise of the form \\(a + bj\\), where
*a* represents the `real` part and *b* represents the `imag` part.

The input tensors `real` and `imag` must have the same shape.

For example:

```
# tensor 'real' is [2.25, 3.25]
# tensor `imag` is [4.75, 5.75]
tf.complex(real, imag) ==> [[2.25 + 4.75j], [3.25 + 5.75j]]
```
END
}
op {
  graph_op_name: "ComplexAbs"
  endpoint {
    name: "ComplexAbs"
  }
  summary: "Computes the complex absolute value of a tensor."
  description: <<END
Given a tensor `x` of complex numbers, this operation returns a tensor of type
`float` or `double` that is the absolute value of each element in `x`. All
elements in `x` must be complex numbers of the form \\(a + bj\\). The absolute
value is computed as \\( \sqrt{a^2 + b^2}\\).
END
}
op {
  graph_op_name: "ComputeAccidentalHits"
  endpoint {
    name: "ComputeAccidentalHits"
  }
  summary: "Computes the ids of the positions in sampled_candidates that match true_labels."
  description: <<END
When doing log-odds NCE, the result of this op should be passed through a
SparseToDense op, then added to the logits of the sampled candidates. This has
the effect of 'removing' the sampled labels that match the true labels by
making the classifier sure that they are sampled labels.
END
}
op {
  graph_op_name: "Concat"
  endpoint {
    name: "Concat"
  }
  summary: "Concatenates tensors along one dimension."
}
op {
  graph_op_name: "ConcatOffset"
  endpoint {
    name: "ConcatOffset"
  }
  summary: "Computes offsets of concat inputs within its output."
  description: <<END
For example:

```
# 'x' is [2, 2, 7]
# 'y' is [2, 3, 7]
# 'z' is [2, 5, 7]
concat_offset(2, [x, y, z]) => [0, 0, 0], [0, 2, 0], [0, 5, 0]
```

This is typically used by gradient computations for a concat operation.
END
}
op {
  graph_op_name: "ConcatV2"
  endpoint {
    name: "ConcatV2"
  }
  summary: "Concatenates tensors along one dimension."
}
op {
  graph_op_name: "ConcatenateDataset"
  endpoint {
    name: "ConcatenateDataset"
  }
  summary: "Creates a dataset that concatenates `input_dataset` with `another_dataset`."
}
op {
  graph_op_name: "ConditionalAccumulator"
  endpoint {
    name: "ConditionalAccumulator"
  }
  summary: "A conditional accumulator for aggregating gradients."
  description: <<END
The accumulator accepts gradients marked with local_step greater or
equal to the most recent global_step known to the accumulator. The
average can be extracted from the accumulator, provided sufficient
gradients have been accumulated. Extracting the average automatically
resets the aggregate to 0, and increments the global_step recorded by
the accumulator.
END
}
op {
  graph_op_name: "Conj"
  endpoint {
    name: "Conj"
  }
  summary: "Returns the complex conjugate of a complex number."
  description: <<END
Given a tensor `input` of complex numbers, this operation returns a tensor of
complex numbers that are the complex conjugate of each element in `input`. The
complex numbers in `input` must be of the form \\(a + bj\\), where *a* is the
real part and *b* is the imaginary part.

The complex conjugate returned by this operation is of the form \\(a - bj\\).

For example:

```
# tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
tf.conj(input) ==> [-2.25 - 4.75j, 3.25 - 5.75j]
```
END
}
op {
  graph_op_name: "Const"
  endpoint {
    name: "Const"
  }
  summary: "Returns a constant tensor."
}
op {
  graph_op_name: "ControlTrigger"
  endpoint {
    name: "ControlTrigger"
  }
  summary: "Does nothing. Serves as a control trigger for scheduling."
  description: <<END
Only useful as a placeholder for control edges.
END
}
op {
  graph_op_name: "Conv2D"
  endpoint {
    name: "Conv2D"
  }
  summary: "Computes a 2-D convolution given 4-D `input` and `filter` tensors."
  description: <<END
Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
and a filter / kernel tensor of shape
`[filter_height, filter_width, in_channels, out_channels]`, this op
performs the following:

1. Flattens the filter to a 2-D matrix with shape
   `[filter_height * filter_width * in_channels, output_channels]`.
2. Extracts image patches from the input tensor to form a *virtual*
   tensor of shape `[batch, out_height, out_width,
   filter_height * filter_width * in_channels]`.
3. For each patch, right-multiplies the filter matrix and the image patch
   vector.

In detail, with the default NHWC format,

    output[b, i, j, k] =
        sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *
                        filter[di, dj, q, k]

Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
horizontal and vertices strides, `strides = [1, stride, stride, 1]`.
END
}
op {
  graph_op_name: "Conv2DBackpropFilter"
  endpoint {
    name: "Conv2DBackpropFilter"
  }
  summary: "Computes the gradients of convolution with respect to the filter."
}
op {
  graph_op_name: "Conv2DBackpropInput"
  endpoint {
    name: "Conv2DBackpropInput"
  }
  summary: "Computes the gradients of convolution with respect to the input."
}
op {
  graph_op_name: "Conv3D"
  endpoint {
    name: "Conv3D"
  }
  summary: "Computes a 3-D convolution given 5-D `input` and `filter` tensors."
  description: <<END
In signal processing, cross-correlation is a measure of similarity of
two waveforms as a function of a time-lag applied to one of them. This
is also known as a sliding dot product or sliding inner-product.

Our Conv3D implements a form of cross-correlation.
END
}
op {
  graph_op_name: "Conv3DBackpropFilter"
  endpoint {
    name: "Conv3DBackpropFilter"
  }
  summary: "Computes the gradients of 3-D convolution with respect to the filter."
}
op {
  graph_op_name: "Conv3DBackpropFilterV2"
  endpoint {
    name: "Conv3DBackpropFilterV2"
  }
  summary: "Computes the gradients of 3-D convolution with respect to the filter."
}
op {
  graph_op_name: "Conv3DBackpropInput"
  endpoint {
    name: "Conv3DBackpropInput"
  }
  summary: "Computes the gradients of 3-D convolution with respect to the input."
}
op {
  graph_op_name: "Conv3DBackpropInputV2"
  endpoint {
    name: "Conv3DBackpropInputV2"
  }
  summary: "Computes the gradients of 3-D convolution with respect to the input."
}
op {
  graph_op_name: "Cos"
  endpoint {
    name: "Cos"
  }
  summary: "Computes cos of x element-wise."
}
op {
  graph_op_name: "Cosh"
  endpoint {
    name: "Cosh"
  }
  summary: "Computes hyperbolic cosine of x element-wise."
}
op {
  graph_op_name: "CountUpTo"
  endpoint {
    name: "CountUpTo"
  }
  summary: "Increments \'ref\' until it reaches \'limit\'."
}
op {
  graph_op_name: "CropAndResize"
  endpoint {
    name: "CropAndResize"
  }
  summary: "Extracts crops from the input image tensor and bilinearly resizes them (possibly"
  description: <<END
with aspect ratio change) to a common output size specified by `crop_size`. This
is more general than the `crop_to_bounding_box` op which extracts a fixed size
slice from the input image and does not allow resizing or aspect ratio change.

Returns a tensor with `crops` from the input `image` at positions defined at the
bounding box locations in `boxes`. The cropped boxes are all resized (with
bilinear interpolation) to a fixed `size = [crop_height, crop_width]`. The
result is a 4-D tensor `[num_boxes, crop_height, crop_width, depth]`.
END
}
op {
  graph_op_name: "CropAndResizeGradBoxes"
  endpoint {
    name: "CropAndResizeGradBoxes"
  }
  summary: "Computes the gradient of the crop_and_resize op wrt the input boxes tensor."
}
op {
  graph_op_name: "CropAndResizeGradImage"
  endpoint {
    name: "CropAndResizeGradImage"
  }
  summary: "Computes the gradient of the crop_and_resize op wrt the input image tensor."
}
op {
  graph_op_name: "Cross"
  endpoint {
    name: "Cross"
  }
  summary: "Compute the pairwise cross product."
  description: <<END
`a` and `b` must be the same shape; they can either be simple 3-element vectors,
or any shape where the innermost dimension is 3. In the latter case, each pair
of corresponding 3-element vectors is cross-multiplied independently.
END
}
op {
  graph_op_name: "Cumprod"
  endpoint {
    name: "Cumprod"
  }
  summary: "Compute the cumulative product of the tensor `x` along `axis`."
  description: <<END
By default, this op performs an inclusive cumprod, which means that the first
element of the input is identical to the first element of the output:

```python
tf.cumprod([a, b, c])  # => [a, a * b, a * b * c]
```

By setting the `exclusive` kwarg to `True`, an exclusive cumprod is
performed instead:

```python
tf.cumprod([a, b, c], exclusive=True)  # => [1, a, a * b]
```

By setting the `reverse` kwarg to `True`, the cumprod is performed in the
opposite direction:

```python
tf.cumprod([a, b, c], reverse=True)  # => [a * b * c, b * c, c]
```

This is more efficient than using separate `tf.reverse` ops.

The `reverse` and `exclusive` kwargs can also be combined:

```python
tf.cumprod([a, b, c], exclusive=True, reverse=True)  # => [b * c, c, 1]
```
END
}
op {
  graph_op_name: "Cumsum"
  endpoint {
    name: "Cumsum"
  }
  summary: "Compute the cumulative sum of the tensor `x` along `axis`."
  description: <<END
By default, this op performs an inclusive cumsum, which means that the first
element of the input is identical to the first element of the output:

```python
tf.cumsum([a, b, c])  # => [a, a + b, a + b + c]
```

By setting the `exclusive` kwarg to `True`, an exclusive cumsum is
performed instead:

```python
tf.cumsum([a, b, c], exclusive=True)  # => [0, a, a + b]
```

By setting the `reverse` kwarg to `True`, the cumsum is performed in the
opposite direction:

```python
tf.cumsum([a, b, c], reverse=True)  # => [a + b + c, b + c, c]
```

This is more efficient than using separate `tf.reverse` ops.

The `reverse` and `exclusive` kwargs can also be combined:

```python
tf.cumsum([a, b, c], exclusive=True, reverse=True)  # => [b + c, c, 0]
```
END
}
