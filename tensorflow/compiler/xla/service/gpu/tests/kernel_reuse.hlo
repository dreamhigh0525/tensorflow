// RUN: hlo_to_llvm_ir %s | FileCheck %s

// All fusions must reuse the same kernel:
// CHECK-LABEL: target triple
// CHECK: define void
// CHECK-NOT: define void

HloModule KernelReuse

fused_computation {
  param_0.2 = f32[5,5]{1,0} parameter(0)
  sqrt.11 = f32[5,5]{1,0} sqrt(param_0.2)
  sqrt.10 = f32[5,5]{1,0} sqrt(sqrt.11)
  ROOT sqrt.9 = f32[5,5]{1,0} sqrt(sqrt.10)
}

fused_computation.1 {
  param_0.5 = f32[5,5]{1,0} parameter(0)
  sqrt.14 = f32[5,5]{1,0} sqrt(param_0.5)
  sqrt.13 = f32[5,5]{1,0} sqrt(sqrt.14)
  ROOT sqrt.12 = f32[5,5]{1,0} sqrt(sqrt.13)
}

fused_computation.2 {
  param_0.8 = f32[5,5]{1,0} parameter(0)
  sqrt.17 = f32[5,5]{1,0} sqrt(param_0.8)
  sqrt.16 = f32[5,5]{1,0} sqrt(sqrt.17)
  ROOT sqrt.15 = f32[5,5]{1,0} sqrt(sqrt.16)
}

ENTRY main {
  a = f32[5,5]{1,0} parameter(0)
  custom-call = f32[5,5]{1,0} custom-call(a, a), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  fusion.2 = f32[5,5]{1,0} fusion(custom-call), kind=kLoop, calls=fused_computation.2
  custom-call.1 = f32[5,5]{1,0} custom-call(fusion.2, fusion.2), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  fusion.1 = f32[5,5]{1,0} fusion(custom-call.1), kind=kLoop, calls=fused_computation.1
  custom-call.2 = f32[5,5]{1,0} custom-call(fusion.1, fusion.1), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  fusion = f32[5,5]{1,0} fusion(custom-call.2), kind=kLoop, calls=fused_computation
  custom-call.3 = f32[5,5]{1,0} custom-call(fusion, fusion), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  ROOT tuple = (f32[5,5]{1,0}, f32[5,5]{1,0}, f32[5,5]{1,0}, f32[5,5]{1,0}) tuple(custom-call, custom-call.1, custom-call.2, custom-call.3)
}

// -----

// We need 2 different kernels:
// - @fusion_2's %arg0 must have align 16, because we are passing a module input
// - @fusion_1's %arg0 must have align 128, because we are passing an internal buffer
// CHECK-LABEL: target triple
// CHECK: define void @fusion_2(ptr noalias align 16 dereferenceable(100) %arg0, ptr noalias align 128 dereferenceable(100) %arg1) {
// CHECK: define void @fusion_1(ptr noalias align 128 dereferenceable(100) %arg0, ptr noalias align 128 dereferenceable(100) %arg1) {
// CHECK-NOT: define void

HloModule KernelReuse

fused_computation {
  param_0.2 = f32[5,5]{1,0} parameter(0)
  sqrt.11 = f32[5,5]{1,0} sqrt(param_0.2)
  sqrt.10 = f32[5,5]{1,0} sqrt(sqrt.11)
  ROOT sqrt.9 = f32[5,5]{1,0} sqrt(sqrt.10)
}

fused_computation.1 {
  param_0.5 = f32[5,5]{1,0} parameter(0)
  sqrt.14 = f32[5,5]{1,0} sqrt(param_0.5)
  sqrt.13 = f32[5,5]{1,0} sqrt(sqrt.14)
  ROOT sqrt.12 = f32[5,5]{1,0} sqrt(sqrt.13)
}

fused_computation.2 {
  param_0.8 = f32[5,5]{1,0} parameter(0)
  sqrt.17 = f32[5,5]{1,0} sqrt(param_0.8)
  sqrt.16 = f32[5,5]{1,0} sqrt(sqrt.17)
  ROOT sqrt.15 = f32[5,5]{1,0} sqrt(sqrt.16)
}

ENTRY main {
  a = f32[5,5]{1,0} parameter(0)
  fusion.2 = f32[5,5]{1,0} fusion(a), kind=kLoop, calls=fused_computation.2
  custom-call.1 = f32[5,5]{1,0} custom-call(fusion.2, fusion.2), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  fusion.1 = f32[5,5]{1,0} fusion(custom-call.1), kind=kLoop, calls=fused_computation.1
  custom-call.2 = f32[5,5]{1,0} custom-call(fusion.1, fusion.1), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  fusion = f32[5,5]{1,0} fusion(custom-call.2), kind=kLoop, calls=fused_computation
  custom-call.3 = f32[5,5]{1,0} custom-call(fusion, fusion), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  ROOT tuple = (f32[5,5]{1,0}, f32[5,5]{1,0}, f32[5,5]{1,0}) tuple(custom-call.1, custom-call.2, custom-call.3)
}

// -----

// We need 2 different kernels:
// The first fusion call is aliased, the others are not.
// CHECK-LABEL: target triple
// CHECK: define void @fusion_2(ptr align 128 dereferenceable(100) %arg0, ptr align 128 dereferenceable(100) %arg1, ptr noalias align 128 dereferenceable(100) %arg2) {
// CHECK: define void @fusion_1(ptr noalias align 128 dereferenceable(100) %arg0, ptr noalias align 128 dereferenceable(100) %arg1, ptr noalias align 128 dereferenceable(100) %arg2) {
// CHECK-NOT: define void

HloModule KernelReuse

fused_computation {
  a = f32[5,5]{1,0} parameter(0)
  b = f32[5,5]{1,0} parameter(1)
  ROOT c = f32[5,5]{1,0} add(a, b)
}

fused_computation.1 {
  a = f32[5,5]{1,0} parameter(0)
  b = f32[5,5]{1,0} parameter(1)
  ROOT c = f32[5,5]{1,0} add(a, b)
}

fused_computation.2 {
  a = f32[5,5]{1,0} parameter(0)
  b = f32[5,5]{1,0} parameter(1)
  ROOT c = f32[5,5]{1,0} add(a, b)
}

ENTRY main {
  a = f32[5,5]{1,0} parameter(0)
  custom-call = f32[5,5]{1,0} custom-call(a, a), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  fusion.2 = f32[5,5]{1,0} fusion(custom-call, custom-call), kind=kLoop, calls=fused_computation.2
  custom-call.1 = f32[5,5]{1,0} custom-call(fusion.2, fusion.2), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  fusion.1 = f32[5,5]{1,0} fusion(custom-call, custom-call.1), kind=kLoop, calls=fused_computation.1
  custom-call.2 = f32[5,5]{1,0} custom-call(fusion.1, fusion.1), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  fusion = f32[5,5]{1,0} fusion(custom-call.1, custom-call.2), kind=kLoop, calls=fused_computation
  custom-call.3 = f32[5,5]{1,0} custom-call(fusion, fusion), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  ROOT tuple = (f32[5,5]{1,0}, f32[5,5]{1,0}, f32[5,5]{1,0}, f32[5,5]{1,0}) tuple(custom-call, custom-call.1, custom-call.2, custom-call.3)
}

// -----

// We need 2 different kernels:
// In the first one we modify the input buffer in place.
// In the others, we have a separate input and output buffer, so we can use
// "!invariant.load" (thanks to ir_array.MarkInvariantOverWholeProgram).
//
// CHECK-LABEL: target triple
// CHECK: define void @fusion_2(ptr align 128 dereferenceable(100) %arg0, ptr align 128 dereferenceable(100) %arg1) {
// CHECK-NOT: !invariant.load
// CHECK: define void @fusion(ptr noalias align 128 dereferenceable(100) %arg0, ptr noalias align 128 dereferenceable(100) %arg1) {
// CHECK-NOT: define void
// CHECK: !invariant.load
// CHECK-NOT: define void

HloModule KernelReuse

fused_computation {
  a = f32[5,5]{1,0} parameter(0)
  ROOT b = f32[5,5]{1,0} sqrt(a)
}

fused_computation.1 {
  a = f32[5,5]{1,0} parameter(0)
  ROOT b = f32[5,5]{1,0} sqrt(a)
}

fused_computation.2 {
  a = f32[5,5]{1,0} parameter(0)
  ROOT b = f32[5,5]{1,0} sqrt(a)
}

ENTRY main {
  a = f32[5,5]{1,0} parameter(0)
  custom-call = f32[5,5]{1,0} custom-call(a, a), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  fusion.2 = f32[5,5]{1,0} fusion(custom-call), kind=kLoop, calls=fused_computation.2
  custom-call.1 = f32[5,5]{1,0} custom-call(fusion.2, fusion.2), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  fusion.1 = f32[5,5]{1,0} fusion(custom-call.1), kind=kLoop, calls=fused_computation.1
  custom-call.2 = f32[5,5]{1,0} custom-call(fusion.1, fusion.1), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  fusion = f32[5,5]{1,0} fusion(custom-call.1), kind=kLoop, calls=fused_computation
  custom-call.3 = f32[5,5]{1,0} custom-call(fusion, fusion), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"alpha_imag\":0,\"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\"epilogue\":\"DEFAULT\"}"
  // We don't output custom-call, so fusion.2 can change its input.
  ROOT tuple = (f32[5,5]{1,0}, f32[5,5]{1,0}, f32[5,5]{1,0}) tuple(custom-call.1, custom-call.2, custom-call.3)
}


