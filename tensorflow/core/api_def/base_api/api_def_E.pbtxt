op {
  graph_op_name: "EditDistance"
  endpoint {
    name: "EditDistance"
  }
  summary: "Computes the (possibly normalized) Levenshtein Edit Distance."
  description: <<END
The inputs are variable-length sequences provided by SparseTensors
  (hypothesis_indices, hypothesis_values, hypothesis_shape)
and
  (truth_indices, truth_values, truth_shape).

The inputs are:
END
}
op {
  graph_op_name: "Elu"
  endpoint {
    name: "Elu"
  }
  summary: "Computes exponential linear: `exp(features) - 1` if < 0, `features` otherwise."
  description: <<END
See [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)
](http://arxiv.org/abs/1511.07289)
END
}
op {
  graph_op_name: "EluGrad"
  endpoint {
    name: "EluGrad"
  }
  summary: "Computes gradients for the exponential linear (Elu) operation."
}
op {
  graph_op_name: "EncodeBase64"
  endpoint {
    name: "EncodeBase64"
  }
  summary: "Encode strings into web-safe base64 format."
  description: <<END
Refer to the following article for more information on base64 format:
en.wikipedia.org/wiki/Base64. Base64 strings may have padding with '=' at the
end so that the encoded has length multiple of 4. See Padding section of the
link above.

Web-safe means that the encoder uses - and _ instead of + and /.
END
}
op {
  graph_op_name: "EncodeJpeg"
  endpoint {
    name: "EncodeJpeg"
  }
  summary: "JPEG-encode an image."
  description: <<END
`image` is a 3-D uint8 Tensor of shape `[height, width, channels]`.

The attr `format` can be used to override the color format of the encoded
output.  Values can be:

*   `''`: Use a default format based on the number of channels in the image.
*   `grayscale`: Output a grayscale JPEG image.  The `channels` dimension
    of `image` must be 1.
*   `rgb`: Output an RGB JPEG image. The `channels` dimension
    of `image` must be 3.

If `format` is not specified or is the empty string, a default format is picked
in function of the number of channels in `image`:

*   1: Output a grayscale image.
*   3: Output an RGB image.
END
}
op {
  graph_op_name: "EncodePng"
  endpoint {
    name: "EncodePng"
  }
  summary: "PNG-encode an image."
  description: <<END
`image` is a 3-D uint8 or uint16 Tensor of shape `[height, width, channels]`
where `channels` is:

*   1: for grayscale.
*   2: for grayscale + alpha.
*   3: for RGB.
*   4: for RGBA.

The ZLIB compression level, `compression`, can be -1 for the PNG-encoder
default or a value from 0 to 9.  9 is the highest compression level, generating
the smallest output, but is slower.
END
}
op {
  graph_op_name: "EncodeWav"
  endpoint {
    name: "EncodeWav"
  }
  summary: "Encode audio data using the WAV file format."
  description: <<END
This operation will generate a string suitable to be saved out to create a .wav
audio file. It will be encoded in the 16-bit PCM format. It takes in float
values in the range -1.0f to 1.0f, and any outside that value will be clamped to
that range.

`audio` is a 2-D float Tensor of shape `[length, channels]`.
`sample_rate` is a scalar Tensor holding the rate to use (e.g. 44100).
END
}
op {
  graph_op_name: "Enter"
  endpoint {
    name: "Enter"
  }
  summary: "Creates or finds a child frame, and makes `data` available to the child frame."
  description: <<END
This op is used together with `Exit` to create loops in the graph.
The unique `frame_name` is used by the `Executor` to identify frames. If
`is_constant` is true, `output` is a constant in the child frame; otherwise
it may be changed in the child frame. At most `parallel_iterations` iterations
are run in parallel in the child frame.
END
}
op {
  graph_op_name: "Equal"
  endpoint {
    name: "Equal"
  }
  summary: "Returns the truth value of (x == y) element-wise."
  description: <<END
*NOTE*: `Equal` supports broadcasting. More about broadcasting
[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
END
}
op {
  graph_op_name: "Erf"
  endpoint {
    name: "Erf"
  }
  summary: "Computes the Gauss error function of `x` element-wise."
}
op {
  graph_op_name: "Erfc"
  endpoint {
    name: "Erfc"
  }
  summary: "Computes the complementary error function of `x` element-wise."
}
op {
  graph_op_name: "Exit"
  endpoint {
    name: "Exit"
  }
  summary: "Exits the current frame to its parent frame."
  description: <<END
Exit makes its input `data` available to the parent frame.
END
}
op {
  graph_op_name: "Exp"
  endpoint {
    name: "Exp"
  }
  summary: "Computes exponential of x element-wise.  \\\\(y = e^x\\\\)."
}
op {
  graph_op_name: "ExpandDims"
  endpoint {
    name: "ExpandDims"
  }
  summary: "Inserts a dimension of 1 into a tensor\'s shape."
  description: <<END
Given a tensor `input`, this operation inserts a dimension of 1 at the
dimension index `dim` of `input`'s shape. The dimension index `dim` starts at
zero; if you specify a negative number for `dim` it is counted backward from
the end.

This operation is useful if you want to add a batch dimension to a single
element. For example, if you have a single image of shape `[height, width,
channels]`, you can make it a batch of 1 image with `expand_dims(image, 0)`,
which will make the shape `[1, height, width, channels]`.

Other examples:

```
# 't' is a tensor of shape [2]
shape(expand_dims(t, 0)) ==> [1, 2]
shape(expand_dims(t, 1)) ==> [2, 1]
shape(expand_dims(t, -1)) ==> [2, 1]

# 't2' is a tensor of shape [2, 3, 5]
shape(expand_dims(t2, 0)) ==> [1, 2, 3, 5]
shape(expand_dims(t2, 2)) ==> [2, 3, 1, 5]
shape(expand_dims(t2, 3)) ==> [2, 3, 5, 1]
```

This operation requires that:

`-1-input.dims() <= dim <= input.dims()`

This operation is related to `squeeze()`, which removes dimensions of
size 1.
END
}
op {
  graph_op_name: "Expm1"
  endpoint {
    name: "Expm1"
  }
  summary: "Computes exponential of x - 1 element-wise."
  description: <<END
I.e., \\(y = (\exp x) - 1\\).
END
}
op {
  graph_op_name: "ExtractGlimpse"
  endpoint {
    name: "ExtractGlimpse"
  }
  summary: "Extracts a glimpse from the input tensor."
  description: <<END
Returns a set of windows called glimpses extracted at location
`offsets` from the input tensor. If the windows only partially
overlaps the inputs, the non overlapping areas will be filled with
random noise.

The result is a 4-D tensor of shape `[batch_size, glimpse_height,
glimpse_width, channels]`. The channels and batch dimensions are the
same as that of the input tensor. The height and width of the output
windows are specified in the `size` parameter.

The argument `normalized` and `centered` controls how the windows are built:

* If the coordinates are normalized but not centered, 0.0 and 1.0
  correspond to the minimum and maximum of each height and width
  dimension.
* If the coordinates are both normalized and centered, they range from
  -1.0 to 1.0. The coordinates (-1.0, -1.0) correspond to the upper
  left corner, the lower right corner is located at (1.0, 1.0) and the
  center is at (0, 0).
* If the coordinates are not normalized they are interpreted as
  numbers of pixels.
END
}
op {
  graph_op_name: "ExtractImagePatches"
  endpoint {
    name: "ExtractImagePatches"
  }
  summary: "Extract `patches` from `images` and put them in the \"depth\" output dimension."
}
op {
  graph_op_name: "ExtractJpegShape"
  endpoint {
    name: "ExtractJpegShape"
  }
  summary: "Extract the shape information of a JPEG-encoded image."
  description: <<END
This op only parses the image header, so it is much faster than DecodeJpeg.
END
}
